{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":2,"outputs":[{"output_type":"stream","text":"/kaggle/input/loan_level_500k.csv\n","name":"stdout"}]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#import H2O and other libraries that will be sued in this tutorial\n\nimport h2o\nimport matplotlib as plt\n%matplotlib inline\n\n#import the Estimators\nfrom h2o.estimators.glm import H2OGeneralizedLinearEstimator\nfrom h2o.estimators import H2ORandomForestEstimator\nfrom h2o.estimators.gbm import H2OGradientBoostingEstimator\n\n#import h2o grid search\nimport h2o.grid\nfrom h2o.grid.grid_search import H2OGridSearch\nprint('Setup Complete')\n","execution_count":3,"outputs":[{"output_type":"stream","text":"Setup Complete\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"h2o.init()","execution_count":4,"outputs":[{"output_type":"stream","text":"Checking whether there is an H2O instance running at http://localhost:54321 ..... not found.\nAttempting to start a local H2O server...\n  Java Version: openjdk version \"11.0.7\" 2020-04-14; OpenJDK Runtime Environment (build 11.0.7+10-post-Ubuntu-2ubuntu218.04); OpenJDK 64-Bit Server VM (build 11.0.7+10-post-Ubuntu-2ubuntu218.04, mixed mode, sharing)\n  Starting server from /opt/conda/lib/python3.7/site-packages/h2o/backend/bin/h2o.jar\n  Ice root: /tmp/tmp7scqh_uk\n  JVM stdout: /tmp/tmp7scqh_uk/h2o_unknownUser_started_from_python.out\n  JVM stderr: /tmp/tmp7scqh_uk/h2o_unknownUser_started_from_python.err\n  Server is running at http://127.0.0.1:54321\nConnecting to H2O server at http://127.0.0.1:54321 ... successful.\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"--------------------------  ------------------------------------------------------------------\nH2O_cluster_uptime:         03 secs\nH2O_cluster_timezone:       Etc/UTC\nH2O_data_parsing_timezone:  UTC\nH2O_cluster_version:        3.30.0.5\nH2O_cluster_version_age:    9 days\nH2O_cluster_name:           H2O_from_python_unknownUser_l8cqc0\nH2O_cluster_total_nodes:    1\nH2O_cluster_free_memory:    3.250 Gb\nH2O_cluster_total_cores:    2\nH2O_cluster_allowed_cores:  2\nH2O_cluster_status:         accepting new members, healthy\nH2O_connection_url:         http://127.0.0.1:54321\nH2O_connection_proxy:       {\"http\": null, \"https\": null}\nH2O_internal_security:      False\nH2O_API_Extensions:         Amazon S3, XGBoost, Algos, AutoML, Core V3, TargetEncoder, Core V4\nPython_version:             3.7.6 final\n--------------------------  ------------------------------------------------------------------","text/html":"<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O_cluster_uptime:</td>\n<td>03 secs</td></tr>\n<tr><td>H2O_cluster_timezone:</td>\n<td>Etc/UTC</td></tr>\n<tr><td>H2O_data_parsing_timezone:</td>\n<td>UTC</td></tr>\n<tr><td>H2O_cluster_version:</td>\n<td>3.30.0.5</td></tr>\n<tr><td>H2O_cluster_version_age:</td>\n<td>9 days </td></tr>\n<tr><td>H2O_cluster_name:</td>\n<td>H2O_from_python_unknownUser_l8cqc0</td></tr>\n<tr><td>H2O_cluster_total_nodes:</td>\n<td>1</td></tr>\n<tr><td>H2O_cluster_free_memory:</td>\n<td>3.250 Gb</td></tr>\n<tr><td>H2O_cluster_total_cores:</td>\n<td>2</td></tr>\n<tr><td>H2O_cluster_allowed_cores:</td>\n<td>2</td></tr>\n<tr><td>H2O_cluster_status:</td>\n<td>accepting new members, healthy</td></tr>\n<tr><td>H2O_connection_url:</td>\n<td>http://127.0.0.1:54321</td></tr>\n<tr><td>H2O_connection_proxy:</td>\n<td>{\"http\": null, \"https\": null}</td></tr>\n<tr><td>H2O_internal_security:</td>\n<td>False</td></tr>\n<tr><td>H2O_API_Extensions:</td>\n<td>Amazon S3, XGBoost, Algos, AutoML, Core V3, TargetEncoder, Core V4</td></tr>\n<tr><td>Python_version:</td>\n<td>3.7.6 final</td></tr></table></div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"loan_level = h2o.import_file(\"https://s3.amazonaws.com/data.h2o.ai/DAI-Tutorials/loan_level_500k.csv\")\n","execution_count":5,"outputs":[{"output_type":"stream","text":"Parse progress: |█████████████████████████████████████████████████████████| 100%\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"loan_level.head()","execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/html":"<table>\n<thead>\n<tr><th style=\"text-align: right;\">  CREDIT_SCORE</th><th style=\"text-align: right;\">  FIRST_PAYMENT_DATE</th><th>FIRST_TIME_HOMEBUYER_FLAG  </th><th style=\"text-align: right;\">  MATURITY_DATE</th><th style=\"text-align: right;\">  METROPOLITAN_STATISTICAL_AREA</th><th style=\"text-align: right;\">  MORTGAGE_INSURANCE_PERCENTAGE</th><th style=\"text-align: right;\">  NUMBER_OF_UNITS</th><th>OCCUPANCY_STATUS  </th><th style=\"text-align: right;\">  ORIGINAL_COMBINED_LOAN_TO_VALUE</th><th style=\"text-align: right;\">  ORIGINAL_DEBT_TO_INCOME_RATIO</th><th style=\"text-align: right;\">  ORIGINAL_UPB</th><th style=\"text-align: right;\">  ORIGINAL_LOAN_TO_VALUE</th><th style=\"text-align: right;\">  ORIGINAL_INTEREST_RATE</th><th>CHANNEL  </th><th>PREPAYMENT_PENALTY_MORTGAGE_FLAG  </th><th>PRODUCT_TYPE  </th><th>PROPERTY_STATE  </th><th>PROPERTY_TYPE  </th><th style=\"text-align: right;\">  POSTAL_CODE</th><th>LOAN_SEQUENCE_NUMBER  </th><th>LOAN_PURPOSE  </th><th style=\"text-align: right;\">  ORIGINAL_LOAN_TERM</th><th style=\"text-align: right;\">  NUMBER_OF_BORROWERS</th><th>SELLER_NAME  </th><th>SERVICER_NAME  </th><th>PREPAID  </th><th>DELINQUENT  </th></tr>\n</thead>\n<tbody>\n<tr><td style=\"text-align: right;\">           669</td><td style=\"text-align: right;\">              200206</td><td>N                          </td><td style=\"text-align: right;\">         202901</td><td style=\"text-align: right;\">                            nan</td><td style=\"text-align: right;\">                              0</td><td style=\"text-align: right;\">                1</td><td>O                 </td><td style=\"text-align: right;\">                               80</td><td style=\"text-align: right;\">                             33</td><td style=\"text-align: right;\">        162000</td><td style=\"text-align: right;\">                      80</td><td style=\"text-align: right;\">                   7.12 </td><td>R        </td><td>N                                 </td><td>FRM           </td><td>WV              </td><td>SF             </td><td style=\"text-align: right;\">        26100</td><td>F199Q1000004          </td><td>P             </td><td style=\"text-align: right;\">                 320</td><td style=\"text-align: right;\">                    2</td><td>Other sellers</td><td>Other servicers</td><td>TRUE     </td><td>FALSE       </td></tr>\n<tr><td style=\"text-align: right;\">           732</td><td style=\"text-align: right;\">              199904</td><td>N                          </td><td style=\"text-align: right;\">         202903</td><td style=\"text-align: right;\">                          17140</td><td style=\"text-align: right;\">                              0</td><td style=\"text-align: right;\">                1</td><td>O                 </td><td style=\"text-align: right;\">                               25</td><td style=\"text-align: right;\">                             10</td><td style=\"text-align: right;\">         53000</td><td style=\"text-align: right;\">                      25</td><td style=\"text-align: right;\">                   6.5  </td><td>R        </td><td>N                                 </td><td>FRM           </td><td>OH              </td><td>SF             </td><td style=\"text-align: right;\">        45200</td><td>F199Q1000005          </td><td>N             </td><td style=\"text-align: right;\">                 360</td><td style=\"text-align: right;\">                    1</td><td>Other sellers</td><td>Other servicers</td><td>TRUE     </td><td>FALSE       </td></tr>\n<tr><td style=\"text-align: right;\">           679</td><td style=\"text-align: right;\">              200208</td><td>N                          </td><td style=\"text-align: right;\">         202902</td><td style=\"text-align: right;\">                          15940</td><td style=\"text-align: right;\">                             30</td><td style=\"text-align: right;\">                1</td><td>O                 </td><td style=\"text-align: right;\">                               91</td><td style=\"text-align: right;\">                             48</td><td style=\"text-align: right;\">        133000</td><td style=\"text-align: right;\">                      91</td><td style=\"text-align: right;\">                   6.75 </td><td>R        </td><td>N                                 </td><td>FRM           </td><td>OH              </td><td>SF             </td><td style=\"text-align: right;\">        44700</td><td>F199Q1000007          </td><td>P             </td><td style=\"text-align: right;\">                 319</td><td style=\"text-align: right;\">                    1</td><td>Other sellers</td><td>Other servicers</td><td>TRUE     </td><td>FALSE       </td></tr>\n<tr><td style=\"text-align: right;\">           721</td><td style=\"text-align: right;\">              200209</td><td>N                          </td><td style=\"text-align: right;\">         202902</td><td style=\"text-align: right;\">                          38060</td><td style=\"text-align: right;\">                              0</td><td style=\"text-align: right;\">                1</td><td>O                 </td><td style=\"text-align: right;\">                               39</td><td style=\"text-align: right;\">                             13</td><td style=\"text-align: right;\">        174000</td><td style=\"text-align: right;\">                      39</td><td style=\"text-align: right;\">                   6.625</td><td>T        </td><td>N                                 </td><td>FRM           </td><td>AZ              </td><td>SF             </td><td style=\"text-align: right;\">        85200</td><td>F199Q1000013          </td><td>N             </td><td style=\"text-align: right;\">                 318</td><td style=\"text-align: right;\">                    2</td><td>Other sellers</td><td>Other servicers</td><td>TRUE     </td><td>FALSE       </td></tr>\n<tr><td style=\"text-align: right;\">           618</td><td style=\"text-align: right;\">              200210</td><td>N                          </td><td style=\"text-align: right;\">         202902</td><td style=\"text-align: right;\">                          10420</td><td style=\"text-align: right;\">                             25</td><td style=\"text-align: right;\">                1</td><td>O                 </td><td style=\"text-align: right;\">                               85</td><td style=\"text-align: right;\">                             24</td><td style=\"text-align: right;\">        122000</td><td style=\"text-align: right;\">                      85</td><td style=\"text-align: right;\">                   6.375</td><td>R        </td><td>N                                 </td><td>FRM           </td><td>OH              </td><td>SF             </td><td style=\"text-align: right;\">        44200</td><td>F199Q1000015          </td><td>N             </td><td style=\"text-align: right;\">                 317</td><td style=\"text-align: right;\">                    2</td><td>Other sellers</td><td>Other servicers</td><td>TRUE     </td><td>FALSE       </td></tr>\n<tr><td style=\"text-align: right;\">           738</td><td style=\"text-align: right;\">              200211</td><td>N                          </td><td style=\"text-align: right;\">         202903</td><td style=\"text-align: right;\">                          10420</td><td style=\"text-align: right;\">                              0</td><td style=\"text-align: right;\">                1</td><td>O                 </td><td style=\"text-align: right;\">                               73</td><td style=\"text-align: right;\">                             44</td><td style=\"text-align: right;\">        218000</td><td style=\"text-align: right;\">                      73</td><td style=\"text-align: right;\">                   6    </td><td>R        </td><td>N                                 </td><td>FRM           </td><td>OH              </td><td>SF             </td><td style=\"text-align: right;\">        44300</td><td>F199Q1000016          </td><td>P             </td><td style=\"text-align: right;\">                 317</td><td style=\"text-align: right;\">                    2</td><td>Other sellers</td><td>Other servicers</td><td>TRUE     </td><td>FALSE       </td></tr>\n<tr><td style=\"text-align: right;\">           761</td><td style=\"text-align: right;\">              200211</td><td>N                          </td><td style=\"text-align: right;\">         202904</td><td style=\"text-align: right;\">                            nan</td><td style=\"text-align: right;\">                              0</td><td style=\"text-align: right;\">                1</td><td>O                 </td><td style=\"text-align: right;\">                               73</td><td style=\"text-align: right;\">                             31</td><td style=\"text-align: right;\">        138000</td><td style=\"text-align: right;\">                      73</td><td style=\"text-align: right;\">                   6.375</td><td>R        </td><td>N                                 </td><td>FRM           </td><td>SC              </td><td>PU             </td><td style=\"text-align: right;\">        29500</td><td>F199Q1000017          </td><td>P             </td><td style=\"text-align: right;\">                 318</td><td style=\"text-align: right;\">                    2</td><td>Other sellers</td><td>Other servicers</td><td>TRUE     </td><td>FALSE       </td></tr>\n<tr><td style=\"text-align: right;\">           707</td><td style=\"text-align: right;\">              200211</td><td>N                          </td><td style=\"text-align: right;\">         202903</td><td style=\"text-align: right;\">                          33340</td><td style=\"text-align: right;\">                              0</td><td style=\"text-align: right;\">                1</td><td>O                 </td><td style=\"text-align: right;\">                               60</td><td style=\"text-align: right;\">                             57</td><td style=\"text-align: right;\">        136000</td><td style=\"text-align: right;\">                      60</td><td style=\"text-align: right;\">                   6.25 </td><td>R        </td><td>N                                 </td><td>FRM           </td><td>WI              </td><td>SF             </td><td style=\"text-align: right;\">        53000</td><td>F199Q1000018          </td><td>C             </td><td style=\"text-align: right;\">                 317</td><td style=\"text-align: right;\">                    2</td><td>Other sellers</td><td>Other servicers</td><td>TRUE     </td><td>FALSE       </td></tr>\n<tr><td style=\"text-align: right;\">           760</td><td style=\"text-align: right;\">              200211</td><td>N                          </td><td style=\"text-align: right;\">         202903</td><td style=\"text-align: right;\">                          33340</td><td style=\"text-align: right;\">                              0</td><td style=\"text-align: right;\">                1</td><td>O                 </td><td style=\"text-align: right;\">                               63</td><td style=\"text-align: right;\">                             30</td><td style=\"text-align: right;\">         79000</td><td style=\"text-align: right;\">                      63</td><td style=\"text-align: right;\">                   6.125</td><td>R        </td><td>N                                 </td><td>FRM           </td><td>WI              </td><td>SF             </td><td style=\"text-align: right;\">        53000</td><td>F199Q1000019          </td><td>N             </td><td style=\"text-align: right;\">                 317</td><td style=\"text-align: right;\">                    2</td><td>Other sellers</td><td>Other servicers</td><td>TRUE     </td><td>FALSE       </td></tr>\n<tr><td style=\"text-align: right;\">           691</td><td style=\"text-align: right;\">              200302</td><td>N                          </td><td style=\"text-align: right;\">         202901</td><td style=\"text-align: right;\">                          15940</td><td style=\"text-align: right;\">                              0</td><td style=\"text-align: right;\">                1</td><td>O                 </td><td style=\"text-align: right;\">                               65</td><td style=\"text-align: right;\">                             25</td><td style=\"text-align: right;\">        130000</td><td style=\"text-align: right;\">                      65</td><td style=\"text-align: right;\">                   5.875</td><td>R        </td><td>N                                 </td><td>FRM           </td><td>OH              </td><td>SF             </td><td style=\"text-align: right;\">        44700</td><td>F199Q1000023          </td><td>P             </td><td style=\"text-align: right;\">                 312</td><td style=\"text-align: right;\">                    2</td><td>Other sellers</td><td>Other servicers</td><td>TRUE     </td><td>FALSE       </td></tr>\n</tbody>\n</table>"},"metadata":{}},{"output_type":"execute_result","execution_count":6,"data":{"text/plain":""},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"loan_level.describe()","execution_count":7,"outputs":[{"output_type":"stream","text":"Rows:500137\nCols:27\n\n\n","name":"stdout"},{"output_type":"display_data","data":{"text/html":"<table>\n<thead>\n<tr><th>       </th><th>CREDIT_SCORE     </th><th>FIRST_PAYMENT_DATE  </th><th>FIRST_TIME_HOMEBUYER_FLAG  </th><th>MATURITY_DATE     </th><th>METROPOLITAN_STATISTICAL_AREA  </th><th>MORTGAGE_INSURANCE_PERCENTAGE  </th><th>NUMBER_OF_UNITS    </th><th>OCCUPANCY_STATUS  </th><th>ORIGINAL_COMBINED_LOAN_TO_VALUE  </th><th>ORIGINAL_DEBT_TO_INCOME_RATIO  </th><th>ORIGINAL_UPB      </th><th>ORIGINAL_LOAN_TO_VALUE  </th><th>ORIGINAL_INTEREST_RATE  </th><th>CHANNEL  </th><th>PREPAYMENT_PENALTY_MORTGAGE_FLAG  </th><th>PRODUCT_TYPE  </th><th>PROPERTY_STATE  </th><th>PROPERTY_TYPE  </th><th>POSTAL_CODE      </th><th>LOAN_SEQUENCE_NUMBER  </th><th>LOAN_PURPOSE  </th><th>ORIGINAL_LOAN_TERM  </th><th>NUMBER_OF_BORROWERS  </th><th>SELLER_NAME  </th><th>SERVICER_NAME  </th><th>PREPAID  </th><th>DELINQUENT  </th></tr>\n</thead>\n<tbody>\n<tr><td>type   </td><td>int              </td><td>int                 </td><td>enum                       </td><td>int               </td><td>int                            </td><td>int                            </td><td>int                </td><td>enum              </td><td>int                              </td><td>int                            </td><td>int               </td><td>int                     </td><td>real                    </td><td>enum     </td><td>enum                              </td><td>enum          </td><td>enum            </td><td>enum           </td><td>int              </td><td>string                </td><td>enum          </td><td>int                 </td><td>int                  </td><td>enum         </td><td>enum           </td><td>enum     </td><td>enum        </td></tr>\n<tr><td>mins   </td><td>300.0            </td><td>199901.0            </td><td>                           </td><td>202402.0          </td><td>10180.0                        </td><td>0.0                            </td><td>1.0                </td><td>                  </td><td>6.0                              </td><td>1.0                            </td><td>8000.0            </td><td>6.0                     </td><td>4.625                   </td><td>         </td><td>                                  </td><td>              </td><td>                </td><td>               </td><td>600.0            </td><td>NaN                   </td><td>              </td><td>301.0               </td><td>1.0                  </td><td>             </td><td>               </td><td>         </td><td>            </td></tr>\n<tr><td>mean   </td><td>712.5362124215468</td><td>200025.43095191979  </td><td>                           </td><td>203023.1958723312 </td><td>30777.82473929504              </td><td>7.744531707523469              </td><td>1.0288902574110184 </td><td>                  </td><td>76.0535707144633                 </td><td>32.91754051870545              </td><td>136493.48478516805</td><td>75.71071405720141       </td><td>7.182686863799322       </td><td>         </td><td>                                  </td><td>              </td><td>                </td><td>               </td><td>55490.8571382869 </td><td>NaN                   </td><td>              </td><td>359.8554696013299   </td><td>1.6302946648262713   </td><td>             </td><td>               </td><td>         </td><td>            </td></tr>\n<tr><td>maxs   </td><td>839.0            </td><td>201103.0            </td><td>                           </td><td>204101.0          </td><td>49740.0                        </td><td>55.0                           </td><td>4.0                </td><td>                  </td><td>180.0                            </td><td>65.0                           </td><td>578000.0          </td><td>100.0                   </td><td>11.5                    </td><td>         </td><td>                                  </td><td>              </td><td>                </td><td>               </td><td>99900.0          </td><td>NaN                   </td><td>              </td><td>362.0               </td><td>2.0                  </td><td>             </td><td>               </td><td>         </td><td>            </td></tr>\n<tr><td>sigma  </td><td>54.79126197408813</td><td>109.81554141403225  </td><td>                           </td><td>110.38418855867243</td><td>11333.401144164478             </td><td>12.04654596949256              </td><td>0.21839057355939082</td><td>                  </td><td>15.139986048512673               </td><td>11.111799994455248             </td><td>60968.74306564561 </td><td>14.937717088968643      </td><td>0.5799408623980744      </td><td>         </td><td>                                  </td><td>              </td><td>                </td><td>               </td><td>29505.38225880303</td><td>NaN                   </td><td>              </td><td>1.9082507104186504  </td><td>0.48272535304031594  </td><td>             </td><td>               </td><td>         </td><td>            </td></tr>\n<tr><td>zeros  </td><td>0                </td><td>0                   </td><td>                           </td><td>0                 </td><td>0                              </td><td>309979                         </td><td>0                  </td><td>                  </td><td>0                                </td><td>0                              </td><td>0                 </td><td>0                       </td><td>0                       </td><td>         </td><td>                                  </td><td>              </td><td>                </td><td>               </td><td>0                </td><td>0                     </td><td>              </td><td>0                   </td><td>0                    </td><td>             </td><td>               </td><td>         </td><td>            </td></tr>\n<tr><td>missing</td><td>2711             </td><td>0                   </td><td>0                          </td><td>0                 </td><td>70149                          </td><td>51048                          </td><td>3                  </td><td>0                 </td><td>13                               </td><td>14929                          </td><td>0                 </td><td>9                       </td><td>0                       </td><td>0        </td><td>0                                 </td><td>0             </td><td>0               </td><td>0              </td><td>31               </td><td>0                     </td><td>0             </td><td>0                   </td><td>247                  </td><td>0            </td><td>0              </td><td>0        </td><td>0           </td></tr>\n<tr><td>0      </td><td>669.0            </td><td>200206.0            </td><td>N                          </td><td>202901.0          </td><td>nan                            </td><td>0.0                            </td><td>1.0                </td><td>O                 </td><td>80.0                             </td><td>33.0                           </td><td>162000.0          </td><td>80.0                    </td><td>7.12                    </td><td>R        </td><td>N                                 </td><td>FRM           </td><td>WV              </td><td>SF             </td><td>26100.0          </td><td>F199Q1000004          </td><td>P             </td><td>320.0               </td><td>2.0                  </td><td>Other sellers</td><td>Other servicers</td><td>TRUE     </td><td>FALSE       </td></tr>\n<tr><td>1      </td><td>732.0            </td><td>199904.0            </td><td>N                          </td><td>202903.0          </td><td>17140.0                        </td><td>0.0                            </td><td>1.0                </td><td>O                 </td><td>25.0                             </td><td>10.0                           </td><td>53000.0           </td><td>25.0                    </td><td>6.5                     </td><td>R        </td><td>N                                 </td><td>FRM           </td><td>OH              </td><td>SF             </td><td>45200.0          </td><td>F199Q1000005          </td><td>N             </td><td>360.0               </td><td>1.0                  </td><td>Other sellers</td><td>Other servicers</td><td>TRUE     </td><td>FALSE       </td></tr>\n<tr><td>2      </td><td>679.0            </td><td>200208.0            </td><td>N                          </td><td>202902.0          </td><td>15940.0                        </td><td>30.0                           </td><td>1.0                </td><td>O                 </td><td>91.0                             </td><td>48.0                           </td><td>133000.0          </td><td>91.0                    </td><td>6.75                    </td><td>R        </td><td>N                                 </td><td>FRM           </td><td>OH              </td><td>SF             </td><td>44700.0          </td><td>F199Q1000007          </td><td>P             </td><td>319.0               </td><td>1.0                  </td><td>Other sellers</td><td>Other servicers</td><td>TRUE     </td><td>FALSE       </td></tr>\n<tr><td>3      </td><td>721.0            </td><td>200209.0            </td><td>N                          </td><td>202902.0          </td><td>38060.0                        </td><td>0.0                            </td><td>1.0                </td><td>O                 </td><td>39.0                             </td><td>13.0                           </td><td>174000.0          </td><td>39.0                    </td><td>6.625                   </td><td>T        </td><td>N                                 </td><td>FRM           </td><td>AZ              </td><td>SF             </td><td>85200.0          </td><td>F199Q1000013          </td><td>N             </td><td>318.0               </td><td>2.0                  </td><td>Other sellers</td><td>Other servicers</td><td>TRUE     </td><td>FALSE       </td></tr>\n<tr><td>4      </td><td>618.0            </td><td>200210.0            </td><td>N                          </td><td>202902.0          </td><td>10420.0                        </td><td>25.0                           </td><td>1.0                </td><td>O                 </td><td>85.0                             </td><td>24.0                           </td><td>122000.0          </td><td>85.0                    </td><td>6.375                   </td><td>R        </td><td>N                                 </td><td>FRM           </td><td>OH              </td><td>SF             </td><td>44200.0          </td><td>F199Q1000015          </td><td>N             </td><td>317.0               </td><td>2.0                  </td><td>Other sellers</td><td>Other servicers</td><td>TRUE     </td><td>FALSE       </td></tr>\n<tr><td>5      </td><td>738.0            </td><td>200211.0            </td><td>N                          </td><td>202903.0          </td><td>10420.0                        </td><td>0.0                            </td><td>1.0                </td><td>O                 </td><td>73.0                             </td><td>44.0                           </td><td>218000.0          </td><td>73.0                    </td><td>6.0                     </td><td>R        </td><td>N                                 </td><td>FRM           </td><td>OH              </td><td>SF             </td><td>44300.0          </td><td>F199Q1000016          </td><td>P             </td><td>317.0               </td><td>2.0                  </td><td>Other sellers</td><td>Other servicers</td><td>TRUE     </td><td>FALSE       </td></tr>\n<tr><td>6      </td><td>761.0            </td><td>200211.0            </td><td>N                          </td><td>202904.0          </td><td>nan                            </td><td>0.0                            </td><td>1.0                </td><td>O                 </td><td>73.0                             </td><td>31.0                           </td><td>138000.0          </td><td>73.0                    </td><td>6.375                   </td><td>R        </td><td>N                                 </td><td>FRM           </td><td>SC              </td><td>PU             </td><td>29500.0          </td><td>F199Q1000017          </td><td>P             </td><td>318.0               </td><td>2.0                  </td><td>Other sellers</td><td>Other servicers</td><td>TRUE     </td><td>FALSE       </td></tr>\n<tr><td>7      </td><td>707.0            </td><td>200211.0            </td><td>N                          </td><td>202903.0          </td><td>33340.0                        </td><td>0.0                            </td><td>1.0                </td><td>O                 </td><td>60.0                             </td><td>57.0                           </td><td>136000.0          </td><td>60.0                    </td><td>6.25                    </td><td>R        </td><td>N                                 </td><td>FRM           </td><td>WI              </td><td>SF             </td><td>53000.0          </td><td>F199Q1000018          </td><td>C             </td><td>317.0               </td><td>2.0                  </td><td>Other sellers</td><td>Other servicers</td><td>TRUE     </td><td>FALSE       </td></tr>\n<tr><td>8      </td><td>760.0            </td><td>200211.0            </td><td>N                          </td><td>202903.0          </td><td>33340.0                        </td><td>0.0                            </td><td>1.0                </td><td>O                 </td><td>63.0                             </td><td>30.0                           </td><td>79000.0           </td><td>63.0                    </td><td>6.125                   </td><td>R        </td><td>N                                 </td><td>FRM           </td><td>WI              </td><td>SF             </td><td>53000.0          </td><td>F199Q1000019          </td><td>N             </td><td>317.0               </td><td>2.0                  </td><td>Other sellers</td><td>Other servicers</td><td>TRUE     </td><td>FALSE       </td></tr>\n<tr><td>9      </td><td>691.0            </td><td>200302.0            </td><td>N                          </td><td>202901.0          </td><td>15940.0                        </td><td>0.0                            </td><td>1.0                </td><td>O                 </td><td>65.0                             </td><td>25.0                           </td><td>130000.0          </td><td>65.0                    </td><td>5.875                   </td><td>R        </td><td>N                                 </td><td>FRM           </td><td>OH              </td><td>SF             </td><td>44700.0          </td><td>F199Q1000023          </td><td>P             </td><td>312.0               </td><td>2.0                  </td><td>Other sellers</td><td>Other servicers</td><td>TRUE     </td><td>FALSE       </td></tr>\n</tbody>\n</table>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"loan_level['DELINQUENT'].table()","execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/html":"<table>\n<thead>\n<tr><th>DELINQUENT  </th><th style=\"text-align: right;\">  Count</th></tr>\n</thead>\n<tbody>\n<tr><td>FALSE       </td><td style=\"text-align: right;\"> 482146</td></tr>\n<tr><td>TRUE        </td><td style=\"text-align: right;\">  17991</td></tr>\n</tbody>\n</table>"},"metadata":{}},{"output_type":"execute_result","execution_count":8,"data":{"text/plain":""},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"Since we have a large enough dataset, we will split our dataset into three sets, and we will call them train, valid, and test. We will treat the test set as if it were some unseen data in which we want to make predictions, and we will use the valid set for validation purposes and to tune all our models. We will not use the test set until the end of the tutorial to check the final scores of our models.\n\nReturn to your Jupyter Notebook to split our dataset into three sets. We will use the .split_frame() function. Note that we can do this in one line of code. Inside the split function, we declare the ratio of the data that we want in our first set, in this case, the train set. We will assign 70% to the training set, and 15% for the validation, as well as for the test set. The random seed is set to 42 just for reproducibility purposes. You can choose any random seed that you want, but if you want to see consistent results, you will have to use the same random seed anytime you re-run your code."},{"metadata":{"trusted":true},"cell_type":"code","source":"train, valid, test = loan_level.split_frame([0.7, 0.15], seed = 42)","execution_count":9,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('train:%d, valid:%d, test:%d' % (train.nrows, valid.nrows, test.nrows))","execution_count":10,"outputs":[{"output_type":"stream","text":"train:350268, valid:74971, test:74898\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"Next, we need to choose our predictors, or x variable, and our response or y variable. For the H2O-3 estimators, we do not use the actual data frame; instead, we use strings containing the name of the columns in our dataset.\n\nReturn to your Jupyter Notebook. For our y variable, we will choose DELINQUENT because we want to predict whether or not a loan will default. For the x variable, we will choose all but four features. One is the feature that we will predict, and then PREPAID and PREPAYMENT_PENALTY_MORTGAGE_FLAG because they are clear indicators if a loan is or is not delinquent and we will not have the information at the time deciding whether to give a loan or not. In machine learning terms, introducing these types of features is called leakage. And lastly, PRODUCT_TYPE because that's a constant value for every row, meaning all samples have the same value; therefore, this feature will not have any predictive value.\n\nThere are several ways to choose your predictors, but for this tutorial, we will subtract the list in the variable ignore from all the names in our training set."},{"metadata":{"trusted":true},"cell_type":"code","source":"y = 'DELINQUENT'\nignore = ['DELINQUENT', 'PREPAID', 'PREPAYMENT_PENALTY_MORTGAGE_FLAG', 'PRODUCT_TYPE']\nx = list(set(train.names) - set(ignore))","execution_count":11,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Build Generalized Linear Model (GLM)"},{"metadata":{"trusted":true},"cell_type":"code","source":"glm = H2OGeneralizedLinearEstimator(family = 'binomial', seed = 42)","execution_count":12,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we will train our GLM model. To do so, we just use the .train() function. In the train function, we need to specify the predictors (x), the response (y), the training set (train), and a validation frame, if you have one. In our case, we have our valid set, which we will use."},{"metadata":{"trusted":true},"cell_type":"code","source":"%time \nglm.train(x = x, y = y, training_frame = train, validation_frame = valid)","execution_count":13,"outputs":[{"output_type":"stream","text":"CPU times: user 4 µs, sys: 1 µs, total: 5 µs\nWall time: 9.3 µs\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.7/site-packages/h2o/estimators/estimator_base.py:200: RuntimeWarning: Dropping bad and constant columns: [LOAN_SEQUENCE_NUMBER]\n  warnings.warn(mesg[\"message\"], RuntimeWarning)\n","name":"stderr"},{"output_type":"stream","text":"glm Model Build progress: |███████████████████████████████████████████████| 100%\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"glm","execution_count":14,"outputs":[{"output_type":"stream","text":"Model Details\n=============\nH2OGeneralizedLinearEstimator :  Generalized Linear Modeling\nModel Key:  GLM_model_python_1593292379278_1\n\n\nGLM Model: summary\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"       family   link                                 regularization  \\\n0    binomial  logit  Elastic Net (alpha = 0.5, lambda = 6.626E-5 )   \n\n   number_of_predictors_total number_of_active_predictors  \\\n0                         161                          88   \n\n   number_of_iterations training_frame  \n0                     7  py_4_sid_b930  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>family</th>\n      <th>link</th>\n      <th>regularization</th>\n      <th>number_of_predictors_total</th>\n      <th>number_of_active_predictors</th>\n      <th>number_of_iterations</th>\n      <th>training_frame</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td></td>\n      <td>binomial</td>\n      <td>logit</td>\n      <td>Elastic Net (alpha = 0.5, lambda = 6.626E-5 )</td>\n      <td>161</td>\n      <td>88</td>\n      <td>7</td>\n      <td>py_4_sid_b930</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"stream","text":"\n\nModelMetricsBinomialGLM: glm\n** Reported on train data. **\n\nMSE: 0.031421719571328846\nRMSE: 0.1772617261885059\nLogLoss: 0.12328049878526559\nNull degrees of freedom: 350267\nResidual degrees of freedom: 350179\nNull deviance: 108932.13150369536\nResidual deviance: 86362.4274970348\nAIC: 86540.4274970348\nAUC: 0.8503523971011903\nAUCPR: 0.206633488178161\nGini: 0.7007047942023805\n\nConfusion Matrix (Act/Pred) for max f1 @ threshold = 0.1282670025027246: \n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"             FALSE     TRUE   Error                 Rate\n0  FALSE  321986.0  15621.0  0.0463   (15621.0/337607.0)\n1   TRUE    7882.0   4779.0  0.6225     (7882.0/12661.0)\n2  Total  329868.0  20400.0  0.0671   (23503.0/350268.0)","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>FALSE</th>\n      <th>TRUE</th>\n      <th>Error</th>\n      <th>Rate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>FALSE</td>\n      <td>321986.0</td>\n      <td>15621.0</td>\n      <td>0.0463</td>\n      <td>(15621.0/337607.0)</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>TRUE</td>\n      <td>7882.0</td>\n      <td>4779.0</td>\n      <td>0.6225</td>\n      <td>(7882.0/12661.0)</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Total</td>\n      <td>329868.0</td>\n      <td>20400.0</td>\n      <td>0.0671</td>\n      <td>(23503.0/350268.0)</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"stream","text":"\nMaximum Metrics: Maximum metrics at their respective thresholds\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"                         metric  threshold          value    idx\n0                        max f1   0.128267       0.289102  207.0\n1                        max f2   0.066290       0.386470  266.0\n2                  max f0point5   0.216327       0.287980  151.0\n3                  max accuracy   0.975876       0.963851    0.0\n4                 max precision   0.554784       0.402597   44.0\n5                    max recall   0.000572       1.000000  399.0\n6               max specificity   0.975876       0.999997    0.0\n7              max absolute_mcc   0.108905       0.267492  222.0\n8    max min_per_class_accuracy   0.039056       0.771557  307.0\n9   max mean_per_class_accuracy   0.034489       0.774192  315.0\n10                      max tns   0.975876  337606.000000    0.0\n11                      max fns   0.975876   12661.000000    0.0\n12                      max fps   0.000572  337607.000000  399.0\n13                      max tps   0.000572   12661.000000  399.0\n14                      max tnr   0.975876       0.999997    0.0\n15                      max fnr   0.975876       1.000000    0.0\n16                      max fpr   0.000572       1.000000  399.0\n17                      max tpr   0.000572       1.000000  399.0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>metric</th>\n      <th>threshold</th>\n      <th>value</th>\n      <th>idx</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>max f1</td>\n      <td>0.128267</td>\n      <td>0.289102</td>\n      <td>207.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>max f2</td>\n      <td>0.066290</td>\n      <td>0.386470</td>\n      <td>266.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>max f0point5</td>\n      <td>0.216327</td>\n      <td>0.287980</td>\n      <td>151.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>max accuracy</td>\n      <td>0.975876</td>\n      <td>0.963851</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>max precision</td>\n      <td>0.554784</td>\n      <td>0.402597</td>\n      <td>44.0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>max recall</td>\n      <td>0.000572</td>\n      <td>1.000000</td>\n      <td>399.0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>max specificity</td>\n      <td>0.975876</td>\n      <td>0.999997</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>max absolute_mcc</td>\n      <td>0.108905</td>\n      <td>0.267492</td>\n      <td>222.0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>max min_per_class_accuracy</td>\n      <td>0.039056</td>\n      <td>0.771557</td>\n      <td>307.0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>max mean_per_class_accuracy</td>\n      <td>0.034489</td>\n      <td>0.774192</td>\n      <td>315.0</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>max tns</td>\n      <td>0.975876</td>\n      <td>337606.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>max fns</td>\n      <td>0.975876</td>\n      <td>12661.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>max fps</td>\n      <td>0.000572</td>\n      <td>337607.000000</td>\n      <td>399.0</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>max tps</td>\n      <td>0.000572</td>\n      <td>12661.000000</td>\n      <td>399.0</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>max tnr</td>\n      <td>0.975876</td>\n      <td>0.999997</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>max fnr</td>\n      <td>0.975876</td>\n      <td>1.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>max fpr</td>\n      <td>0.000572</td>\n      <td>1.000000</td>\n      <td>399.0</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>max tpr</td>\n      <td>0.000572</td>\n      <td>1.000000</td>\n      <td>399.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"stream","text":"\nGains/Lift Table: Avg response rate:  3.61 %, avg score:  3.61 %\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"      group  cumulative_data_fraction  lower_threshold       lift  \\\n0         1                  0.010001         0.315606  10.503740   \n1         2                  0.020002         0.231615   7.763290   \n2         3                  0.030003         0.189186   6.175883   \n3         4                  0.040001         0.160763   5.340267   \n4         5                  0.050002         0.140680   4.470013   \n5         6                  0.100001         0.087297   3.363160   \n6         7                  0.150002         0.062777   2.337808   \n7         8                  0.200001         0.048144   1.679211   \n8         9                  0.300002         0.031478   1.149192   \n9        10                  0.399999         0.021718   0.625557   \n10       11                  0.500000         0.015305   0.417026   \n11       12                  0.600001         0.010849   0.290655   \n12       13                  0.699998         0.007534   0.193512   \n13       14                  0.799999         0.004970   0.109785   \n14       15                  0.899999         0.002843   0.063186   \n15       16                  1.000000         0.000103   0.035542   \n\n    cumulative_lift  response_rate     score  cumulative_response_rate  \\\n0         10.503740       0.379675  0.447135                  0.379675   \n1          9.133515       0.280617  0.268426                  0.330146   \n2          8.147638       0.223237  0.209056                  0.294509   \n3          7.445946       0.193033  0.174289                  0.269146   \n4          6.850725       0.161576  0.150204                  0.247630   \n5          5.106992       0.121567  0.109556                  0.184600   \n6          4.183913       0.084504  0.073795                  0.151234   \n7          3.557756       0.060698  0.054923                  0.128601   \n8          2.754901       0.041539  0.038923                  0.099580   \n9          2.222576       0.022612  0.026218                  0.080339   \n10         1.861464       0.015074  0.018302                  0.067286   \n11         1.599661       0.010506  0.012959                  0.057822   \n12         1.398787       0.006995  0.009110                  0.050561   \n13         1.237661       0.003968  0.006210                  0.044737   \n14         1.107163       0.002284  0.003883                  0.040020   \n15         1.000000       0.001285  0.001771                  0.036147   \n\n    cumulative_score  capture_rate  cumulative_capture_rate        gain  \\\n0           0.447135      0.105047                 0.105047  950.373986   \n1           0.357781      0.077640                 0.182687  676.329044   \n2           0.308206      0.061764                 0.244451  517.588314   \n3           0.274734      0.053392                 0.297844  434.026745   \n4           0.249826      0.044704                 0.342548  347.001260   \n5           0.179693      0.168154                 0.510702  236.316030   \n6           0.144393      0.116894                 0.627597  133.780791   \n7           0.122026      0.083959                 0.711555   67.921061   \n8           0.094325      0.114920                 0.826475   14.919176   \n9           0.077298      0.062554                 0.889029  -37.444271   \n10          0.065499      0.041703                 0.930732  -58.297371   \n11          0.056742      0.029066                 0.959798  -70.934531   \n12          0.049938      0.019351                 0.979149  -80.648796   \n13          0.044472      0.010979                 0.990127  -89.021467   \n14          0.039962      0.006319                 0.996446  -93.681420   \n15          0.036143      0.003554                 1.000000  -96.445799   \n\n    cumulative_gain  \n0        950.373986  \n1        813.351515  \n2        714.763781  \n3        644.594550  \n4        585.072494  \n5        410.699240  \n6        318.391334  \n7        255.775553  \n8        175.490094  \n9        122.257643  \n10        86.146434  \n11        59.966148  \n12        39.878709  \n13        23.766072  \n14        10.716268  \n15         0.000000  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>group</th>\n      <th>cumulative_data_fraction</th>\n      <th>lower_threshold</th>\n      <th>lift</th>\n      <th>cumulative_lift</th>\n      <th>response_rate</th>\n      <th>score</th>\n      <th>cumulative_response_rate</th>\n      <th>cumulative_score</th>\n      <th>capture_rate</th>\n      <th>cumulative_capture_rate</th>\n      <th>gain</th>\n      <th>cumulative_gain</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td></td>\n      <td>1</td>\n      <td>0.010001</td>\n      <td>0.315606</td>\n      <td>10.503740</td>\n      <td>10.503740</td>\n      <td>0.379675</td>\n      <td>0.447135</td>\n      <td>0.379675</td>\n      <td>0.447135</td>\n      <td>0.105047</td>\n      <td>0.105047</td>\n      <td>950.373986</td>\n      <td>950.373986</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td></td>\n      <td>2</td>\n      <td>0.020002</td>\n      <td>0.231615</td>\n      <td>7.763290</td>\n      <td>9.133515</td>\n      <td>0.280617</td>\n      <td>0.268426</td>\n      <td>0.330146</td>\n      <td>0.357781</td>\n      <td>0.077640</td>\n      <td>0.182687</td>\n      <td>676.329044</td>\n      <td>813.351515</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td></td>\n      <td>3</td>\n      <td>0.030003</td>\n      <td>0.189186</td>\n      <td>6.175883</td>\n      <td>8.147638</td>\n      <td>0.223237</td>\n      <td>0.209056</td>\n      <td>0.294509</td>\n      <td>0.308206</td>\n      <td>0.061764</td>\n      <td>0.244451</td>\n      <td>517.588314</td>\n      <td>714.763781</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td></td>\n      <td>4</td>\n      <td>0.040001</td>\n      <td>0.160763</td>\n      <td>5.340267</td>\n      <td>7.445946</td>\n      <td>0.193033</td>\n      <td>0.174289</td>\n      <td>0.269146</td>\n      <td>0.274734</td>\n      <td>0.053392</td>\n      <td>0.297844</td>\n      <td>434.026745</td>\n      <td>644.594550</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td></td>\n      <td>5</td>\n      <td>0.050002</td>\n      <td>0.140680</td>\n      <td>4.470013</td>\n      <td>6.850725</td>\n      <td>0.161576</td>\n      <td>0.150204</td>\n      <td>0.247630</td>\n      <td>0.249826</td>\n      <td>0.044704</td>\n      <td>0.342548</td>\n      <td>347.001260</td>\n      <td>585.072494</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td></td>\n      <td>6</td>\n      <td>0.100001</td>\n      <td>0.087297</td>\n      <td>3.363160</td>\n      <td>5.106992</td>\n      <td>0.121567</td>\n      <td>0.109556</td>\n      <td>0.184600</td>\n      <td>0.179693</td>\n      <td>0.168154</td>\n      <td>0.510702</td>\n      <td>236.316030</td>\n      <td>410.699240</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td></td>\n      <td>7</td>\n      <td>0.150002</td>\n      <td>0.062777</td>\n      <td>2.337808</td>\n      <td>4.183913</td>\n      <td>0.084504</td>\n      <td>0.073795</td>\n      <td>0.151234</td>\n      <td>0.144393</td>\n      <td>0.116894</td>\n      <td>0.627597</td>\n      <td>133.780791</td>\n      <td>318.391334</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td></td>\n      <td>8</td>\n      <td>0.200001</td>\n      <td>0.048144</td>\n      <td>1.679211</td>\n      <td>3.557756</td>\n      <td>0.060698</td>\n      <td>0.054923</td>\n      <td>0.128601</td>\n      <td>0.122026</td>\n      <td>0.083959</td>\n      <td>0.711555</td>\n      <td>67.921061</td>\n      <td>255.775553</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td></td>\n      <td>9</td>\n      <td>0.300002</td>\n      <td>0.031478</td>\n      <td>1.149192</td>\n      <td>2.754901</td>\n      <td>0.041539</td>\n      <td>0.038923</td>\n      <td>0.099580</td>\n      <td>0.094325</td>\n      <td>0.114920</td>\n      <td>0.826475</td>\n      <td>14.919176</td>\n      <td>175.490094</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td></td>\n      <td>10</td>\n      <td>0.399999</td>\n      <td>0.021718</td>\n      <td>0.625557</td>\n      <td>2.222576</td>\n      <td>0.022612</td>\n      <td>0.026218</td>\n      <td>0.080339</td>\n      <td>0.077298</td>\n      <td>0.062554</td>\n      <td>0.889029</td>\n      <td>-37.444271</td>\n      <td>122.257643</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td></td>\n      <td>11</td>\n      <td>0.500000</td>\n      <td>0.015305</td>\n      <td>0.417026</td>\n      <td>1.861464</td>\n      <td>0.015074</td>\n      <td>0.018302</td>\n      <td>0.067286</td>\n      <td>0.065499</td>\n      <td>0.041703</td>\n      <td>0.930732</td>\n      <td>-58.297371</td>\n      <td>86.146434</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td></td>\n      <td>12</td>\n      <td>0.600001</td>\n      <td>0.010849</td>\n      <td>0.290655</td>\n      <td>1.599661</td>\n      <td>0.010506</td>\n      <td>0.012959</td>\n      <td>0.057822</td>\n      <td>0.056742</td>\n      <td>0.029066</td>\n      <td>0.959798</td>\n      <td>-70.934531</td>\n      <td>59.966148</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td></td>\n      <td>13</td>\n      <td>0.699998</td>\n      <td>0.007534</td>\n      <td>0.193512</td>\n      <td>1.398787</td>\n      <td>0.006995</td>\n      <td>0.009110</td>\n      <td>0.050561</td>\n      <td>0.049938</td>\n      <td>0.019351</td>\n      <td>0.979149</td>\n      <td>-80.648796</td>\n      <td>39.878709</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td></td>\n      <td>14</td>\n      <td>0.799999</td>\n      <td>0.004970</td>\n      <td>0.109785</td>\n      <td>1.237661</td>\n      <td>0.003968</td>\n      <td>0.006210</td>\n      <td>0.044737</td>\n      <td>0.044472</td>\n      <td>0.010979</td>\n      <td>0.990127</td>\n      <td>-89.021467</td>\n      <td>23.766072</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td></td>\n      <td>15</td>\n      <td>0.899999</td>\n      <td>0.002843</td>\n      <td>0.063186</td>\n      <td>1.107163</td>\n      <td>0.002284</td>\n      <td>0.003883</td>\n      <td>0.040020</td>\n      <td>0.039962</td>\n      <td>0.006319</td>\n      <td>0.996446</td>\n      <td>-93.681420</td>\n      <td>10.716268</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td></td>\n      <td>16</td>\n      <td>1.000000</td>\n      <td>0.000103</td>\n      <td>0.035542</td>\n      <td>1.000000</td>\n      <td>0.001285</td>\n      <td>0.001771</td>\n      <td>0.036147</td>\n      <td>0.036143</td>\n      <td>0.003554</td>\n      <td>1.000000</td>\n      <td>-96.445799</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"stream","text":"\n\nModelMetricsBinomialGLM: glm\n** Reported on validation data. **\n\nMSE: 0.03107511759141766\nRMSE: 0.17628135917168797\nLogLoss: 0.12274529844188314\nNull degrees of freedom: 74970\nResidual degrees of freedom: 74882\nNull deviance: 22974.597464485523\nResidual deviance: 18404.67553897284\nAIC: 18582.67553897284\nAUC: 0.8450464412102321\nAUCPR: 0.19801886666651378\nGini: 0.6900928824204642\n\nConfusion Matrix (Act/Pred) for max f1 @ threshold = 0.12627867037192236: \n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"            FALSE    TRUE   Error               Rate\n0  FALSE  68868.0  3445.0  0.0476   (3445.0/72313.0)\n1   TRUE   1649.0  1009.0  0.6204    (1649.0/2658.0)\n2  Total  70517.0  4454.0  0.0679   (5094.0/74971.0)","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>FALSE</th>\n      <th>TRUE</th>\n      <th>Error</th>\n      <th>Rate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>FALSE</td>\n      <td>68868.0</td>\n      <td>3445.0</td>\n      <td>0.0476</td>\n      <td>(3445.0/72313.0)</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>TRUE</td>\n      <td>1649.0</td>\n      <td>1009.0</td>\n      <td>0.6204</td>\n      <td>(1649.0/2658.0)</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Total</td>\n      <td>70517.0</td>\n      <td>4454.0</td>\n      <td>0.0679</td>\n      <td>(5094.0/74971.0)</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"stream","text":"\nMaximum Metrics: Maximum metrics at their respective thresholds\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"                         metric  threshold         value    idx\n0                        max f1   0.126279      0.283746  201.0\n1                        max f2   0.062995      0.373455  264.0\n2                  max f0point5   0.229837      0.290515  135.0\n3                  max accuracy   0.964445      0.964533    0.0\n4                 max precision   0.395160      0.398104   76.0\n5                    max recall   0.000762      1.000000  398.0\n6               max specificity   0.964445      0.999986    0.0\n7              max absolute_mcc   0.123640      0.260018  204.0\n8    max min_per_class_accuracy   0.038583      0.766742  300.0\n9   max mean_per_class_accuracy   0.032769      0.767428  311.0\n10                      max tns   0.964445  72312.000000    0.0\n11                      max fns   0.964445   2658.000000    0.0\n12                      max fps   0.000495  72313.000000  399.0\n13                      max tps   0.000762   2658.000000  398.0\n14                      max tnr   0.964445      0.999986    0.0\n15                      max fnr   0.964445      1.000000    0.0\n16                      max fpr   0.000495      1.000000  399.0\n17                      max tpr   0.000762      1.000000  398.0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>metric</th>\n      <th>threshold</th>\n      <th>value</th>\n      <th>idx</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>max f1</td>\n      <td>0.126279</td>\n      <td>0.283746</td>\n      <td>201.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>max f2</td>\n      <td>0.062995</td>\n      <td>0.373455</td>\n      <td>264.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>max f0point5</td>\n      <td>0.229837</td>\n      <td>0.290515</td>\n      <td>135.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>max accuracy</td>\n      <td>0.964445</td>\n      <td>0.964533</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>max precision</td>\n      <td>0.395160</td>\n      <td>0.398104</td>\n      <td>76.0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>max recall</td>\n      <td>0.000762</td>\n      <td>1.000000</td>\n      <td>398.0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>max specificity</td>\n      <td>0.964445</td>\n      <td>0.999986</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>max absolute_mcc</td>\n      <td>0.123640</td>\n      <td>0.260018</td>\n      <td>204.0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>max min_per_class_accuracy</td>\n      <td>0.038583</td>\n      <td>0.766742</td>\n      <td>300.0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>max mean_per_class_accuracy</td>\n      <td>0.032769</td>\n      <td>0.767428</td>\n      <td>311.0</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>max tns</td>\n      <td>0.964445</td>\n      <td>72312.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>max fns</td>\n      <td>0.964445</td>\n      <td>2658.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>max fps</td>\n      <td>0.000495</td>\n      <td>72313.000000</td>\n      <td>399.0</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>max tps</td>\n      <td>0.000762</td>\n      <td>2658.000000</td>\n      <td>398.0</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>max tnr</td>\n      <td>0.964445</td>\n      <td>0.999986</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>max fnr</td>\n      <td>0.964445</td>\n      <td>1.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>max fpr</td>\n      <td>0.000495</td>\n      <td>1.000000</td>\n      <td>399.0</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>max tpr</td>\n      <td>0.000762</td>\n      <td>1.000000</td>\n      <td>398.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"stream","text":"\nGains/Lift Table: Avg response rate:  3.55 %, avg score:  3.62 %\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"      group  cumulative_data_fraction  lower_threshold       lift  \\\n0         1                  0.010004         0.317794  10.417340   \n1         2                  0.020008         0.234316   8.273700   \n2         3                  0.030012         0.187723   6.430921   \n3         4                  0.040002         0.159223   4.481294   \n4         5                  0.050006         0.139193   4.287281   \n5         6                  0.100012         0.087251   3.197509   \n6         7                  0.150005         0.062508   2.325398   \n7         8                  0.200011         0.048269   1.722893   \n8         9                  0.300009         0.031184   1.124921   \n9        10                  0.400008         0.021592   0.665923   \n10       11                  0.500007         0.015227   0.470285   \n11       12                  0.600005         0.010764   0.331080   \n12       13                  0.700004         0.007518   0.158016   \n13       14                  0.800003         0.004933   0.142967   \n14       15                  0.900001         0.002824   0.045147   \n15       16                  1.000000         0.000123   0.048910   \n\n    cumulative_lift  response_rate     score  cumulative_response_rate  \\\n0         10.417340       0.369333  0.455618                  0.369333   \n1          9.345520       0.293333  0.270835                  0.331333   \n2          8.373987       0.228000  0.208398                  0.296889   \n3          7.401787       0.158879  0.172164                  0.262421   \n4          6.778720       0.152000  0.149074                  0.240331   \n5          4.988115       0.113364  0.109587                  0.176847   \n6          4.100700       0.082444  0.073822                  0.145385   \n7          3.506209       0.061083  0.054932                  0.124308   \n8          2.712481       0.039883  0.038895                  0.096168   \n9          2.200859       0.023609  0.026053                  0.078029   \n10         1.854753       0.016673  0.018210                  0.065758   \n11         1.600813       0.011738  0.012873                  0.056755   \n12         1.394703       0.005602  0.009061                  0.049447   \n13         1.238239       0.005069  0.006183                  0.043900   \n14         1.105675       0.001601  0.003837                  0.039200   \n15         1.000000       0.001734  0.001748                  0.035454   \n\n    cumulative_score  capture_rate  cumulative_capture_rate        gain  \\\n0           0.455618      0.104214                 0.104214  941.733985   \n1           0.363227      0.082769                 0.186983  727.369952   \n2           0.311617      0.064334                 0.251317  543.092099   \n3           0.276789      0.044771                 0.296087  348.129435   \n4           0.251239      0.042889                 0.338977  328.728066   \n5           0.180413      0.159895                 0.498871  219.750930   \n6           0.144889      0.116253                 0.615124  132.539762   \n7           0.122398      0.086155                 0.701279   72.289325   \n8           0.094565      0.112491                 0.813770   12.492095   \n9           0.077438      0.066591                 0.880361  -33.407690   \n10          0.065592      0.047028                 0.927389  -52.971532   \n11          0.056806      0.033108                 0.960497  -66.891959   \n12          0.049985      0.015801                 0.976298  -84.198435   \n13          0.044510      0.014296                 0.990594  -85.703346   \n14          0.039991      0.004515                 0.995109  -95.485267   \n15          0.036167      0.004891                 1.000000  -95.109039   \n\n    cumulative_gain  \n0        941.733985  \n1        834.551969  \n2        737.398679  \n3        640.178718  \n4        577.871972  \n5        398.811451  \n6        310.070006  \n7        250.620872  \n8        171.248142  \n9        120.085890  \n10        85.475329  \n11        60.081346  \n12        39.470341  \n13        23.823891  \n14        10.567514  \n15         0.000000  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>group</th>\n      <th>cumulative_data_fraction</th>\n      <th>lower_threshold</th>\n      <th>lift</th>\n      <th>cumulative_lift</th>\n      <th>response_rate</th>\n      <th>score</th>\n      <th>cumulative_response_rate</th>\n      <th>cumulative_score</th>\n      <th>capture_rate</th>\n      <th>cumulative_capture_rate</th>\n      <th>gain</th>\n      <th>cumulative_gain</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td></td>\n      <td>1</td>\n      <td>0.010004</td>\n      <td>0.317794</td>\n      <td>10.417340</td>\n      <td>10.417340</td>\n      <td>0.369333</td>\n      <td>0.455618</td>\n      <td>0.369333</td>\n      <td>0.455618</td>\n      <td>0.104214</td>\n      <td>0.104214</td>\n      <td>941.733985</td>\n      <td>941.733985</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td></td>\n      <td>2</td>\n      <td>0.020008</td>\n      <td>0.234316</td>\n      <td>8.273700</td>\n      <td>9.345520</td>\n      <td>0.293333</td>\n      <td>0.270835</td>\n      <td>0.331333</td>\n      <td>0.363227</td>\n      <td>0.082769</td>\n      <td>0.186983</td>\n      <td>727.369952</td>\n      <td>834.551969</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td></td>\n      <td>3</td>\n      <td>0.030012</td>\n      <td>0.187723</td>\n      <td>6.430921</td>\n      <td>8.373987</td>\n      <td>0.228000</td>\n      <td>0.208398</td>\n      <td>0.296889</td>\n      <td>0.311617</td>\n      <td>0.064334</td>\n      <td>0.251317</td>\n      <td>543.092099</td>\n      <td>737.398679</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td></td>\n      <td>4</td>\n      <td>0.040002</td>\n      <td>0.159223</td>\n      <td>4.481294</td>\n      <td>7.401787</td>\n      <td>0.158879</td>\n      <td>0.172164</td>\n      <td>0.262421</td>\n      <td>0.276789</td>\n      <td>0.044771</td>\n      <td>0.296087</td>\n      <td>348.129435</td>\n      <td>640.178718</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td></td>\n      <td>5</td>\n      <td>0.050006</td>\n      <td>0.139193</td>\n      <td>4.287281</td>\n      <td>6.778720</td>\n      <td>0.152000</td>\n      <td>0.149074</td>\n      <td>0.240331</td>\n      <td>0.251239</td>\n      <td>0.042889</td>\n      <td>0.338977</td>\n      <td>328.728066</td>\n      <td>577.871972</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td></td>\n      <td>6</td>\n      <td>0.100012</td>\n      <td>0.087251</td>\n      <td>3.197509</td>\n      <td>4.988115</td>\n      <td>0.113364</td>\n      <td>0.109587</td>\n      <td>0.176847</td>\n      <td>0.180413</td>\n      <td>0.159895</td>\n      <td>0.498871</td>\n      <td>219.750930</td>\n      <td>398.811451</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td></td>\n      <td>7</td>\n      <td>0.150005</td>\n      <td>0.062508</td>\n      <td>2.325398</td>\n      <td>4.100700</td>\n      <td>0.082444</td>\n      <td>0.073822</td>\n      <td>0.145385</td>\n      <td>0.144889</td>\n      <td>0.116253</td>\n      <td>0.615124</td>\n      <td>132.539762</td>\n      <td>310.070006</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td></td>\n      <td>8</td>\n      <td>0.200011</td>\n      <td>0.048269</td>\n      <td>1.722893</td>\n      <td>3.506209</td>\n      <td>0.061083</td>\n      <td>0.054932</td>\n      <td>0.124308</td>\n      <td>0.122398</td>\n      <td>0.086155</td>\n      <td>0.701279</td>\n      <td>72.289325</td>\n      <td>250.620872</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td></td>\n      <td>9</td>\n      <td>0.300009</td>\n      <td>0.031184</td>\n      <td>1.124921</td>\n      <td>2.712481</td>\n      <td>0.039883</td>\n      <td>0.038895</td>\n      <td>0.096168</td>\n      <td>0.094565</td>\n      <td>0.112491</td>\n      <td>0.813770</td>\n      <td>12.492095</td>\n      <td>171.248142</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td></td>\n      <td>10</td>\n      <td>0.400008</td>\n      <td>0.021592</td>\n      <td>0.665923</td>\n      <td>2.200859</td>\n      <td>0.023609</td>\n      <td>0.026053</td>\n      <td>0.078029</td>\n      <td>0.077438</td>\n      <td>0.066591</td>\n      <td>0.880361</td>\n      <td>-33.407690</td>\n      <td>120.085890</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td></td>\n      <td>11</td>\n      <td>0.500007</td>\n      <td>0.015227</td>\n      <td>0.470285</td>\n      <td>1.854753</td>\n      <td>0.016673</td>\n      <td>0.018210</td>\n      <td>0.065758</td>\n      <td>0.065592</td>\n      <td>0.047028</td>\n      <td>0.927389</td>\n      <td>-52.971532</td>\n      <td>85.475329</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td></td>\n      <td>12</td>\n      <td>0.600005</td>\n      <td>0.010764</td>\n      <td>0.331080</td>\n      <td>1.600813</td>\n      <td>0.011738</td>\n      <td>0.012873</td>\n      <td>0.056755</td>\n      <td>0.056806</td>\n      <td>0.033108</td>\n      <td>0.960497</td>\n      <td>-66.891959</td>\n      <td>60.081346</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td></td>\n      <td>13</td>\n      <td>0.700004</td>\n      <td>0.007518</td>\n      <td>0.158016</td>\n      <td>1.394703</td>\n      <td>0.005602</td>\n      <td>0.009061</td>\n      <td>0.049447</td>\n      <td>0.049985</td>\n      <td>0.015801</td>\n      <td>0.976298</td>\n      <td>-84.198435</td>\n      <td>39.470341</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td></td>\n      <td>14</td>\n      <td>0.800003</td>\n      <td>0.004933</td>\n      <td>0.142967</td>\n      <td>1.238239</td>\n      <td>0.005069</td>\n      <td>0.006183</td>\n      <td>0.043900</td>\n      <td>0.044510</td>\n      <td>0.014296</td>\n      <td>0.990594</td>\n      <td>-85.703346</td>\n      <td>23.823891</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td></td>\n      <td>15</td>\n      <td>0.900001</td>\n      <td>0.002824</td>\n      <td>0.045147</td>\n      <td>1.105675</td>\n      <td>0.001601</td>\n      <td>0.003837</td>\n      <td>0.039200</td>\n      <td>0.039991</td>\n      <td>0.004515</td>\n      <td>0.995109</td>\n      <td>-95.485267</td>\n      <td>10.567514</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td></td>\n      <td>16</td>\n      <td>1.000000</td>\n      <td>0.000123</td>\n      <td>0.048910</td>\n      <td>1.000000</td>\n      <td>0.001734</td>\n      <td>0.001748</td>\n      <td>0.035454</td>\n      <td>0.036167</td>\n      <td>0.004891</td>\n      <td>1.000000</td>\n      <td>-95.109039</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"stream","text":"\n\nScoring History: \n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"               timestamp    duration  iterations  negative_log_likelihood  \\\n0    2020-06-27 21:13:28   0.000 sec           0             54466.065752   \n1    2020-06-27 21:13:30   1.168 sec           1             50061.613368   \n2    2020-06-27 21:13:30   1.611 sec           2             43570.207802   \n3    2020-06-27 21:13:30   1.999 sec           3             43215.311321   \n4    2020-06-27 21:13:31   2.393 sec           4             43195.943426   \n5    2020-06-27 21:13:31   2.819 sec           5             43195.779638   \n6    2020-06-27 21:13:32   3.761 sec           6             43182.000891   \n7    2020-06-27 21:13:33   4.170 sec           7             43181.213749   \n\n   objective  \n0   0.155498  \n1   0.144447  \n2   0.125483  \n3   0.124491  \n4   0.124463  \n5   0.124463  \n6   0.124441  \n7   0.124441  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>timestamp</th>\n      <th>duration</th>\n      <th>iterations</th>\n      <th>negative_log_likelihood</th>\n      <th>objective</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td></td>\n      <td>2020-06-27 21:13:28</td>\n      <td>0.000 sec</td>\n      <td>0</td>\n      <td>54466.065752</td>\n      <td>0.155498</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td></td>\n      <td>2020-06-27 21:13:30</td>\n      <td>1.168 sec</td>\n      <td>1</td>\n      <td>50061.613368</td>\n      <td>0.144447</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td></td>\n      <td>2020-06-27 21:13:30</td>\n      <td>1.611 sec</td>\n      <td>2</td>\n      <td>43570.207802</td>\n      <td>0.125483</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td></td>\n      <td>2020-06-27 21:13:30</td>\n      <td>1.999 sec</td>\n      <td>3</td>\n      <td>43215.311321</td>\n      <td>0.124491</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td></td>\n      <td>2020-06-27 21:13:31</td>\n      <td>2.393 sec</td>\n      <td>4</td>\n      <td>43195.943426</td>\n      <td>0.124463</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td></td>\n      <td>2020-06-27 21:13:31</td>\n      <td>2.819 sec</td>\n      <td>5</td>\n      <td>43195.779638</td>\n      <td>0.124463</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td></td>\n      <td>2020-06-27 21:13:32</td>\n      <td>3.761 sec</td>\n      <td>6</td>\n      <td>43182.000891</td>\n      <td>0.124441</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td></td>\n      <td>2020-06-27 21:13:33</td>\n      <td>4.170 sec</td>\n      <td>7</td>\n      <td>43181.213749</td>\n      <td>0.124441</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"execute_result","execution_count":14,"data":{"text/plain":""},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"From the summary results, we can see the GLM performance. We will focus on the Area Under the Curve (AUC), and since we have a very imbalanced dataset, we will be looking at the F1 score. Additionally, we will also take a quick look at the misclassification error and logloss.\n\nFrom the report, we can look at the metrics on the training and validation data, and we see that the training AUC was 0.8502 while the validation AUC was 0.8450\n\n"},{"metadata":{},"cell_type":"markdown","source":"From the report, we can also see the max F1 score as well as all the metrics for our model with their respective thresholds. For the default GLM, we obtained a training F1 score of 0.2881 and a validation F1 score of 0.2827."},{"metadata":{},"cell_type":"markdown","source":"We can plot the Scoring history for any of our models, as shown below:"},{"metadata":{"trusted":true},"cell_type":"code","source":"glm.plot(metric='negative_log_likelihood')","execution_count":15,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"metadata":{},"cell_type":"markdown","source":"We can see from the plot above that after four iterations, the score no longer improves; therefore, if we needed to set a number of iterations as a future parameter, we can choose 4, as the scores don't really improve after that point. We can also use the default number of iterations and use early stopping; that way, the model will stop training when it is no longer improving. We will use early stopping when we start tuning our models.\n\nWe can also generate a variable importance plot to see how each of our features contribute to the linear model."},{"metadata":{"trusted":true},"cell_type":"code","source":"glm.varimp_plot()","execution_count":16,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 1008x720 with 1 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAAA/0AAAJTCAYAAABaXnZKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nOzde9yt9Zz/8de7NqNEwjCNadokOpdEFCkSKXJo1NYMNcj5OA5R2BhqFBXJKTo4bCGZlEODIvJD2O3dOVsb5VDJRAeZdp/fH9d31dVq3Ye99123ltfz8bgfa63v9T1d11qbPtf3cKWqkCRJkiRJ42eV2e6AJEmSJEm6fRj0S5IkSZI0pgz6JUmSJEkaUwb9kiRJkiSNKYN+SZIkSZLGlEG/JEmSJEljyqBfkqQxk2T7JJVk/krWs3erZ+/lKHNMKzN3ZdqWJEkzw6BfkqQZkuQzLeB9yTTy/k/L+/Q7om/jondD4/TZ7svtbUVuuvwtSHJ6uy7bT5LnmOFrl86Tk3wgycIkf0jy5yQXJjksyf2naPchST6Y5IIk1yS5tpU9MslDV+J87p1kv3Zelyf5S5I/JTk3ydFJnpokQ2Wm/e8gydyWt1q/7zFBviRZ0su7/Yqek6S/Lgb9kiTNnI+21xdOlqmNgj8B+A1w8u3Qjx8CGwJH3A51S3dWfwd8FdgXuAL4OPAh4M/Aq4Czk6w/qmCSVwLnAS8Bfgt8GDgSuAx4MXBuy7NckjwNWAIcCKwLfAV4L93/llwMPB04Cfjc8tY9wo3A3YF5Exx/AvCglk/SGJkz2x2QJGlcVNXpSS4CHpZky6r6yQRZnw8EOLqqZvw/sKvqOuCCma5XupNbBhwAHFlVfxgkJlmFLoB/EfA+4Kn9QkmeCxwOXAU8o6q+M3T8scCXgMOT/G9VHTedziR5PHACXZD9QuATVXXTUJ67Af8K7LQc5zmRH9PdWHght9yg7HshcAPwLWDnGWhP0l8JR/olSZpZH2uvI0f7k6wK7AMUcFRLe3qSTyW5qE0ZvibJj5O8sgUkw3UMpi4/KMkrkixKcv1gqu9Ea/qTPDzJ4UnOTnJVm9p8cZL3JllrspNKskuSM1v//pDkCxONik5Sx9at3G/bFOZfJflIkn9cnnomqPvmqfBJnpjkjHYdr2hTpO/V8j0sycntHK5JclJG7D/Qm0L+d0n+M8klSW5o05/fluSuE/TjCUm+1ru+FyU5KMmak7Rx1yRvbVPFb2jf7+nA0S3r0b0p1zfvl5DkH1u57/Wu6a/TLTPZcER7g2nex7T3n01yZevnWUl2neT67pHkm73zWppkQZKtRuSdl+S03DJ9/vwkByT5u4nqvyNU1f9V1bv6AX9Lvwl4R/u4ff9Yuqnwh7WPzxkO+Fv5M4C92sdDM8H0+aF6V6WbLTAHeGVVHTUc8Le6/1xVRwHPmarOabiR7je1VZIthvpzX7pZBSfQ3dyQNEYM+iVJmlnHAn8BnpNk9RHHdwYeAHyjqi5paQcBWwI/AD4AfBJYg2508dhJ2joceCewuL3/3hR9eyGwJ3Ah3X/8f5huicFrge9NEqw8k24k89LWzveBZwH/L9Ncy5xkn9a/nYHT6AKps4AXAGcl+efp1DMNTwNOoZu+/WG6KdJ7A19K8ijgu3SB1sdbf54KnDLq5krzOeDfgS/TLZcoYD5wQnKbddYvAv4H2Jbueh1GF0C9EThzcONhhBOAlwJntjKLgWOA/27H/xt4e+/vf1v6dsB+7fMJwKHA/wN2B36UZPMJ2luXbgnIXLrf2vHAJsB/J9lh6JyS5Bjgs8BmwBdbO2cAjwV2Hcr/ceAzwINb3g+2a/BO4GtJ5gzlnz/qBtUs+Et7HZ55szuwFvDDqvr6RIWr6mvAj4B7tzJT2R5YH/gV8ImpMs/gjKCj6H7DLxhKfx5wV265aSlpjDi9X5KkGVRVVyT5EvDs9nfMUJbBDID+9NpdqmpJP1MLQo8GnpvkiKr6wYjmtgQe1rt5MJUDgZdV1bKhtp5PFwy8FPivEeWeCjy1qk7ulXkVXYB6JN1a4AkleQjwEWAp8Liquqx37PF0gfLhwDOmeR6TeRrwhKr6dqt/FeDrwI5066X3rapP99r/OF1Q/1RuCbL7NgQ2HowOJ9mf7qbFrnTTrj/Z0tcF3g9cAzyyqm5eXpHkSLq14O+hW08+bF1gk6q6sp/Y7insBnypqo4ZUe5bwP2r6k9D5Tanu6FxEKOnaW8PzK+qt/fKfAb4GvD6dn4DL6QLCH8EPLGqru6VWRW4X+/z3nTX8kRgr6q6vndsPvA24GV03/VM2DsTbza3xQTpE3l+e/3aUPpj2us3plHH/wCPoLvpc/QUebdtr98e/vd4e6qqnyf5FrBXktf3vqMX0N0g+za3vSEg6U7OkX5JkmbeIKC/1X88J1kbeArwO3oB5nDA39Ju4pbg6EkTtPOe5Qj4qapfTBBgfAL44yTtfKsf8DdH0G1A9vgW8E7mJcBdgFf1A/7Wp2/RbVT21OlMi56GBYOAv9V/Ey0wB87pB/zNYP31REHiO/vTwavqz8Cb2sd/7+X7V7qR0iP6AX+zP/An4N8mmOL+luGAfzqq6vLhgL+ln013Q2CHJHcZUfQXwH8Olfk68EvgkUN5X9FeX9QP+FuZZVX1m17Sq+hGyv+9H/A37wR+zy3T4AeOYMU3nXwe3Y2EUX8TzXK4jSSPaGX+RLfmv2/t9vqraVQ1yDOd5Sr/0F4vG3WwzYAY/ptopsjy+hhwL+BfWluPBTYAjqqqmqE2JP0VcaRfkqSZ9y26gHjbJBtW1fktfR+6/+89pqr+b5A5yX3oRlifQrd79t2H6nvABO38cHk61QLAF9FN8d8IWJNbDwBM1M63hxOqalmS7wLrAQ+jCyQn8uj2+rgWYA27H7Aq8BC6zcZWxlkj0n7dXkfVPQi6/mmC+m5z7nRT22+kO++BLdvrt4YzV9UfkvyUbjr+BsDZQ1mW63vsS7IL3e7xWwH35bb/bXdfuiUcfQsnuPnzK275rkhyd7pp/7+rqp9O0Y/V6QLtK4FXD618GLiBLsC/WbvZsdw3PJodqur0CfpzDN1NgUm1WShfprspteeIG3CDE5lOMDyTed82Iu0YblnasTJOpLvmL6S76bUv8H/cdlaSpDFh0C9J0gyrqkpyFN10+hcA/9HWf/87vQ38ANro3Y+AB9IFf8fRrYG+kW407lV0jxob5bfL2bXj6abQ/5xupsFv6QIxgFdP0s7vpmj/NpvUDblPe339FPnWmOL4dFw9Iu3GaRwbNSIOI8693fD4Pb2p7dxyDYYDbIbSR43WLu/3CNz8GLnDgT/QTS3/JXAd3W/s6XRB+KjvdKLA8UZufRNo0NeRo9FD1qILZP+e0QHrX510G1GeRrcOf8+qOmlEtsH3Np09JwY3jib6DYyqd+SNtqq6+a5Ju7m27ah8K6Kq/pLkOOC1SR5NtwfBSVV1+Uy1Iemvi0G/JEm3j6PpdgR/bpI30W16th7dVPmf9fK9gC7gf3tVze9X0P6D/FWTtDHtqbhtl/Vn0K1NfsrQTINVgDdMUvz+E6QPpiiPCqb7BsfXrKo/TqO7f03uTxdM36ytZb8P3ZKIgcE5/gNw7oh61h7Kd7MVmVLdNsR7O90Ngy2HptkPfjsra3BzYKIZIH2D8/ppVW05ac6/Au3pBt+k+x7/papG7ecA3caP+9DtCbH/FNXu2F6n2lCzn2f7JKuM2rn/dvYxug08PwfcjdGP8JM0JlzTL0nS7aCqfke3Vn3wKKzB+v7h/7h+cHs9YUQ1j5vBLg3aOakf8DePBFabpOxt+tEC38EmZ5NO/abbUR66Gx93NqO+g8fSDZz0z3vwfvvhzG02xxbAn4Hzh49PYjAFf9URx+5LNxJ/5oiAfw1uWW6wwqrqWuAc4P5JHjZF3mvobnZsnOTeK9v27SnJpsDpdCP8z5ok4Af4At3Nj0cmeeIkdT6R7t/RH1qZqZwO/AxYh+6mwh2q7TtxBt3shKVMb6NCSXdSBv2SJN1+Bo+/+g+6UfYr6dbT9i1tr9v3E1uQ9SZmzkTt3I/usWqTefyIZ7i/nG7mwmlVNdl6fug2afs/umeYP2T4YLrn1P+13hB4S5K1Bh+S3I1u2Qbceof2T9Gd4yuSPJhbeydwT+BTVXUD0/f79jpqavnldFP5H96C/EH/7kI35f++y9HOZN7fXj+S5FbLOJKs0janHHgf3WaGnxi16VyStZJsOZR23yQbtOfE3+7a8+lPA+4B7DZig8pbaTNT/qN9/EyS20yzT7IN3WMKAV49anPFEfUuo9uL4UbgA0n2GfXYyPZ9jnr050zYl+5/l545CzMNJN2BnN4vSdLt51TgEm7ZEf2IqvrLUJ7j6Na6H9aekX4x3fO7d6V7zvkeM9SXH9FNKX5mkjPppi3fn+6Rbhdyy2Z3o3wZODHJiXSjk5vTbTp4Fd1j/iZVVRck+Xe6pwScm+RrwEV06+j/mW7k/Aq6Te7+2pxP1+cv0AX1u9Hd7DiFW54KQFUtTfJquhsoP0nyObpzehzd5ngXAG9czra/TxfYv7qNng/2F/hAVV2d5P3AfsDiJP9NF3DvQDeCfVp7v7KOopvR8Vzg4tbOFXQ71D+e7judD1BVn0jycLrfxJIkgycC3JtuCct2dDdKXtyr/+V0ewC8fVDP7aXdvPlm6883gUdPsAzisKq6ed+Ddl73onvk4hlJTqfbFLKAh9Nd55voAv7jRtQ3UlV9M8nuwLF01/GtSb5N92/xbnTXeEe6JQiLGL0XwwZt08JRfllVb52k/QvofpeSxpxBvyRJt5O2od/HueXxaB8bkefXbZT7ILrg6kl0/yH+UroptzMS9LfN557W+vIU4JV0G7Qd1dLOm6T4F+mWJewP7EIX/H4ReFNVXTTN9j+V5Gy6UdMdgJ2Aa+kCnC/QbTL41+jZwFvoHjX3j3TXbD5w0PBa/Ko6MsnPgNcBz6Ibof0VcDDw7n4gOR1t1/9n0QXF+3DLUx0+RbeG/i10AfgL6J7KcDXdhn4H0AXRK62d4/OSnEo3Mvxsus0Bf0M3PfykofwvS/JVusB+R7olCFfRBf8Ht77PljXpAn6AJ7S/UY5hKMCuqvcl+QrdHhuPBx7VDl0KfAQ4fMSjGqdUVf+dZD26a7sz3b+ve9EtBbmU7ubS54GvTDAaf38mfkrB2cCEQb+kvx3xcZySJEm31kZzH9ffRV2SpDsj1/RLkiRJkjSmDPolSZIkSRpTBv2SJEmSJI0p1/RLkiRJkjSm3L1fuhM49thj63nPm2hzXkmSJEli5OazTu+X7gSuvfba2e6CJEmSpDshg35JkiRJksaUQb8kSZIkSWPKoF+SJEmSpDFl0C9JkiRJ0pgy6JckSZIkaUwZ9EuSJEmSNKYM+iVJkiRJGlMG/ZIkSZIkjSmDfkmSJEmSxpRBvyRJkiRJY8qgX5IkSZKkMWXQL0mSJEnSmDLolyRJkiRpTBn0S5IkSZI0pgz6JUmSJEkaUwb9kiRJkiSNKYN+SZIkSZLGlEG/JEmSJEljyqBfkiRJkqQxZdAvSZIkSdKYMuiXJEmSJGlMGfRLkiRJkjSmDPolSZIkSRpTBv2SJEmSJI0pg35JkiRJksaUQb8kSZIkSWPKoF+SJEmSpDFl0C9JkiRJ0piaM9sdkDS1xZddzdz9TpntbkiSJEkClh60y2x3Ydoc6ZckSZIkaUwZ9EuSJEmSNKYM+iVJkiRJGlMG/ZIkSZIkjSmDfkmSJEmSxpRBvyRJkiRJY8qgX5IkSZKkMWXQL0mSJEnSmDLolyRJkiRpTBn0S5IkSZI0pgz6JUmSJEkaUwb9kiRJkiSNKYN+SZIkSZLGlEG/JEmSJEljyqBfkiRJkqQxZdAvSZIkSdKYMuiXJEmSJGlMzUrQn2T/JOcmWZRkYZKtk5ye5ML2eWGSL7S885Nc1tLOSzKvpV+S5KFD9R6W5A1Jtk9yci995yRnJTk/yQVJDhlR9+DvXq381Ul+2s8/yfnsneSmJJv10s5JMrf3+WFJKsmThspWkk/2Ps9JcsWg/63uK4b6uNFQHa9Kcljv80eSfKP3+RVJ3t/eLxuqa7+WfnqSrYbqvdV17KXv2q7N2e07edEE1/Og3jldmeTAoXoG3/nZSX6UZIvesTWSfCjJktbWj5O8sHd84yTfSnJRkouTvCVJRlyzc5N8IcnqQ22fnWTBUNoxrf9/1z7fN8nS9n5uknN6eV+Y5CdJ1hqqY36S65Lcr5d2zVCeZ7TvfYPhaytJkiRJM+kOD/qTPBrYFdiyqjYDdgR+1Q7vVVVbtL/de8UOraotgN2AjyS5C/BZYM9evasAuwPHD7W3CXAE8K9VtSGwCfDz4bp7f//b0s+oqocBDwN2TbLtFKd2KbD/JMfnAd9tr33XApskWa19fiJw2VCe44f6eN7Q8TOBbXqftwDWTLJq+7wN8L32/vqhug6a4rxupV37jwJPrarN6a7P6b0s/eu5X0vbCbgQePYgMO/Zq9VzJHBwL/0o4A/A+u17eDJw79aH1YCTgIOq6iHA5u0cX9orP7hmGwN/AfboncOGdL/97ZLcfag/y4B/n+Ia/BvwCmCnqvrDiCxXAv8xSRWD38Kek+SRJEmSpJU2GyP9awNXVtUNAFV1ZVX9ejoFq+pi4DpgLWABtw6atgOWVtUvhoq9AXhXVV3Q6rixqo6cbmer6npgIfCAKbKeDGw8PPsAoAW6uwN7AzsludtQlq8Cu7T38+jObXn8FHhIktWSrEl3jRYCm7bj29DdGJgJ9wDmAL8HqKobqurCKcrMAw4Hfgk8aoI836dd4yTrAY8EDqiqm1o7V1TVf7W8zwG+V1WntmPXAS8H9huuNMkc4O50NxDolf8kcCrwtKEihwGvaeVuI8mzWzs7VdWVE5zLJ4A9ktx7RPk1gG2B5zNF0J9k33QzVM5adt3Vk2WVJEmSpJFmI+g/FVinTcs+Msnjesc+3ZsafvBwwSRbAhdX1eVVtQi4Kcnm7fCejA6WNwF+PEl/XtNr87QRba4FrA98Z4rzugl4D/DmEce2BS6pqiV0o+JPGTr+WWDPdjNgM+AHQ8f3GJqSv1r/YFXdSBfkP4IuqP4B8P+AbZL8I5CqGsymWG2orj1YDlV1Fd0o+y+SLEiyV5tlMdC/nk9qfX0C3U2RBdx2psPAk4EvtfcbA2cPAv4RNmboO23Xdo0k92xJeyRZSDdr4t7Al3vZ96CbETKqP7+kG4X/txHtrks3a2SnqvrtBH0DuIYu8H/ViGNPB75WVRcBV7Xf9EhV9dGq2qqqtlp19TUnaU6SJEmSRrvDg/6qugZ4OLAvcAVwfJK92+H+9P7X94q9JsmFdMHs/F76ArpgeQ7d1P/Pr0CX+tPRd+ilPzbJIuC3wMlTBHkDnwEeleSBQ+nz6AJ72uutAs12A2NuS//KiHqHp/dfPyLP9+hG9LehGzX/fnu/Lbce5R+e3n/8bauaXFW9gC6Q/yHwOroAd6B/Pb9Ot5TjtDYafwLwjN6yA+hu9FwKvBH4wKj20u0BsTDJYEZIgJqoe+31+LYk5B+AxcDrW12PAK5oM0K+CWw5vC4feHfLP/zv4wq6mwLPnqDtvvcDz+vdhBiY9LcgSZIkSTNpVjbyq6plVXV6Vb2Nblr2s6YocmhVPZRuhPa43vT4BXQB2I7Aoqq6fETZc+luMiyvM9qeA5sCL+lvMjeRNuL+XroAFoAW4D4LeGvbFO4DwM5J7jFU/CTgEJZ/av/AYF3/o+kC/vOBjbj1ev4ZU1WLq+pQuj0IJvv+5gE7tnP/MXAfoH9zZS/ggXQ3TD7Y0s4DNh/MIKiqd7UAfhBAnwsMbzr4IOCaqvrTUD+LbpR/u15/Nmj9WdLqfNZQmZ/RzZwYDu6vA3YGXpxkr0nOmbY3xGfo7TOQ5D7A44GjWvuvp5uRMLzPgSRJkiTNiNnYyO+hSdbvJW0BDK/DH6mqvgicBTyvfV5Ct7b8ICYOlg8G3pzkIa39VZK8drr9bdOwD6QXyE/hGLqbEH/fPu9IN1V9naqaW1Xr0o14P32o3CeAd1TV4un2bciZdFP7/74tfyi6kendmLn1/INd9bfvJU34/bVR7scA/9zOfS7wMm470+H/gAPoZkls2ILus4D/HMwKaDd6BsHxp4HHJNmxHVuNbmT9PRN0+zHAknYT4V+AzXr92W24P8276GYx3EpVXUG3FOHdaU9iSPLyJC8fUcf7gBfR7YEA3b4Ox1XVuq39dYBLWv8kSZIkacbNxkj/GsCx6R71tohuNHp+O9Zf0/+NCcq/A3htbx35AmAD4MRRmdvU+VcDC5KcD5xDt5ngQH8N+sL0HrPX82G6nd6Hp+2Pau8vdAHo4JFt80b07QS6zeT65S6tqsMnqHZ4Tf82AG3N+qD8H+iC/HN75b7f+nF2L214TX9/9/5Tklza/gZLJZ7QS7uUbrf+N6Q9XhF4O90GhaM8E/jWYNPG5r+Bp6U9Fq/X/+vpZkkMAu0X0M0K+FmSHwPfoN14aXl3Aw5oyz4WAz+iW28/fM0WtT6/k260/7Kq6j8d4TvARkn6vwmq6lzgJ6NOqqouodsA8BNJtqb7/f1+RL4r6b77wblO67cgSZIkSTMl3YCwpBWV5GTgme2Gz+3iJfsfWF9dttntVb0kSZKk5bD0oF2mznTHG7lseORjySRNX1XtOtt9kCRJkqRRDPqXQ5J9uO1j2L5XVS+bjf5IkiRJkjQZg/7lUFVHA0fPdj8kSZIkSZqOWXlknyRJkiRJuv0Z9EuSJEmSNKYM+iVJkiRJGlMG/ZIkSZIkjSmDfkmSJEmSxpRBvyRJkiRJY8qgX5IkSZKkMWXQL0mSJEnSmDLolyRJkiRpTM2Z7Q5ImtqmD1iTD710l9nuhiRJkqQ7GUf6JUmSJEkaUwb9kiRJkiSNKYN+SZIkSZLGlEG/JEmSJEljyqBfkiRJkqQxZdAvSZIkSdKYMuiXJEmSJGlMGfRLkiRJkjSmDPolSZIkSRpTc2a7A5Kmtviyq5m73ymz3Q1JkiTdAZYetMtsd0FjxJF+SZIkSZLGlEG/JEmSJEljyqBfkiRJkqQxZdAvSZIkSdKYMuiXJEmSJGlMGfRLkiRJkjSmDPolSZIkSRpTBv2SJEmSJI0pg35JkiRJksaUQb8kSZIkSWPKoF+SJEmSpDFl0C9JkiRJ0pgy6JckSZIkaUwZ9EuSJEmSNKYM+iVJkiRJGlMG/ZIkSZIkjSmDfkmSJEmSxtS0gv4k+yc5N8miJAuTbJ3k9CQXts8Lk3yh5Z2f5LKWdl6SeS39kiQPHar3sCRvSLJ9kpN76TsnOSvJ+UkuSHLIiLoHf/dq5a9O8tN+/knOZ+8kNyXZrJd2TpK5vc8PS1JJnjRUtpJ8svd5TpIrBv1vdV8x1MeNRvRhaZL7tvfLWr5zknw+yerTaaulPb19LxckWZzk6b1jx7TrvjDJ2UmeMFTXu5Nc3Ovn/kN9fEbrwwa9tLkt7RW9tCOS7N37/LrWn3Nau89t6acn2WqornOG2jy8fcer9NLun+TkVtd5Sb7SK3/90LUetLW0XY+F7XW3lT23dj13b+/v3X5v+4z4bivJe4eux/yhPGcnWTBcVpIkSZJm0pRBf5JHA7sCW1bVZsCOwK/a4b2qaov2t3uv2KFVtQWwG/CRJHcBPgvs2at3FWB34Pih9jYBjgD+tao2BDYBfj5cd+/vf1v6GVX1MOBhwK5Jtp3i1C4F9p/k+Dzgu+2171pgkySrtc9PBC4bynP8UB/Pm6Iv17d8mwB/AV48nbaSbA4cAuxWVRsATwMO6d/MAF7fvotXAx/upf8n8I/Apu34Y4G7THAN9hxKvxx4VZK7Dp9Ikhe3fj6ync92QKY4/0HZVYBn0P2+tusdegfwP1W1eVVtBOzXO7Zk6Fof1zu2Qzu33YH3r+y59fq5JvB14KNVdfSILDcAzxzc1BlRfkO6f3vbJbn7RO1IkiRJ0sqazkj/2sCVVXUDQFVdWVW/nk7lVXUxcB2wFrCAWwdY2wFLq+oXQ8XeALyrqi5oddxYVUdOp72W/3pgIfCAKbKeDGycodkHAElCFyjuDeyU5G5DWb4K7NLez6M7t5lyBvDgabb1OuDdVXUJQHs9EHj9iHq/T7smbSbBC4FXVNWfW9k/VdX8QeYkawDbAs/ntoHxFcA3geeNaOfNwEur6o+t3qur6tjJT/lmOwDnAB/i1jdb1qa7SUOrc9E06xu4J/CHwYeVODeANei+k89U1YcmyHMj8FHgNRMcfw7wSeBUuhs1IyXZN92Ml7OWXXf1RNkkSZIkaULTCfpPBdZJclGSI5M8rnfs071p1QcPF0yyJXBxVV3eArWb2ug0dMHWqGB5E+DHk/TnNb02TxvR5lrA+sB3pjivm4D30AWpw7YFLqmqJcDpwFOGjn8W2LPdDNgM+MHQ8T2GppyvxjQkmQPsDCyeZlsbc9trdVZLH/Zk4Evt/YOBX1bVnybpztOBr1XVRcBV7bvsOwj4jySr9vp/D+Ae7bpN5ObfDPCVoWODmxon0s3WGMw8+CDw8SSnpVtq8o+9MusNXevH9o6d1pYPfBs4YGXOred9wHer6tBJznHQ573arIBhe9DNcFnAbWeS3KyqPlpVW1XVVquuPqoaSZIkSZrclEF/VV0DPBzYl24U9Pje+u3+9P7+6PJrklxIF6DO76UvoAtg59BN/f/8CvS5P71/h176Y5MsAn4LnFxVv51GXZ8BHpXkgUPp8+iCbdrrrQKzdgNjbksfDlzhttP7r5+iH6u1IPgs4JfAx6fZVoCaIu3gJD8HPgW8e1TjSfZpAfOvkqzTkqe6BpcAP6QbtZ6sP8Nu/s3Qu5nSptM/BfhSmyXwA2Cn1tbXgQcBHwM2AH6a5O9b0eHp/Wf02tqhLTHYFDiijfCv6LkNfAvYLcn9JjvJdg7HAa/spyd5BHBFm+HyTWDLdqNKkiRJkmbcnOlkqqpldCPepydZzMRTnwcOrapDkjwTOC7Jem0a+QK6mQPfBhZV1eUjyp5Ld5Ph7Gmew8AZVbVrkocA301yYlUtnKxAVd3YNlx74yCtje4+C3hauo3tAtwnyT2GRsZPoltPvz1wn7zc9CEAACAASURBVOXs67DrWxA8kYnaOhfYCuhPd98S6O8h8Hrgi3TB57F01/ZnwD8PzqmtSz+6jYqvmuQ+wOPp9hMoYFWgkrxhqF/vBr5Am1VRVX9Mcm2SB1XVz1k+TwbWBBZ3qytYnW5pyCmt7qvobtJ8Jt1Ghtsx+YyQm1XVkiS/AzZKsmRFzq3ns3R7AXwlyQ5TzJY4DPgJ0F/3Pw/YIMnS9vmedL+3o6ZzLpIkSZK0PKazkd9Dk6zfS9oCGF6HP1JVfZFu9Pp57fMS4Pd006cnWgd/MPDmFryTZJUkr51Oe62Ni+jWtb9xqrzNMXSbEw5GjncEzq6qdapqblWtC5xANyW87xPAO6pqMbe/ido6BHhT2lMH2uubgff2M1XVTcDhwCpJnlRV19HNJjhisF9Bu9kx2Lxud+C4qlq3XYN1gEuAxwzVewHdDYZde8kHAh9Mcs9W7z2T7DuNc5wHvKC1Nxd4IN1+CqsneXxueaLBPYD16GZETEsblX8g3e92Zc5tcOwwulH6Ewcb/iW5YES+q4DP0e0dMNio8F+AzXrnuRuTTPGXJEmSpJUxnTX9awDHpntU2iJgI26Zst9f0/+NCcq/A3htbnkE2wK6KdonjsrcprO/GliQ5Hy6jd3W7mXpr+lfmN5j9no+TLcz+vC0/VHt/YVuZ/fBdO15I/p2AkNTvavq0qo6fIJqh9f0bwPQpvAPzKHb5X1KE7XVZjK8EfhyCzq/DLxh1AyHqiq6HfsHI9r7A78BzknyU7oNBI8Ffs00r0HzLuCfep8/BJwG/Ki3nv66yc6vBfRPoo3qt/5eSzei/lS62Qlntd/f94GjqupHLevwmv7+dPrT2jU/Ddivqn63kud2s6p6I91TBj7ZbipM9ISC9wKDXfy3Ay6rqv7THr5DNwNh7duUlCRJkqSVlC4W1B2prUdfWFVTPWFAdwJJdgUeVFXDjwWcMS/Z/8D66rLNps4oSZKkO72lB+0ydSbptkYORE5rTb9mTpKn0T014E2z3RfNjKo6ebb7IEmSJEmjjHXQn2Qf4FVDyd+rqpfNRn8Aquokuo35JEmSJEm6XY110D/YlX62+yFJkiRJ0myYzkZ+kiRJkiTpTsigX5IkSZKkMWXQL0mSJEnSmDLolyRJkiRpTBn0S5IkSZI0pgz6JUmSJEkaUwb9kiRJkiSNKYN+SZIkSZLGlEG/JEmSJEljyqBfkiRJkqQxNWe2OyBpaps+YE0+9NJdZrsbkiRJku5kHOmXJEmSJGlMGfRLkiRJkjSmDPolSZIkSRpTBv2SJEmSJI0pg35JkiRJksaUQb8kSZIkSWPKoF+SJEmSpDFl0C9JkiRJ0pgy6JckSZIkaUzNme0OSJra4suuZu5+p8x2NyRJkqZl6UG7zHYXJDWO9EuSJEmSNKYM+iVJkiRJGlMG/ZIkSZIkjSmDfkmSJEmSxpRBvyRJkiRJY8qgX5IkSZKkMWXQL0mSJEnSmDLolyRJkiRpTBn0S5IkSZI0pgz6JUmSJEkaUwb9kiRJkiSNKYN+SZIkSZLGlEG/JEmSJEljyqBfkiRJkqQxZdAvSZIkSdKYMuiXJEmSJGlM3WmD/iT7Jzk3yaIkC5NsneT0JBe2zwuTfKHlnZ/kspZ2XpJ5Lf2SJA8dqvewJG9Isn2Sk3vpOyc5K8n5SS5IcsiIugd/92rlr07y037+Sc5n7yQ3Jdmsl3ZOkrm9zw9LUkmeNFS2knyy93lOkisG/W91XzHUx41G9GGNJB9JsqRd2+8k2boduybJpr3yV7XrtzDJN5LMTXJOy7t969PzR/T9de1zkhyQ5OIkFyU5LcnGvfxLkyxu3++3k6yb5MTW3s/atR30ZZt2zu9u9Q3S9x86v2e0PmwwlP7I9tu5OMlPkpySZNPJvt+h8qPO/am94ycn2b69v0uSg1pb5yT5YZKdJ/hZSJIkSdJKmTPbHVgRSR4N7ApsWVU3JLkvcNd2eK+qOmtEsUOr6pAk6wM/bjcEPgvsCby91bsKsDuwLfDAXnubAEcAu1TVBUnmAPsO1z3UR4AzqmrXJKsBP01yYlV9b5JTuxTYH9hjguPzgO+216/30q8FNkmyWlVdDzwRuGyo7PFV9fJJ2gY4CrgEWL+qbkryIGDDwcGqWgxs0c7vGODkqhrcWJk7VNfidh4fb5/3BM7uHX8ZsA2weVVdl2Qn4KQkG1fVn1ueHarqyiRvBw6oqme0trYHXldVuw4qS3IQ8A/AplX15yT3AP5jqE+D67cnML+Vuz/wOeA5VXVmS3sMsF47Bxjx/U5h8D1+ecSxdwJrA5u03+79gcctR92SJEmSNG131pH+tYErq+oGgKq6sqp+PZ2CVXUxcB2wFrCALgAc2A5YWlW/GCr2BuBdVXVBq+PGqjpyup1tgfhC4AFTZD0Z2DhDsw+gGxmnuyGxN7BTkrsNZfkqsEt7P4/u3KYtyXrA1nTB9U2t3z+vqlOWp56eXwJ3S3L/1vcntz4OvBF4RVVd19o6FTgT2GtEXd9nkmuXZHXgha2+P7f6/lRV83t51qC7mfN8bv2dvxw4dhDwt7LfraovLce5DjsbuDrJEyfp5+C3+7uq+twE57VvutklZy277uqV6I4kSZKkv1V31qD/VGCdNi38yCT9kdJP96ZhHzxcMMmWwMVVdXlVLQJuSrJ5O7wno4PlTYAfT9Kf1/TaPG1Em2sB6wPfmeK8bgLeA7x5xLFtgUuqaglwOvCUoeOfBfZsNwM2A34wdHyPoSnqqw0d3xhYWFXLpujj8vgC8C90I/o/AW4ASHJP4O7tXPrOav0Y9mRgsiD8wcAvq+pPk+R5OvC1qroIuKr9Dmjt/WSK85j0+53AfwIHTNDPP06ngqr6aFVtVVVbrbr6mtNsVpIkSZJucacM+qvqGuDhdFPsrwCOT7J3O7xXVW3R/l7fK/aaJBfSBcPze+kL6ILlOcBuwOdXoEuH9trcoZf+2CSLgN/STYX/7TTq+gzwqCQPHEqfRxfY017n9Q+2GxhzW/pXRtR7fK+PW7TZB7e3z9EF/dOdeRCgep9PS3I5sCPddZmWJPu0AP1XSdZpyZNev17ZH6Tbt+HwXvJE3++EquqMVt9jp9tvSZIkSZppd8qgH6CqllXV6VX1Nrop2s+aosihVfVQunXmx/Wmxy8Ank0XWC6qqstHlD2X7ibD8jqjqjYDNgVekmSLqQpU1Y3Ae+mmvwOQZFW683trkqXAB4Cd27r1vpOAQ1jOqf3NucDmbV+DGdFucvwf3R4D3+yl/xG4tu0Z0LclcF7v8w7Auq1v75ikqZ8B/zy4HlV1dFVtAVwNrJrkPsDjgaPa9Xs93cyHtLoHo/5U1dbAW4CZGFp/F93a/pH9lCRJkqTb250y6E/y0LYh38AWwPA6/JGq6ot008if1z4vAX4PHMTEwfLBwJuTPKS1v0qS1063v21K+YH0AvkpHEN3E+Lv2+cdgbOrap2qmltV6wIn0E1Z7/sE8I624d5yadfhLODtLRgmyfpJdlveuoa8FXjjiGUDBwPvHywzSLIj8BiGRvTbjIRXA89Ncu8J+n4d3YaBRwxu5rQbJYPNHXcHjquqddv1W4duw8LHAB8E9k6yTa/K1ac6qSQPSPLNyfK0fQrWAjYf6uf7k9y11bN2kn+dqj1JkiRJWhF3yqAfWAM4Nt3j9xYBG3HLlP3+mv5vTFD+HcBre6PaC4ANgBNHZW5T518NLEhyPnAO3WaCA/013wtH7GQP8GFguxHT9ke19xfg/cD9WtK8EX07AXjOULlLq+pwRhte078NQJKFvTwvoNsB/2dJFgMfA6a1QeIk53LmBJvifQD4EbC4Lbt4C7DbqGUHVfUbuu/oZZM0tT/wG+CcJD8FzgCObf2f8Pq12Qh7AAemexTgmXQ3CY7o5R31/a4N3Dj52QPdaP8/9T4fQLck5bx0j/n7UvssSZIkSTMuVTV1Lkm3kuTldJvynXRHtPeS/Q+sry7b7I5oSpIkaaUtPWiXqTNJmmkZlTjnju6FNA6q6oipc0mSJEnS7DLov4Ml2Qd41VDy96pqsqnrkiRJkiQtN4P+O1hVHQ0cPdv9kCRJkiSNvzvrRn6SJEmSJGkKBv2SJEmSJI0pg35JkiRJksaUQb8kSZIkSWPKoF+SJEmSpDFl0C9JkiRJ0pgy6JckSZIkaUwZ9EuSJEmSNKYM+iVJkiRJGlMG/ZIkSZIkjak5s90BSVPb9AFr8qGX7jLb3ZAkSZJ0J+NIvyRJkiRJY8qgX5IkSZKkMWXQL0mSJEnSmDLolyRJkiRpTBn0S5IkSZI0pgz6JUmSJEkaUwb9kiRJkiSNKYN+SZIkSZLGlEG/JEmSJEljas5sd0DS1BZfdjVz9ztltrshSZoFSw/aZba7IEm6E3OkX5IkSZKkMWXQL0mSJEnSmDLolyRJkiRpTBn0S5IkSZI0pgz6JUmSJEkaUwb9kiRJkiSNKYN+SZIkSZLGlEG/JEmSJEljyqBfkiRJkqQxZdAvSZIkSdKYMuiXJEmSJGlMGfRLkiRJkjSmDPolSZIkSRpTBv2SJEmSJI0pg35JkiRJksaUQb8kSZIkSWPKoF+SJEmSpDE1I0F/kv2TnJtkUZKFSbZOcnqSC9vnhUm+0PLOT3JZSzsvybyWfkmShw7Ve1iSNyTZPsnJvfSdk5yV5PwkFyQ5ZETdg797tfJXJ/lpP/8k57N3kpuSbNZLOyfJ3N7nhyWpJE8aKltJPtn7PCfJFYP+t7qvGOrjRiP6sEaSjyRZ0q7td5Js3Y5dM6K/RwylnZ1kwVDao5L8oLV5fpL5k/Upydwk5wzVMT/J69r7JDkgycVJLkpyWpKNe3mXJjljqPzCQZ2976Xf7o7t2LKh9Ln938EMfEfv7X1+3eBatM/PbXWd236jg/M9pv1OB306c6Lr3zv/+45IH/n7lSRJkqSZNmdlK0jyaGBXYMuquqEFOXdth/eqqrNGFDu0qg5Jsj7w43Q3BD4L7Am8vdW7CrA7sC3wwF57mwBHALtU1QVJ5gD7Dtc91EeAM6pq1ySrAT9NcmJVfW+SU7sU2B/YY4Lj84Dvttev99KvBTZJslpVXQ88EbhsqOzxVfXySdoGOAq4BFi/qm5K8iBgwynKAJBkQ7obOtsluXtVXdsOHQs8u6rOTrIq0L/Jcps+9QPoCbwM2AbYvKquS7ITcFKSjavqzy3PPZKsU1W/av0adkZV7Toi/fqq2mKK/qzod3QD8MwkB1bVlUNt7Ay8Gtipqn6d5G7Av/WyvL6qvjBBe1Oaxu9XkiRJkmbMTIz0rw1cWVU3AFTVlVX16+kUrKqLgeuAtYAFdEH/wHbA0qr6xVCxNwDvqqoLWh03VtWR0+1sC8QXAg+YIuvJwMYZmn0A3Qg33Q2JvYGdWmDY91Vgl/Z+Ht25TVuS9YCtgQOq6qbW759X1SnTrOI5wCeBU4Gn9dLvB/ym1besqs5bnn6N8EbgFVV1XavzVOBMYK9ens9xS1C+3NdiCiv6Hd0IfBR4zYg63wS8bvAbrqo/V9XHZrDP0/79Jtm3zQg4a9l1V89gFyRJkiT9rZiJoP9UYJ02vfvIJI/rHft0byr0wcMFk2wJXFxVl1fVIuCmJJu3w3syOkDcBPjxJP15Ta/N00a0uRawPvCdKc7rJuA9wJtHHNsWuKSqlgCnA08ZOv5ZYM8WaG4G/GDo+B5DU9dXGzq+MbCwqpZN0LfV+uWBdwzXDxxPd/3m9dIPBS5McmKSFw0FwhP1ab2htl4MkOSewN3bNeg7q/V/4AvAM9v7pwJfHsr/2KF21xtxjidOcB1W5jv6ILBXkjWH0qf6fR3c69enJ8k3kanqv1lVfbSqtqqqrVZdfbibkiRJkjS1lZ7eX1XXJHk48FhgB+D4JPu1wxNN739NkhcCDwKe3EtfQBcsnwvsBrx1Bbp0m+n9zWOTLKKb0n5QVf12GnV9Btg/yQOH0ufRBfa0138Dvjg4WFWL2lT0ecBXRtQ7nen9k7nV1PckewNbtfePAK6oql8kuRT4RJK1quoPVfWOFqjuRDcbYB6w/UR9assilgy1NX+KvgWo3uergD8k2RM4n25mR9+0p/dPYEW/oz8mOQ54JXD9NNoZWKnp/ZIkSZJ0R5qRjfzaVPHTq+ptwMuBZ01R5NCqeijdiPRxvRHnBcCzgR2BRVV1+Yiy5wIPX4FunlFVmwGbAi9JMmVAWVU3Au+lm8YOQFsL/yzgrUmWAh8Adk5yj6HiJwGHsGLT2c8FNm/7GiyvecAGrW9LgHvS+z6qaklVfQh4QmvjPivQBlX1R+DattdA35bA8LKB4+lG1mdyav+gHyvzHR0GPB+4ey9tRX9f03V71y9JkiRJN1vpoD/JQ9uGfANbAMPr8Eeqqi/STQd/Xvu8BPg9cBATB4gHA29O8pDW/ipJXjvd/lbVRcCB9ILEKRxDdxPi79vnHYGzq2qdqppbVesCJwBPHyr3CeAdVbV4un3r9XEJ3XV5e1ubTpL1k+w2Wbl2k+BfgM1a3+bSzZgYPCFhl0F9dEsclgH/u7z96zkYeP9gKUC6nfcfQzf63nci3TT8r3P7OIYV+I6q6iq6PQee30s+EHhPkn8ASPJ3SV45g31dqd+vJEmSJC2PmRjpXwM4Nt2jzRYBGwHz27H+mv5vTFD+HcBre6PaC4AN6ALF22hr/18NLEhyPnAO3WaCA/01/Qsn2IH+w3Q72w9PCR/V3l+A99NtggddAD3ctxPopsv3y11aVYdPUO3w+vltoHucXS/PC4B/AH6WZDHwMWCqDRK3Ay6rqv7TAr4DbJRkbbop7he2dj5Jt/xisG/AyD5N4QPAj4DFSS4E3gLs1jZLvFlV/amq/qtdy2HDa/p3n0a7t7Ki31HzXuDmx+pV1VfoZiV8oy0z+TG3XgZz8FB/B0+q2DvJpb2/f2rpi3pp75vG71eSJEmSZkyqaupckmbVS/Y/sL66bLPZ7oYkaRYsPWiXqTNJktTtr3YbM7KmX5IkSZIk/fVZ6d3778yS7AO8aij5e1X1stnojyRJkiRJM+lvOuivqqOBo2e7H5IkSZIk3R6c3i9JkiRJ0pgy6JckSZIkaUwZ9EuSJEmSNKYM+iVJkiRJGlMG/ZIkSZIkjSmDfkmSJEmSxpRBvyRJkiRJY8qgX5IkSZKkMWXQL0mSJEnSmDLolyRJkiRpTM2Z7Q5ImtqmD1iTD710l9nuhiRJkqQ7GUf6JUmSJEkaUwb9kiRJkiSNKYN+SZIkSZLGlEG/JEmSJEljyqBfkiRJkqQxZdAvSZIkSdKYMuiXJEmSJGlMGfRLkiRJkjSmDPolSZIkSRpTc2a7A5Kmtviyq5m73ymz3Q1J+puz9KBdZrsLkiStFEf6JUmSJEkaUwb9kiRJkiSNKYN+SZIkSZLGlEG/JEmSJEljyqBfkiRJkqQxZdAvSZIkSdKYMuiXJEmSJGlMGfRLkiRJkjSmDPolSZIkSRpTBv2SJEmSJI0pg35JkiRJksaUQb8kSZIkSWPKoF+SJEmSpDFl0C9JkiRJ0pgy6JckSZIkaUwZ9EuSJEmSNKYM+v8GJVmWZGGSc5J8PsnqI9K/nORevTIbJ/lWkouSXJzkLUnSju2d5IpW9rwkLxyRPvjbKMncJNf38h+X5P69PL9Ncll7f3aSM5Ps3OvLs5N8bZLz2z/JuUkWtTq2TnJie/+zJFf32tqmlTk7yYL2fp/e8b8kWdzeHzTROY3owxpJPpJkSevLd5Js3Tv+jCSVZIOV/0YlSZIkabQ5s90BzYrrq2oLgCSfBl4MvG8o/VjgZcC7kqwGnAS8pKpObTcJTgBeCnyw1Xl8Vb08yf2Ac5Oc1E/vN55kLrCkqrZIsirwP8COvbbnA9dU1SHt8ybA55OcBqwKvAt48qgTS/JoYFdgy6q6Icl9gbtW1TPa8e2B11XVrr0yG9LdANsuyd2r6mjg6HZsKbBDVV3ZPu896pxGOAq4BFi/qm5K8iBgw97xecB3gT2B+VPUJUmSJEkrxJF+nQE8eET694EHtPfPAb5XVacCVNV1wMuB/YYLVdXlwBJg3ek0XlXLgB/22hqV5xzgy8AbgbcBx1XVkgmyrw1cWVU3tLJXVtWvp+jGc4BPAqcCT5tOvyeTZD1ga+CAqrqp9ePnVXVKO74GsC3wfLqgf6J69k1yVpKzll139cp2S5IkSdLfIIP+v2FJ5gA7A4uH0lcFnkA3ug+wMfDjfp4WdK+R5J5DZR8EPAj4WUvaY2gq/GpD+e9GFyBPOF2/eTtdcL4z8J5J8p0KrNOWIRyZ5HFT1AuwB3A8sIBuBH7K/JOdE931WthuaIzydOBrVXURcFWSLUdlqqqPVtVWVbXVqquvOY1uSZIkSdKtGfT/bVotyULgLOCXwMeH0n8P3Jtu2j1AgJqgrkH6Hq3sAuBFVXVVSz++qrbo/V3f0tfrtfXLqlo0WYer6lq6wPyTg1H8CfJdAzwc2Be4Aji+TckfKckjgCuq6hfAN4Etk6w1WV8mOafpmgd8tr3/LNO70SBJkiRJy801/X+bbl67Pyo9yZrAyXRr+t8PnAts18/YRvSvqao/tf38prPOvW+wpn9t4PQkT6uqk6Yoc1P7m1QbYT+91bsYeB5wzATZ5wEbtLX7APcEnkW3Jn9FnQtsnmSVwfT+gST3AR4PbJKk6PYoqCRvqKqJbqxIkiRJ0gpxpF+3UVVXA6/k/7d359GWlPW5x78PNEa4GPAiGES0CSKRoWmGxAkUIirYBE1EoUWvuExIUIzCVUHbpYRoQMFLHKLGCcQlgwFRRBE1FxTBqZUemAVpDaiB1qQNwlVpfveP/Z5YbPYZejx9iu9nrbPO3u9b9dav6pTYz663asPrk2wCfArYN8mBAG06+3uZeJr9VLf1UwbPBnjTmo4FkGTnJDt1muYCPxpn2Y2AFwFzqmp2Vc0Gns8aXnlvtz4sBP4u+e9vONgpyfOBwxg8k+DxbZvbM3jg375rsk1JkiRJGsXQr5Gq6hpgMXBEm77+fOAtSW5i8AyA7wLvn8JQw/e/P23EMp8FNkuy31oofXPgE+2rAJcAuzD+0/GfAdxRVXd02r4O7NJmIIxn5D612xXG/CXwB8AtbbbBR4CfMPhA4aKh8S5k8LwCSZIkSVqr4oxiacN3zIJT6tKVc6a7DEl6yFl26rzpLkGSpKnKqEav9EuSJEmS1FM+yE8zUnsg3r+O6HpWVf18fdcjSZIkSRsiQ79mpBbsR30DgSRJkiSpcXq/JEmSJEk9ZeiXJEmSJKmnDP2SJEmSJPWUoV+SJEmSpJ4y9EuSJEmS1FOGfkmSJEmSesrQL0mSJElSTxn6JUmSJEnqKUO/JEmSJEk9ZeiXJEmSJKmnZk13AZImt/t2W/DBV82b7jIkSZIkzTBe6ZckSZIkqacM/ZIkSZIk9ZShX5IkSZKknjL0S5IkSZLUU4Z+SZIkSZJ6ytAvSZIkSVJPGfolSZIkSeopQ78kSZIkST1l6JckSZIkqadmTXcBkia39I4VzD7xC9NdhiT11rJT5013CZIkrRNe6ZckSZIkqacM/ZIkSZIk9ZShX5IkSZKknjL0S5IkSZLUU4Z+SZIkSZJ6ytAvSZIkSVJPGfolSZIkSeopQ78kSZIkST1l6JckSZIkqacM/ZIkSZIk9ZShX5IkSZKknjL0S5IkSZLUU4Z+SZIkSZJ6ytAvSZIkSVJPGfolSZIkSeopQ78kSZIkST1l6JckSZIkqacM/UCSBUmuS7IkyaIkT27tVyS5qbUtSnJBaz8pyR2t7fok81v7bUl2Hhr7H5O8Mcn+SS7ptB+cZGGSG5LcmOT0EWOP/WzZ1l+R5Jru8hPs01FJ7k8yp9N2bZLZnfd7Jqkkzx1at5J8svN+VpK7xupvY981VOMuI2rYIsnZSW5tP2cn2aL1zU7ykqF63z/RPk23JI8ZOwckSZIkaSZ4yIf+JE8FDgH2qqo5wIHAv3UWObKq5rafwzrtZ1TVXOD5wD8n2QQ4DziiM/ZGwGHA+UPb3A14P/DSqnoSsBvww+GxOz//2dqvrKo9gT2BQ5I8fZLdux1YMEH/fOAb7XfXr4Ddkmza3j8buGNomfOHarx+xPgfA35YVTtW1Y7AbcBHW99s4CUj1lktSTZe1+NU1U+GzoHV3casNR1DkiRJkqbiIR/6gW2B5VX1a4CqWl5VP5nqylX1A+Ae4JHAuXRCP/AMYFlV/WhotTcC76iqG9sY91XVB1Zhm/cCi4DtJln0EmDX4dkHAEnC4AOJo4DnJHn40CKXAvPa6/kM9m3KkjwB2Bv4+07zycA+SXYETgX2a7MEjmv9j0nypSQ/SPKuzljPSfLNJN9P8i9JNm/ty5K8Nck3gBcNbf9FbWbD4iRfb20bJzktyXfbrI6/bu37J7k8yTnA0iTvTPKqzlgnJfnfbXbCtZ2xTk+ytI31mta+d5KvJfleksuSbNvar0jyD0m+Brx2VH0jjuHRbTbIwpX3rFiVwy9JkiRJgKEf4MvA9kluTvKBJM8c6v9UZwr7acMrJ9kL+EFV3VlVS4D7k+zRuo9gdFjeDfjeBDUd19nm5SO2+UhgJ2BkWOy4H3gX8OYRfU8HbquqW4ErgOcN9Z8HHNE+DJgDfHuo//Ch6f2bDvXvAiyqqpVjDe31ImBX4EQGMxfmVtUZbZG5wOHA7m387ZM8CngLcGBV7QUsBI7vbOf/VdW+VXXe0PbfCjy3qvYADm1trwRWVNUfA38M/FWSHVrfnwALqmqXtu+Hd8Z6MfAvQ+MfDewA7NlmiHyqzfZ4H3BYVe0NfBx4R2edLavqmVX17nHqe4Cq+nBV7VNV+2y82RajFpEkSZKkCT3kpxlX1d1J9gb2Aw4Azk9yYlWd1RY5sqoWjlj1uCR/BfwhcFCn/VwGYfk6BlP/37oaZZ1RVaPu2d8vyRJgZ+DUqvrZFMY6B1jQCbdj5jMIt7TfLwM+M9ZZVUva/f/znzin0wAAIABJREFUgS+OGPf8qjp2gu0GqFVoB/jXqloBkOR64PHAlgw+QLhqMDmBhwHf7NYxzlhXAWcl+TS/26/nAHOSjE3R34LBhye/Ab5TVbcBVNU1SbZJ8hhga+A/qurH3echMLgN5ENVdV9b5xftto3dgK+0WjcGfjpOraPqkyRJkqS16iEf+uG/r0BfAVyRZCnwcuCsSVY7o6pOT/IXwNlJdqyq/8cg9H8Z+BqwpKruHLHudQymvi9exVKvrKpDkjwR+EaSi6pq0UQrVNV9Sd4NnDDW1u5bfyFwaJIFDIL4VkkeUVX/1Vn9YuB0YH9gq1Ws9TpgzyQbVdX9bbsbAXsANwCPHbHOrzuvVzI4PwN8paqGnzsw5lejGqvqbzJ4IOM8YFGSuW2s11TVZd1lk+w/YpwLGNz+8Af87sORB6zGgz+8CHBdVT11slpH1VdVPx9nPUmSJElaLQ/56f1Jdk6yU6dpLjB8D/64quozDKacv7y9vxX4OYN71se7D/404M0tvJNkoyTHj7PsqG3eDJxCJ8hP4iwGV6a3bu8PBBZX1fZVNbuqHg9cCLxgaL2PAydX1dKp1tap8RbgGgZT88e8Bfh+6/sv4BFTGOpbwNPbMwJIstnYcZtI+xDm21X1VmA5sD1wGXBMm4ZPkicm+R/jDDH2UMbDGHwAMOzLwN+MPZQvyf8EbgK2zuDhkCTZJMmuq1CfJEmSJK1VD/nQD2wOfCKDr95bwmAq+Umd/u49/V8dZ4yTgePblWwYhP0/Ai4atXC79/91wLlJbgCuZfBAwTHde/oXDU0rH/Mh4Bkjpu2P2t5vgPcC27Sm+SNqu5Chp+lX1e1V9Z5xhh2+p/9pAEm6Mw9eCTwxyS1JbgWe2NoAlgD3tQfZHcc4quouBg8bPLf9fb7F4NhO5rT2kL1rGTz7YDGDbw64Hvh+a/9nxpntUlXXMfhQ4o6q+umIRT4K/BhYkmQx8JJ2nA8D3tnaFgFPW4X6JEmSJGmtStV4t1dL2lAcs+CUunTlnOkuQ5J6a9mp8yZfSJKkDVtGNXqlX5IkSZKknvJBfjNcklcArx1qvqqqXj0d9UiSJEmSNhyG/hmuqs4EzpzuOiRJkiRJGx6n90uSJEmS1FOGfkmSJEmSesrQL0mSJElSTxn6JUmSJEnqKUO/JEmSJEk9ZeiXJEmSJKmnDP2SJEmSJPWUoV+SJEmSpJ4y9EuSJEmS1FOzprsASZPbfbst+OCr5k13GZIkSZJmGK/0S5IkSZLUU4Z+SZIkSZJ6ytAvSZIkSVJPGfolSZIkSeopQ78kSZIkST1l6JckSZIkqacM/ZIkSZIk9ZShX5IkSZKknjL0S5IkSZLUU7OmuwBJk1t6xwpmn/iF6S5DkjY4y06dN90lSJK0QfNKvyRJkiRJPWXolyRJkiSppwz9kiRJkiT1lKFfkiRJkqSeMvRLkiRJktRThn5JkiRJknrK0C9JkiRJUk8Z+iVJkiRJ6ilDvyRJkiRJPWXolyRJkiSppwz9kiRJkiT1lKFfkiRJkqSeMvRLkiRJktRThn5JkiRJknrK0C9JkiRJUk8Z+iVJkiRJ6ilDvyRJkiRJPWXo1zqV5A+SnJfk1iTXJ/likicmuTfJotZ2dpJN2vL7J1nR+sZ+Dmx9K9v765IsTnJ8ko06612S5BWd9X6TZGl7feo49T26rbd4rL5O3xNbvbckuSHJp5M8uvXtm+Q7SW5sP0d31jspyR2d/Zvf6TsryW2dGq9eN0dekiRJkmDWdBeg/koS4CLgE1V1RGubCzwauLWq5ibZGPgK8GLgU23VK6vqkBFD3ltVc9s42wDnAFsAbxtboKrOBM5syywDDqiq5ROUeTLwlap6T1tnTvv9cOALwPFV9fnWdgCwdduvc4AXVNX3kzwKuCzJHVX1hTbuGVV1epKdgO8luaCqftv63lBVF0x+BCVJkiRpzXilX+vSAcBvq+pDYw1VtQj4t877lcB3gO1WZeCquhM4Gji2hfDVtS1we2fcJe3lS4BvjgX+1nd5VV0LvBo4q6q+39qXA28EThxR5w+Ae4BHrmphSY5OsjDJwpX3rFjV1SVJkiTJ0K91ajfgexMt0K6oPxn4Uqd5v6Hp/TuOWreqfsjgHN5mDWr8J+BjSS5PsiDJY6ZQ+64j+ha29gdIshfwg/YhxZjTOvv2qeF1xlTVh6tqn6raZ+PNtpjyDkmSJEnSGKf3a7rsmGQRsBNwQecKO4w/vX+UNbnKT1VdluQPgYOAg4Frkuw2hW3WqOE6r49L8lfA2NhdTu+XJEmStF54pV/r0nXA3uP03druz38C8JQkh67q4C2srwTunGzZiVTVL6rqnKp6GfBd4BlMXPt1wD5DbXsD13fen1FVOwOHA2e3GQ2SJEmStF4Z+rUu/V/g99oVbwCS/DHw+LH3VfVTBvfCv2lVBk6yNfAh4P1VNeqq+1TH+dMkm7XXjwB2BH7M4EF9T0syr7PsQUl2Z3BLwFHtoYQk2Qp4J/Cu4fGr6jMMpv6/fHVrlCRJkqTVZejXOtPC+J8Dz25f2XcdcBLwk6FFPwtslmS/9n74nv7DWvumY1/ZB3wV+DLwd2tY5t7AwiRLgG8CH62q71bVvcAhwGuS/CDJ9cBRwJ3tg4qXAh9JciNwNfDx7kP/hpwM/PfXC/LAe/oXJXnYGu6DJEmSJI2UNbhIKmk9OWbBKXXpyjnTXYYkbXCWnTpv8oUkSXpoGPm8M6/0S5IkSZLUUz69Xw8JSV4BvHao+aqqevV01CNJkiRJ64OhXw8JVXUmcOZ01yFJkiRJ65PT+yVJkiRJ6ilDvyRJkiRJPWXolyRJkiSppwz9kiRJkiT1lKFfkiRJkqSeMvRLkiRJktRThn5JkiRJknrK0C9JkiRJUk8Z+iVJkiRJ6ilDvyRJkiRJPTVruguQNLndt9uCD75q3nSXIUmSJGmG8Uq/JEmSJEk9ZeiXJEmSJKmnDP2SJEmSJPWUoV+SJEmSpJ4y9EuSJEmS1FOGfkmSJEmSesrQL0mSJElSTxn6JUmSJEnqKUO/JEmSJEk9NWu6C5A0uaV3rGD2iV+Y7jIkab1Yduq86S5BkqTe8Eq/JEmSJEk9ZeiXJEmSJKmnDP2SJEmSJPWUoV+SJEmSpJ4y9EuSJEmS1FOGfkmSJEmSesrQL0mSJElSTxn6JUmSJEnqKUO/JEmSJEk9ZeiXJEmSJKmnDP2SJEmSJPWUoV+SJEmSpJ4y9EuSJEmS1FOGfkmSJEmSesrQL0mSJElSTxn6JUmSJEnqqWkP/UkWJLkuyZIki5I8OckVSW5q7xcluaAte1KS148Y4+4RbScluaMzxqIkWybZP8mKJNckuTHJ6ZPUd1SS+5PM6bRdm2R25/2eSSrJc4fWrSSf7LyfleSuJJd0xr5rqMZdRtSwLMnS1r80yfOH9z3JRkne22pbmuS7SXborP+ozjr7j9XQ3r+gHf8b27ov6PSdleS2tu3vJ3lqa39Kkm+39huSnNRZ56Ak32njLUpyfpLHDR2H5UlOae8XdPZ/Zef1367O33G84zrVY9Sp4boki5Mcn2SjzrFbMTT2gZ2/97s7dby+1T/Z/j3onJYkSZKktWHWdG68BchDgL2q6tctdD2sdR9ZVQvXcBNnVNUDQn0SgCur6pAkmwLXJLmoqq6aYJzbgQXA4eP0zwe+0X5f1mn/FbBbkk2r6l7g2cAdQ+ueX1XHTmFfDqiq5Ul2Br4MfG6o/3DgMcCcqro/yWPb9ieUZA/gdODZVXVbC8FfSfLDqlrSFntDVV2Q5DnAPwNzgE8AL66qxUk2BnZu4+0GvA84tKpuaG2HArOBH7fxngPcBLw4yZur6h3AO9qyd1fV3E59J7F6f8cHHdck86d4jO4dqyHJNsA5wBbA21r/lVV1yIj1fg38RZJTqmr5WOMU9k+SJEmS1onpvtK/LbC8qn4NUFXLq+on62vjLYgvArabZNFLgF1b4H6ADNLnYcBRwHOSPHxokUuBee31fODcNakZ+H3gP0a0bwv8tKruB6iq26tq1HLDXg/8Q1Xd1ta7DTgFeMOIZb8OPKG93gb4aVtnZVVd39pPaOPdMLZSVV1cVV/vjDMfeA+DDwGeMoUaJ7QKf8dVPkZVdSdwNHBs+1tP5D7gw8BxUypckiRJktax6Q79Xwa2T3Jzkg8keWan71OdadCnreb4x3XGuHy4M8kjgZ0YhNmJ3A+8C3jziL6nA7dV1a3AFcDzhvrPA45oHwbMAb491H/40FTxTcep4fIk1wJfA94yov/TwJ+1Md6dZM8R6y9Ksgj4aKd9V+B7Q8subO3D/gxY2l6fAdyU5KIkf935sGNX4Pvj7ANt/57F4IOUcxl8ADCZ1fk7jjqukx2jkarqhwz+t7JNa9pvaOwdO4v/E3Bkki2mMvZEkhydZGGShSvvWbGmw0mSJEl6CJrW0F9VdwN7M7iSehdwfpKjWveRVTW3/Yy66jwVZ3TGOKDTvl+SJcDPgEuq6mdTGOsc4Clj94B3zGcQ7Gm/HxBi2xT52a39iyPGPb9T49x21XqUA6pqN2B34P1JNh/azu0Mpti/icGHFP+a5FlD689tU8v/stMeoIa2Ndx2Wvuw4GjglW17JwP7MPjg5iXAl4YLTrJVC8U3d+5bPwS4vKruAS4E/rzdHjCR1fk7Pui4TuEYTaR7lf/KobFvHeuoql8CZwN/O8Vxx1VVH66qfapqn403W+PPECRJkiQ9BE3rPf0wmBrO4Ar5FUmWAi9fD5sduxf8icA32r3giyap8772kLYTxtpaWH0hcGiSBQyC4VZJHlFV/9VZ/WIG983vD2y1JoVX1a1J/h3YBfjOUN+vGdxOcGlb5gXAv04y5HUMwvuSTttewPWd92+oqgtG1QJ8MMlHgLuSbNXG2wtYXFU/B+a2wD/2IcV84OlJlrX3WwEHAF+dpM5RVufvuMrHKMkfAiuBO4EnTaGuf2Qw2+HMKSwrSZIkSevMtF7pT7Jzkp06TXOBH62v7VfVzQzuXz9hsmWbs4ADga3b+wMZhNvtq2p2VT2ewdXrFwyt93Hg5KpayhpqD5bbgaHjlGSvJI9przdicCvBVI7l6cCb0r6NoP1+M/DucdcYLDevc4/7TgxC8X8yuA1iQZJuON6srfP7wL7A49rxmg28mqlN8R/XVP+Oq3OMkmwNfAh4f1UNz4gYr55fMLiV4JVTWV6SJEmS1pXpvtK/OfC+JFsyeAjaLQymkF/A4J7+sanuy6vqwPb6LUleNzZAVT0W2CzJ7Z1x/0/7fVySl3bah8M4DALd65PsMPYwu/FU1W+SvJfBQ+hgEFYvGlrsQuAY4JOd9W7vrDPs8CT7dt6/qqquTrKo+5R3BvfkrwQ2AU6sqn8fGmcb4CNJfq+9/w7w/on2p9W2KMkJwOeTbAL8FnjjZFfMgZcBZyS5h8Hf7sg2a2NpktcCZyd5BPBzBg/sexvwF8D/HXtwY/M54F1Jfm+ovWuV/o7t/YOOK4OHIE7lGG3abmfYpO3bJ/ndOQXtnv7O+7ePmAnxbmAq38ogSZIkSetMpnjxUtI0OmbBKXXpyjnTXYYkrRfLTp03+UKSJGnYyG8bm+6n90uSJEmSpHVkuqf3bzCSvAJ47VDzVVX16umoR5IkSZKkNWXob6rqTHzauiRJkiSpR5zeL0mSJElSTxn6JUmSJEnqKUO/JEmSJEk9ZeiXJEmSJKmnDP2SJEmSJPWUoV+SJEmSpJ4y9EuSJEmS1FOGfkmSJEmSesrQL0mSJElSTxn6JUmSJEnqqVnTXYCkye2+3RZ88FXzprsMSZIkSTOMV/olSZIkSeopQ78kSZIkST1l6JckSZIkqacM/ZIkSZIk9ZShX5IkSZKknjL0S5IkSZLUU4Z+SZIkSZJ6ytAvSZIkSVJPGfolSZIkSeqpWdNdgKTJLb1jBbNP/MJ0lyHpIW7ZqfOmuwRJkrSKvNIvSZIkSVJPGfolSZIkSeopQ78kSZIkST1l6JckSZIkqacM/ZIkSZIk9ZShX5IkSZKknjL0S5IkSZLUU4Z+SZIkSZJ6ytAvSZIkSVJPGfolSZIkSeopQ78kSZIkST1l6JckSZIkqacM/ZIkSZIk9ZShX5IkSZKknjL0S5IkSZLUU4Z+SZIkSZJ6ytAvSZIkSVJP9S70J1mQ5LokS5IsSvLkJFckuam9X5TkgrbsSUnuaG3XJ5nf2m9LsvPQuP+Y5I1J9k9ySaf94CQLk9yQ5MYkp48Ye+xny7b+iiTXdJefYH+OSnJ/kjmdtmuTzO683zNJJXnu0LqV5JOd97OS3DVWfxv7rqEadxlRw7IkF3beH5bkrKFlPpfkm+31czvj3d059mcPH7/O+pskOTXJD9r+fSfJwZ3tP7oz5s86x3ZxkqvHlm3LvzjJlyY7Bkle0RnzN0mWttentmUPanXc2NrPT/K41ndWO0/G1r+6s42R50TrO7q13djG3nfEn12SJEmS1opZ013A2pTkqcAhwF5V9eskjwIe1rqPrKqFI1Y7o6pOT7IT8L32gcB5wBHA37VxNwIOA54O7NDZ3m7A+4F5VXVjklnA0cNjD9UIcGVVHZJkU+CaJBdV1VUT7NrtwALg8HH65wPfaL8v67T/CtgtyaZVdS/wbOCOoXXPr6pjJ9j2mH2S7FpV1w13JNkS2Au4O8kOVXXZWB1JrgBeP3bsk+w/zvh/D2wL7Nb+do8GntnpX1lVc9sYJwF3jx3b9nf4lySXAxsD7wAOmuwYVNWZwJltjGXAAVW1vDPm+4BDq+qG1nYoMBv4cRv7DVV1wdCxGPecSHII8NfAvlW1PMlewGeT/ElV/Wyc4yJJkiRJq61vV/q3BZZX1a8Bqmp5Vf1kKitW1Q+Ae4BHAucyCP1jngEsq6ofDa32RuAdVXVjG+O+qvrAVIttIXQRsN0ki14C7Jqh2QcAGXyKcBhwFPCcJA8fWuRSYF57PZ/Bvq2O04E3j9P3QuDz/O7DklWSZDPgr4DXdP52/15Vn57K+lV1bdv+CcDbgLOr6tbOIqtzDE4A/mEs8LftXFxVX59kvYnOiRMYfFCwvPV9H/gE8OpRA7VZAQuTLFx5z4oplCxJkiRJD9S30P9lYPskNyf5QJLuleJPdaZinza8Yrvq+oOqurOqlgD3J9mjdR/B6KC4G/C9Ceo5rrPNy0ds85HATsBkQfJ+4F2MDt1PB25rIfcK4HlD/ecBR7QPA+YA3x7qP3xoev+m49TwaWCvJE8Y0TcWpM9tr1fVE4AfV9UvV2PdMX8HvAQ4mMGx6prsGIyyK/D9SZY5rXPcPtXaJjondh3Rt7C1P0hVfbiq9qmqfTbebIsplCxJkiRJD9Sr0F9VdwN7M5hOfRdwfpKjWveRVTW3/byhs9pxSW5iEARP6rSfyyAozgKeD/zLapR0RmebB3Ta90uyBPgZcMkUp3afAzwlyQ5D7fMZhFra7weE7vYBxuzW/sUR457fqXFum30wykrgNOBN3cY2Df8JwDeq6mbgvjbFfb2qql8B5wOfHJst0Omb7BhMKMlWLdjfnOT1na43dI7bkatZeoBazXUlSZIkaUK9Cv0AVbWyqq6oqrcBxzKYej6RM6pqZwb3y5/dmR5/LvBi4EBgSVXdOWLd6xh8yLCqrqyqOcDuwDFJ5k62QlXdB7ybwRRxAJJszGD/3truSX8fcHCSRwytfjGD6fmrO7V/zCcZ3OrwuE7b4Qxuibit1TCbVZ/ifwvwuBF1r6r7288oq3oMrmPwnAKq6ufteQIfBjafwnrjnRPXj+jbq7VLkiRJ0lrXq9CfZOf2QL4xc4Hh+/BHqqrPMJhq/fL2/lbg58CpjB8UTwPenOSJbfsbJTl+qvW2K+On0AnykziLwYcQW7f3BwKLq2r7qppdVY8HLgReMLTex4GTq2rpVGsbp97fAmcAr+s0zwcOatufzSDUrlLor6p7gI8B703yMIAk2yZ56ZrUO2RVj8G7gAVJntRp22wK6010TrwLeGeSrVrfXAbPYpjycyAkSZIkaVX0KvQzuAr7iQy+fm8JsAu/m7Lfvaf/q+OsfzJwfHtaPwzC/h8BF41auE0bfx1wbpIbgGsZPExwTPee/kXpfM1ex4eAZ4yYtj9qe78B3gts05rmj6jtQgb3tnfXu72q3jPOsMP39D8NIMmicZb/GO1bH9r+PA74VmdbtwG/TPLkCXblWUlu7/w8FXgLg1syrk9yLfDZ9n6tmOQYjFp+KfBaBrM/bkxyFfAkBrdZjDlt6Ng9bKJzoqouZvDhw9VJbgQ+Ary0qn66VnZSkiRJkoakytuJpQ3dMQtOqUtXzpnuMiQ9xC07dd7kC0mSpOmSUY19u9IvSZIkSZKaWdNdgAaSvILBdPKuq6pq5He4S5IkSZI0GUP/BqKqzgTOnO46JEmSJEn94fR+SZIkSZJ6ytAvSZIkSVJPGfolSZIkSeopQ78kSZIkST1l6JckSZIkqacM/ZIkSZIk9ZShX5IkSZKknjL0S5IkSZLUU4Z+SZIkSZJ6ytAvSZIkSVJPzZruAiRNbvfttuCDr5o33WVIkiRJmmG80i9JkiRJUk8Z+iVJkiRJ6ilDvyRJkiRJPWXolyRJkiSppwz9kiRJkiT1lKFfkiRJkqSeMvRLkiRJktRThn5JkiRJknrK0C9JkiRJUk/Nmu4CJE1u6R0rmH3iF6a7DEk9t+zUedNdgiRJWsu80i9JkiRJUk8Z+iVJkiRJ6ilDvyRJkiRJPWXolyRJkiSppwz9kiRJkiT1lKFfkiRJkqSeMvRLkiRJktRThn5JkiRJknrK0C9JkiRJUk8Z+iVJkiRJ6ilDvyRJkiRJPWXolyRJkiSppwz9kiRJkiT1lKFfkiRJkqSeMvRLkiRJktRThn5JkiRJknrK0D8kyYIk1yVZkmRRkicnuSLJTe39oiQXtGVPSvL6EWPcPaLtpCR3dMZYlGTLJPsnWZHkmiQ3Jjl9kvqOSnJ/kjmdtmuTzO683zNJJXnu0LqV5JOd97OS3JXkks7Ydw3VuMuIGpYlWdpZ5mlJZie5tvWPu09JHp3kkiSLk1yf5ItJdu+M9Yskt7XXX51kf1a25a5N8vkkW7b22UnubX2Lk1ydZOehdd/T/h4bddomPLZtvx/VXu/d6txzaNz9W61/1mm7JMn+nfdbJ/ltkr8ePraSJEmStDYZ+juSPBU4BNirquYABwL/1rqPrKq57eew1dzEGZ0x5lbVf7b2K6tqT2BP4JAkT59knNuBBRP0zwe+0X53/QrYLcmm7f2zgTuGljl/qMbrx9nGAZ1lrh7RP94+nQx8par2qKpdgBOraunYWMDFwBva+wMn2Z9723K7Ab8AXt3pu7X17QF8AnjzWEcL+n/O4G/7jKExJzu2tA8FLgAOr6prRiwy2RgvAr41Yn8kSZIkaa0y9D/QtsDyqvo1QFUtr6qfrK+NV9W9wCJgu0kWvQTYdfjqNUCSAIcBRwHPSfLwoUUuBea11/OBc9ek5smM2KdtGYTisf4lE60/hf0Z803GP26/D/xH5/0BwLXAB3lw8B732DZPAj4LvKyqvjPOMouBFUmePU7/fOB/A49NMu7fOsnRSRYmWbjynhXjLSZJkiRJ4zL0P9CXge2T3JzkA0me2en7VGcK+mmrOf5xnTEuH+5M8khgJ+Drk4xzP/AuOlevO54O3FZVtwJXAM8b6j8POKKF5znAt4f6Dx+a3r8po13e+ofXf4AR+/RPwMeSXJ7BrRSPmWj9KewPSTYGnsVglsCYHVt9twLHA/+n0zf2YcdFDGYhbNLpm+jYAnwOOLaqvjFJ3W8H3jKi1u2BP2gfGHwaOHy8Aarqw1W1T1Xts/FmW0yyOUmSJEl6MEN/R1XdDewNHA3cBZyf5KjW3Z3e/4bV3ER3ev8Bnfb9kiwBfgZcUlU/m8JY5wBPSbLDUPt8BsGe9vsBV7LblfXZrf2LI8Ydnt5/7zjbH5ve/+Rx+kfuU1VdBvwh8BHgj4Brkmw9wX5OtD+bJlkE/Bz4n8BXOn1j0/t3BF4HfBggycMYfHDw2ar6JYMPPZ4ztM3xji3AV4G/bB80jKuqrmzb22+o6wgGYX/U/kiSJEnSWmXoH1JVK6vqiqp6G3As8ML1sNkr2zMEdgeOSTJ3shWq6j7g3cAJY20tiL4QeGuSZcD7gIOTPGJo9YuB01m3U/vH3aeq+kVVnVNVLwO+y4PvqwemtD/3tucAPB54GA+8p7/r4s42DgK2AJa2MfflwR+MPOjYdhzbfn9gnG11vYMH39s/HziqbftiYI8kO01hLEmSJElaZYb+jiQ7DwWwucCP1tf2q+pm4BRGh81RzmLwsMGxK+UHAouravuqml1VjwcuBF4wtN7HgZOraumaVz2x4X1K8qdJNmuvHwHsCPx4nNWntD9VtQL4W+D1Q1P1x+wL3Npezwf+so03G9iBwbMCNhta5yweeGzH3N/G2DnJyW0//iTJ2SP2/cvAI4E92nI7A/+jqrbrbP8UBlf/JUmSJGmtM/Q/0ObAJ9pXyS0BdgFOan3de/q/2lnnLUluH/tpbZt125Ic39q79/QvSudr9jo+BDxjnKnlD1BVvwHeC2zTmuYzuE+960LgJUPr3V5V7xln2OF7+p8G0KbRr67uPu0NLGzH95vAR6vqu+OsN6X9AWhP0V/M7wL02D39i4F/YDAlfzPgucAXOuv9isE3A/zZ0HjDx7bb92vg+cChSV4NPA4Y7zaIdwCPnWR/nOIvSZIkaZ1IVU13DdKM1h7s+MnJvolgTRyz4JS6dOWcdTW8JAGw7NR5ky8kSZI2VBnVOGt9VyH1zRo82FGSJEmS1ilD/wYqySuA1w41X1VV4z2sTpIkSZKkBzD0b6Cq6kzgzOmuQ5IkSZI0c/kgP0mSJEmSesrQL0mSJElSTxn6JUmSJEnqKUO/JEmSJEk9ZeiXJEmSJKmnDP2SJEmSJPWUoV+SJEmSpJ4y9EuSJEkQ5FHmAAAFg0lEQVSS1FOGfkmSJEmSesrQL0mSJElST82a7gIkTW737bbgg6+aN91lSJIkSZphvNIvSZIkSVJPGfolSZIkSeopQ78kSZIkST1l6JckSZIkqacM/ZIkSZIk9ZShX5IkSZKknjL0S5IkSZLUU4Z+SZIkSZJ6ytAvSZIkSVJPGfolSZIkSeopQ78kSZIkST1l6JckSZIkqacM/ZIkSZIk9ZShX5IkSZKknjL0S5IkSZLUU4Z+SZIkSZJ6ytAvSZIkSVJPGfolSZIkSeopQ78kSZIkST1l6JckSZIkqacM/ZIkSZIk9ZShX5IkSZKknjL0S5IkSZLUU4Z+SZIkSZJ6ytAvSZIkSVJPGfolSZIkSeopQ78kSZIkST1l6JckSZIkqacM/ZIkSZIk9VSqarprkDSJE0444b822WSTm6a7DvXD3Xff/ajNN998+XTXof7wnNLa5jmltc1zSmvbBnpOLX/7299+0HCjoV+aAZIsrKp9prsO9YPnk9Y2zymtbZ5TWts8p7S2zaRzyun9kiRJkiT1lKFfkiRJkqSeMvRLM8OHp7sA9Yrnk9Y2zymtbZ5TWts8p7S2zZhzynv6JUmSJEnqKa/0S5IkSZLUU4Z+SZIkSZJ6ytAvbSCSHJTkpiS3JDlxRH+SvLf1L0my13TUqZljCufUke1cWpLk6iR7TEedmjkmO6c6y/1xkpVJDluf9Wnmmco5lWT/JIuSXJfka+u7Rs0cU/j/vS2SfD7J4nY+vWI66tTMkeTjSe5Mcu04/TPi3+eGfmkDkGRj4J+Ag4FdgPlJdhla7GBgp/ZzNPDB9VqkZpQpnlO3Ac+sqjnA3zODHkij9W+K59TYcu8ELlu/FWqmmco5lWRL4APAoVW1K/Ci9V6oZoQp/jfq1cD1VbUHsD/w7iQPW6+FaqY5Czhogv4Z8e9zQ7+0YfgT4Jaq+mFV/QY4D3j+0DLPB86ugW8BWybZdn0Xqhlj0nOqqq6uqv9ob78FPHY916iZZSr/nQJ4DXAhcOf6LE4z0lTOqZcAn6mqHwNUleeVxjOV86mARyQJsDnwC+C+9VumZpKq+jqD82Q8M+Lf54Z+acOwHfBvnfe3t7ZVXUYas6rnyyuBS9dpRZrpJj2nkmwH/DnwofVYl2auqfx36onAI5NckeR7Sf7XeqtOM81Uzqf3A08CfgIsBV5bVfevn/LUUzPi3+ezprsASQBkRNvw92lOZRlpzJTPlyQHMAj9+67TijTTTeWc+kfghKpaObiQJk1oKufULGBv4FnApsA3k3yrqm5e18VpxpnK+fRcYBHwp8COwFeSXFlVv1zXxam3ZsS/zw390obhdmD7zvvHMvgUelWXkcZM6XxJMgf4KHBwVf18PdWmmWkq59Q+wHkt8D8KeF6S+6rqs+unRM0wU/3/vuVV9SvgV0m+DuwBGPo1bCrn0yuAU6uqgFuS3Ab8EfCd9VOiemhG/Pvc6f3ShuG7wE5JdmgPlDkCuHhomYuB/9WeEvoUYEVV/XR9F6oZY9JzKsnjgM8AL/OqmaZg0nOqqnaoqtlVNRu4AHiVgV8TmMr/930O2C/JrCSbAU8GbljPdWpmmMr59GMGs0ZI8mhgZ+CH67VK9c2M+Pe5V/qlDUBV3ZfkWAZPu94Y+HhVXZfkb1r/h4AvAs8DbgHuYfBptTTSFM+ptwJbAR9oV2bvq6p9pqtmbdimeE5JUzaVc6qqbkjyJWAJcD/w0aoa+dVZemib4n+j/h44K8lSBtOyT6iq5dNWtDZ4Sc5l8E0Pj0pyO/A2YBOYWf8+z2B2iyRJkiRJ6hun90uSJEmS1FOGfkmSJEmSesrQL0mSJElSTxn6JUmSJEnqKUO/JEmSJEk9ZeiXJEmSJKmnDP2SJEmSJPXU/wfSLmQ+bNL8yQAAAABJRU5ErkJggg==\n"},"metadata":{"needs_background":"light"}}]},{"metadata":{},"cell_type":"markdown","source":"From the variable importance plot, we can see that the most significant feature is SERVICER_NAME. In the most important feature, we have different banks or \"servicers,\" and in our linear model, each one makes a difference; for that reason, we see that the first four variables in the plot above are 4 of the servicers in the dataset. These services are the most influential to our model in making predictions of whether someone will default or not. Please keep in mind that it does not necessarily mean that if someone gets a loan from Wells Fargo, they have a high probability of default.\n\nWe will take a look at the first ten predictions of our model with the following command:"},{"metadata":{"trusted":true},"cell_type":"code","source":"glm.predict(valid).head(10)","execution_count":17,"outputs":[{"output_type":"stream","text":"glm prediction progress: |████████████████████████████████████████████████| 100%\n","name":"stdout"},{"output_type":"display_data","data":{"text/html":"<table>\n<thead>\n<tr><th>predict  </th><th style=\"text-align: right;\">   FALSE</th><th style=\"text-align: right;\">      TRUE</th></tr>\n</thead>\n<tbody>\n<tr><td>FALSE    </td><td style=\"text-align: right;\">0.994227</td><td style=\"text-align: right;\">0.00577262</td></tr>\n<tr><td>FALSE    </td><td style=\"text-align: right;\">0.997196</td><td style=\"text-align: right;\">0.00280374</td></tr>\n<tr><td>FALSE    </td><td style=\"text-align: right;\">0.964314</td><td style=\"text-align: right;\">0.0356865 </td></tr>\n<tr><td>FALSE    </td><td style=\"text-align: right;\">0.996098</td><td style=\"text-align: right;\">0.0039019 </td></tr>\n<tr><td>FALSE    </td><td style=\"text-align: right;\">0.996148</td><td style=\"text-align: right;\">0.00385171</td></tr>\n<tr><td>TRUE     </td><td style=\"text-align: right;\">0.646653</td><td style=\"text-align: right;\">0.353347  </td></tr>\n<tr><td>FALSE    </td><td style=\"text-align: right;\">0.994166</td><td style=\"text-align: right;\">0.00583412</td></tr>\n<tr><td>FALSE    </td><td style=\"text-align: right;\">0.995727</td><td style=\"text-align: right;\">0.00427344</td></tr>\n<tr><td>FALSE    </td><td style=\"text-align: right;\">0.958063</td><td style=\"text-align: right;\">0.0419368 </td></tr>\n<tr><td>FALSE    </td><td style=\"text-align: right;\">0.994599</td><td style=\"text-align: right;\">0.005401  </td></tr>\n</tbody>\n</table>"},"metadata":{}},{"output_type":"execute_result","execution_count":17,"data":{"text/plain":""},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"The model used by H2O for this classification problem is a Logistic Regression model, and the predictions are based on the threshold for each probability[1]. For a binary classifier, H2O predicts the labels based on the maximum F1 threshold. From the report, the threshold for max F1 is 0.1224. So, any time the probability for TRUE is greater than the 0.1224, the predicted label will be TRUE, as is in the case of the sixth prediction. To learn more about predictions, you can visit the Prediction Section from the H2O documentation.\n\nLastly, save the default performance of the model, as we will use this for comparison purposes later on."},{"metadata":{"trusted":true},"cell_type":"code","source":"default_glm_perf=glm.model_performance(valid)","execution_count":18,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(default_glm_perf.auc())","execution_count":19,"outputs":[{"output_type":"stream","text":"0.8450464412102321\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"## Build a Random Forest"},{"metadata":{},"cell_type":"markdown","source":"We will build a default Distributed Random Forest (DRF) model and see how it performs on our validation set. DRF generates a forest of classification or regression trees, rather than a single classification or regression tree. Each of these trees is a weak learner built on a subset of rows and columns. More trees will reduce the variance. Both classification and regression take the average prediction over all of their trees to make a final prediction, whether predicting for a class or numeric value.\n\nTo build and train our Random Forest or RF(as we will be referring to from this point on) model, simply run the following two lines of code:"},{"metadata":{"trusted":true},"cell_type":"code","source":"rf = H2ORandomForestEstimator (seed = 42, model_id='default_rf')\n%time rf.train(x = x, y = y, training_frame=train, validation_frame=valid)\n                               ","execution_count":20,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.7/site-packages/h2o/estimators/estimator_base.py:200: RuntimeWarning: Dropping bad and constant columns: [LOAN_SEQUENCE_NUMBER]\n  warnings.warn(mesg[\"message\"], RuntimeWarning)\n","name":"stderr"},{"output_type":"stream","text":"drf Model Build progress: |███████████████████████████████████████████████| 100%\nCPU times: user 648 ms, sys: 54.5 ms, total: 703 ms\nWall time: 1min 7s\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"Note that we defined the random seed and the model id. You do not need to do this; the model can be built without defining these parameters. The reason for choosing the random seed is for reproducibility purposes, and the model id is to recognize the model in Flow easily.\n\nAgain, print the summary of your model as we did with the GLM model. You will see the summary of the model with the default settings, and the metrics score on the training and validation data.\n\nBelow you will see some of the details from the model we just built.\n\nThe AUC and F1 Score reported on the training data are 0.8033 and 0.2620, respectively, and you can see them in the image below."},{"metadata":{"trusted":true},"cell_type":"code","source":"rf","execution_count":21,"outputs":[{"output_type":"stream","text":"Model Details\n=============\nH2ORandomForestEstimator :  Distributed Random Forest\nModel Key:  default_rf\n\n\nModel Summary: \n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"     number_of_trees  number_of_internal_trees  model_size_in_bytes  \\\n0               50.0                      50.0            7598180.0   \n\n   min_depth  max_depth  mean_depth  min_leaves  max_leaves  mean_leaves  \n0       20.0       20.0        20.0      9881.0     11724.0     10834.34  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>number_of_trees</th>\n      <th>number_of_internal_trees</th>\n      <th>model_size_in_bytes</th>\n      <th>min_depth</th>\n      <th>max_depth</th>\n      <th>mean_depth</th>\n      <th>min_leaves</th>\n      <th>max_leaves</th>\n      <th>mean_leaves</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td></td>\n      <td>50.0</td>\n      <td>50.0</td>\n      <td>7598180.0</td>\n      <td>20.0</td>\n      <td>20.0</td>\n      <td>20.0</td>\n      <td>9881.0</td>\n      <td>11724.0</td>\n      <td>10834.34</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"stream","text":"\n\nModelMetricsBinomial: drf\n** Reported on train data. **\n\nMSE: 0.03217049865504154\nRMSE: 0.1793613633284536\nLogLoss: 0.18808040483623167\nMean Per-Class Error: 0.26910942081145595\nAUC: 0.8034365546707388\nAUCPR: 0.19880274803695155\nGini: 0.6068731093414776\n\nConfusion Matrix (Act/Pred) for max f1 @ threshold = 0.1714152473716729: \n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"             FALSE     TRUE   Error                 Rate\n0  FALSE  322404.0  15203.0   0.045   (15203.0/337607.0)\n1   TRUE    8458.0   4203.0   0.668     (8458.0/12661.0)\n2  Total  330862.0  19406.0  0.0676   (23661.0/350268.0)","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>FALSE</th>\n      <th>TRUE</th>\n      <th>Error</th>\n      <th>Rate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>FALSE</td>\n      <td>322404.0</td>\n      <td>15203.0</td>\n      <td>0.045</td>\n      <td>(15203.0/337607.0)</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>TRUE</td>\n      <td>8458.0</td>\n      <td>4203.0</td>\n      <td>0.668</td>\n      <td>(8458.0/12661.0)</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Total</td>\n      <td>330862.0</td>\n      <td>19406.0</td>\n      <td>0.0676</td>\n      <td>(23661.0/350268.0)</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"stream","text":"\nMaximum Metrics: Maximum metrics at their respective thresholds\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"                         metric  threshold          value    idx\n0                        max f1   0.171415       0.262139  194.0\n1                        max f2   0.088095       0.345659  266.0\n2                  max f0point5   0.291459       0.272684  125.0\n3                  max accuracy   0.570928       0.964273   43.0\n4                 max precision   0.998148       1.000000    0.0\n5                    max recall   0.000007       1.000000  399.0\n6               max specificity   0.998148       1.000000    0.0\n7              max absolute_mcc   0.151393       0.234703  209.0\n8    max min_per_class_accuracy   0.037451       0.727541  330.0\n9   max mean_per_class_accuracy   0.013768       0.730891  360.0\n10                      max tns   0.998148  337607.000000    0.0\n11                      max fns   0.998148   12655.000000    0.0\n12                      max fps   0.000007  337607.000000  399.0\n13                      max tps   0.000007   12661.000000  399.0\n14                      max tnr   0.998148       1.000000    0.0\n15                      max fnr   0.998148       0.999526    0.0\n16                      max fpr   0.000007       1.000000  399.0\n17                      max tpr   0.000007       1.000000  399.0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>metric</th>\n      <th>threshold</th>\n      <th>value</th>\n      <th>idx</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>max f1</td>\n      <td>0.171415</td>\n      <td>0.262139</td>\n      <td>194.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>max f2</td>\n      <td>0.088095</td>\n      <td>0.345659</td>\n      <td>266.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>max f0point5</td>\n      <td>0.291459</td>\n      <td>0.272684</td>\n      <td>125.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>max accuracy</td>\n      <td>0.570928</td>\n      <td>0.964273</td>\n      <td>43.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>max precision</td>\n      <td>0.998148</td>\n      <td>1.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>max recall</td>\n      <td>0.000007</td>\n      <td>1.000000</td>\n      <td>399.0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>max specificity</td>\n      <td>0.998148</td>\n      <td>1.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>max absolute_mcc</td>\n      <td>0.151393</td>\n      <td>0.234703</td>\n      <td>209.0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>max min_per_class_accuracy</td>\n      <td>0.037451</td>\n      <td>0.727541</td>\n      <td>330.0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>max mean_per_class_accuracy</td>\n      <td>0.013768</td>\n      <td>0.730891</td>\n      <td>360.0</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>max tns</td>\n      <td>0.998148</td>\n      <td>337607.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>max fns</td>\n      <td>0.998148</td>\n      <td>12655.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>max fps</td>\n      <td>0.000007</td>\n      <td>337607.000000</td>\n      <td>399.0</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>max tps</td>\n      <td>0.000007</td>\n      <td>12661.000000</td>\n      <td>399.0</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>max tnr</td>\n      <td>0.998148</td>\n      <td>1.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>max fnr</td>\n      <td>0.998148</td>\n      <td>0.999526</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>max fpr</td>\n      <td>0.000007</td>\n      <td>1.000000</td>\n      <td>399.0</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>max tpr</td>\n      <td>0.000007</td>\n      <td>1.000000</td>\n      <td>399.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"stream","text":"\nGains/Lift Table: Avg response rate:  3.61 %, avg score:  3.75 %\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"      group  cumulative_data_fraction  lower_threshold       lift  \\\n0         1                  0.010001         0.355807  10.811744   \n1         2                  0.020002         0.276656   6.547068   \n2         3                  0.030003         0.232143   5.172894   \n3         4                  0.040001         0.202677   4.408091   \n4         5                  0.050002         0.180995   4.011955   \n5         6                  0.100218         0.117647   2.944402   \n6         7                  0.150002         0.081530   2.086227   \n7         8                  0.202559         0.062500   1.498295   \n8         9                  0.300002         0.030525   1.059398   \n9        10                  0.399999         0.008321   0.906742   \n10       11                  0.500011         0.003247   0.509377   \n11       12                  0.600001         0.001321   0.340452   \n12       13                  0.700001         0.000419   0.202984   \n13       14                  1.000000         0.000000   0.202723   \n\n    cumulative_lift  response_rate     score  cumulative_response_rate  \\\n0         10.811744       0.390808  0.468185                  0.390808   \n1          8.679406       0.236654  0.311273                  0.313731   \n2          7.510569       0.186983  0.252600                  0.271482   \n3          6.735115       0.159338  0.217047                  0.243452   \n4          6.190452       0.145019  0.191749                  0.223764   \n5          4.563960       0.106430  0.144611                  0.164972   \n6          3.741617       0.075410  0.098156                  0.135247   \n7          3.159555       0.054158  0.070321                  0.114207   \n8          2.477410       0.038294  0.049436                  0.089550   \n9          2.084751       0.032776  0.016276                  0.075357   \n10         1.769646       0.018412  0.005313                  0.063967   \n11         1.531473       0.012306  0.002151                  0.055358   \n12         1.341688       0.007337  0.000820                  0.048497   \n13         1.000000       0.007328  0.000059                  0.036147   \n\n    cumulative_score  capture_rate  cumulative_capture_rate        gain  \\\n0           0.468185      0.108127                 0.108127  981.174427   \n1           0.389729      0.065477                 0.173604  554.706793   \n2           0.344019      0.051734                 0.225338  417.289444   \n3           0.312283      0.044072                 0.269410  340.809059   \n4           0.288175      0.040123                 0.309533  301.195477   \n5           0.216240      0.147856                 0.457389  194.440231   \n6           0.177049      0.103862                 0.561251  108.622686   \n7           0.149357      0.078746                 0.639997   49.829529   \n8           0.116902      0.103230                 0.743227    5.939771   \n9           0.091746      0.090672                 0.833899   -9.325786   \n10          0.074458      0.050944                 0.884843  -49.062265   \n11          0.062408      0.034042                 0.918885  -65.954762   \n12          0.053610      0.020299                 0.939183  -79.701561   \n13          0.037544      0.060817                 1.000000  -79.727696   \n\n    cumulative_gain  \n0        981.174427  \n1        767.940610  \n2        651.056888  \n3        573.511538  \n4        519.045216  \n5        356.395953  \n6        274.161694  \n7        215.955480  \n8        147.740996  \n9        108.475142  \n10        76.964602  \n11        53.147315  \n12        34.168827  \n13         0.000000  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>group</th>\n      <th>cumulative_data_fraction</th>\n      <th>lower_threshold</th>\n      <th>lift</th>\n      <th>cumulative_lift</th>\n      <th>response_rate</th>\n      <th>score</th>\n      <th>cumulative_response_rate</th>\n      <th>cumulative_score</th>\n      <th>capture_rate</th>\n      <th>cumulative_capture_rate</th>\n      <th>gain</th>\n      <th>cumulative_gain</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td></td>\n      <td>1</td>\n      <td>0.010001</td>\n      <td>0.355807</td>\n      <td>10.811744</td>\n      <td>10.811744</td>\n      <td>0.390808</td>\n      <td>0.468185</td>\n      <td>0.390808</td>\n      <td>0.468185</td>\n      <td>0.108127</td>\n      <td>0.108127</td>\n      <td>981.174427</td>\n      <td>981.174427</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td></td>\n      <td>2</td>\n      <td>0.020002</td>\n      <td>0.276656</td>\n      <td>6.547068</td>\n      <td>8.679406</td>\n      <td>0.236654</td>\n      <td>0.311273</td>\n      <td>0.313731</td>\n      <td>0.389729</td>\n      <td>0.065477</td>\n      <td>0.173604</td>\n      <td>554.706793</td>\n      <td>767.940610</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td></td>\n      <td>3</td>\n      <td>0.030003</td>\n      <td>0.232143</td>\n      <td>5.172894</td>\n      <td>7.510569</td>\n      <td>0.186983</td>\n      <td>0.252600</td>\n      <td>0.271482</td>\n      <td>0.344019</td>\n      <td>0.051734</td>\n      <td>0.225338</td>\n      <td>417.289444</td>\n      <td>651.056888</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td></td>\n      <td>4</td>\n      <td>0.040001</td>\n      <td>0.202677</td>\n      <td>4.408091</td>\n      <td>6.735115</td>\n      <td>0.159338</td>\n      <td>0.217047</td>\n      <td>0.243452</td>\n      <td>0.312283</td>\n      <td>0.044072</td>\n      <td>0.269410</td>\n      <td>340.809059</td>\n      <td>573.511538</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td></td>\n      <td>5</td>\n      <td>0.050002</td>\n      <td>0.180995</td>\n      <td>4.011955</td>\n      <td>6.190452</td>\n      <td>0.145019</td>\n      <td>0.191749</td>\n      <td>0.223764</td>\n      <td>0.288175</td>\n      <td>0.040123</td>\n      <td>0.309533</td>\n      <td>301.195477</td>\n      <td>519.045216</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td></td>\n      <td>6</td>\n      <td>0.100218</td>\n      <td>0.117647</td>\n      <td>2.944402</td>\n      <td>4.563960</td>\n      <td>0.106430</td>\n      <td>0.144611</td>\n      <td>0.164972</td>\n      <td>0.216240</td>\n      <td>0.147856</td>\n      <td>0.457389</td>\n      <td>194.440231</td>\n      <td>356.395953</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td></td>\n      <td>7</td>\n      <td>0.150002</td>\n      <td>0.081530</td>\n      <td>2.086227</td>\n      <td>3.741617</td>\n      <td>0.075410</td>\n      <td>0.098156</td>\n      <td>0.135247</td>\n      <td>0.177049</td>\n      <td>0.103862</td>\n      <td>0.561251</td>\n      <td>108.622686</td>\n      <td>274.161694</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td></td>\n      <td>8</td>\n      <td>0.202559</td>\n      <td>0.062500</td>\n      <td>1.498295</td>\n      <td>3.159555</td>\n      <td>0.054158</td>\n      <td>0.070321</td>\n      <td>0.114207</td>\n      <td>0.149357</td>\n      <td>0.078746</td>\n      <td>0.639997</td>\n      <td>49.829529</td>\n      <td>215.955480</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td></td>\n      <td>9</td>\n      <td>0.300002</td>\n      <td>0.030525</td>\n      <td>1.059398</td>\n      <td>2.477410</td>\n      <td>0.038294</td>\n      <td>0.049436</td>\n      <td>0.089550</td>\n      <td>0.116902</td>\n      <td>0.103230</td>\n      <td>0.743227</td>\n      <td>5.939771</td>\n      <td>147.740996</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td></td>\n      <td>10</td>\n      <td>0.399999</td>\n      <td>0.008321</td>\n      <td>0.906742</td>\n      <td>2.084751</td>\n      <td>0.032776</td>\n      <td>0.016276</td>\n      <td>0.075357</td>\n      <td>0.091746</td>\n      <td>0.090672</td>\n      <td>0.833899</td>\n      <td>-9.325786</td>\n      <td>108.475142</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td></td>\n      <td>11</td>\n      <td>0.500011</td>\n      <td>0.003247</td>\n      <td>0.509377</td>\n      <td>1.769646</td>\n      <td>0.018412</td>\n      <td>0.005313</td>\n      <td>0.063967</td>\n      <td>0.074458</td>\n      <td>0.050944</td>\n      <td>0.884843</td>\n      <td>-49.062265</td>\n      <td>76.964602</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td></td>\n      <td>12</td>\n      <td>0.600001</td>\n      <td>0.001321</td>\n      <td>0.340452</td>\n      <td>1.531473</td>\n      <td>0.012306</td>\n      <td>0.002151</td>\n      <td>0.055358</td>\n      <td>0.062408</td>\n      <td>0.034042</td>\n      <td>0.918885</td>\n      <td>-65.954762</td>\n      <td>53.147315</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td></td>\n      <td>13</td>\n      <td>0.700001</td>\n      <td>0.000419</td>\n      <td>0.202984</td>\n      <td>1.341688</td>\n      <td>0.007337</td>\n      <td>0.000820</td>\n      <td>0.048497</td>\n      <td>0.053610</td>\n      <td>0.020299</td>\n      <td>0.939183</td>\n      <td>-79.701561</td>\n      <td>34.168827</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td></td>\n      <td>14</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.202723</td>\n      <td>1.000000</td>\n      <td>0.007328</td>\n      <td>0.000059</td>\n      <td>0.036147</td>\n      <td>0.037544</td>\n      <td>0.060817</td>\n      <td>1.000000</td>\n      <td>-79.727696</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"stream","text":"\n\nModelMetricsBinomial: drf\n** Reported on validation data. **\n\nMSE: 0.03071157490750522\nRMSE: 0.17524718230974562\nLogLoss: 0.13267563440956423\nMean Per-Class Error: 0.24861547353029934\nAUC: 0.826378639356413\nAUCPR: 0.2236693606654231\nGini: 0.652757278712826\n\nConfusion Matrix (Act/Pred) for max f1 @ threshold = 0.1855035085498162: \n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"            FALSE    TRUE   Error               Rate\n0  FALSE  70080.0  2233.0  0.0309   (2233.0/72313.0)\n1   TRUE   1851.0   807.0  0.6964    (1851.0/2658.0)\n2  Total  71931.0  3040.0  0.0545   (4084.0/74971.0)","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>FALSE</th>\n      <th>TRUE</th>\n      <th>Error</th>\n      <th>Rate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>FALSE</td>\n      <td>70080.0</td>\n      <td>2233.0</td>\n      <td>0.0309</td>\n      <td>(2233.0/72313.0)</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>TRUE</td>\n      <td>1851.0</td>\n      <td>807.0</td>\n      <td>0.6964</td>\n      <td>(1851.0/2658.0)</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Total</td>\n      <td>71931.0</td>\n      <td>3040.0</td>\n      <td>0.0545</td>\n      <td>(4084.0/74971.0)</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"stream","text":"\nMaximum Metrics: Maximum metrics at their respective thresholds\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"                         metric  threshold         value    idx\n0                        max f1   0.185504      0.283257  164.0\n1                        max f2   0.092517      0.365133  245.0\n2                  max f0point5   0.288050      0.307828  107.0\n3                  max accuracy   0.507947      0.965133   43.0\n4                 max precision   0.996667      1.000000    0.0\n5                    max recall   0.000013      1.000000  399.0\n6               max specificity   0.996667      1.000000    0.0\n7              max absolute_mcc   0.185504      0.255698  164.0\n8    max min_per_class_accuracy   0.041619      0.747931  312.0\n9   max mean_per_class_accuracy   0.043816      0.751385  308.0\n10                      max tns   0.996667  72313.000000    0.0\n11                      max fns   0.996667   2655.000000    0.0\n12                      max fps   0.000013  72313.000000  399.0\n13                      max tps   0.000013   2658.000000  399.0\n14                      max tnr   0.996667      1.000000    0.0\n15                      max fnr   0.996667      0.998871    0.0\n16                      max fpr   0.000013      1.000000  399.0\n17                      max tpr   0.000013      1.000000  399.0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>metric</th>\n      <th>threshold</th>\n      <th>value</th>\n      <th>idx</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>max f1</td>\n      <td>0.185504</td>\n      <td>0.283257</td>\n      <td>164.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>max f2</td>\n      <td>0.092517</td>\n      <td>0.365133</td>\n      <td>245.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>max f0point5</td>\n      <td>0.288050</td>\n      <td>0.307828</td>\n      <td>107.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>max accuracy</td>\n      <td>0.507947</td>\n      <td>0.965133</td>\n      <td>43.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>max precision</td>\n      <td>0.996667</td>\n      <td>1.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>max recall</td>\n      <td>0.000013</td>\n      <td>1.000000</td>\n      <td>399.0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>max specificity</td>\n      <td>0.996667</td>\n      <td>1.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>max absolute_mcc</td>\n      <td>0.185504</td>\n      <td>0.255698</td>\n      <td>164.0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>max min_per_class_accuracy</td>\n      <td>0.041619</td>\n      <td>0.747931</td>\n      <td>312.0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>max mean_per_class_accuracy</td>\n      <td>0.043816</td>\n      <td>0.751385</td>\n      <td>308.0</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>max tns</td>\n      <td>0.996667</td>\n      <td>72313.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>max fns</td>\n      <td>0.996667</td>\n      <td>2655.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>max fps</td>\n      <td>0.000013</td>\n      <td>72313.000000</td>\n      <td>399.0</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>max tps</td>\n      <td>0.000013</td>\n      <td>2658.000000</td>\n      <td>399.0</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>max tnr</td>\n      <td>0.996667</td>\n      <td>1.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>max fnr</td>\n      <td>0.996667</td>\n      <td>0.998871</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>max fpr</td>\n      <td>0.000013</td>\n      <td>1.000000</td>\n      <td>399.0</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>max tpr</td>\n      <td>0.000013</td>\n      <td>1.000000</td>\n      <td>399.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"stream","text":"\nGains/Lift Table: Avg response rate:  3.55 %, avg score:  3.75 %\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"      group  cumulative_data_fraction  lower_threshold       lift  \\\n0         1                  0.010004         0.325072  12.372942   \n1         2                  0.020008         0.248567   7.070252   \n2         3                  0.030012         0.210902   5.716374   \n3         4                  0.040002         0.185958   4.933190   \n4         5                  0.050006         0.166226   3.723165   \n5         6                  0.100012         0.107784   3.069609   \n6         7                  0.150005         0.077850   2.016850   \n7         8                  0.200011         0.059189   1.497187   \n8         9                  0.300009         0.033730   1.087298   \n9        10                  0.400008         0.021259   0.714833   \n10       11                  0.500007         0.009280   0.579391   \n11       12                  0.600005         0.003341   0.334843   \n12       13                  0.700044         0.001418   0.221886   \n13       14                  0.800003         0.000542   0.184425   \n14       15                  0.900188         0.000097   0.123924   \n15       16                  1.000000         0.000000   0.079156   \n\n    cumulative_lift  response_rate     score  cumulative_response_rate  \\\n0         12.372942       0.438667  0.439038                  0.438667   \n1          9.721597       0.250667  0.282077                  0.344667   \n2          8.386523       0.202667  0.228056                  0.297333   \n3          7.524053       0.174900  0.197849                  0.266756   \n4          6.763673       0.132000  0.175703                  0.239797   \n5          4.916641       0.108829  0.133063                  0.174313   \n6          3.950216       0.071505  0.091579                  0.140050   \n7          3.336918       0.053081  0.066814                  0.118306   \n8          2.587078       0.038549  0.044971                  0.091722   \n9          2.119032       0.025343  0.025871                  0.075128   \n10         1.811112       0.020542  0.016667                  0.064211   \n11         1.565073       0.011871  0.005657                  0.055488   \n12         1.373127       0.007867  0.002230                  0.048682   \n13         1.224601       0.006539  0.000926                  0.043417   \n14         1.102102       0.004394  0.000294                  0.039074   \n15         1.000000       0.002806  0.000020                  0.035454   \n\n    cumulative_score  capture_rate  cumulative_capture_rate         gain  \\\n0           0.439038      0.123777                 0.123777  1137.294156   \n1           0.360557      0.070730                 0.194507   607.025232   \n2           0.316390      0.057186                 0.251693   471.637422   \n3           0.286785      0.049285                 0.300978   393.318958   \n4           0.264562      0.037246                 0.338224   272.316479   \n5           0.198813      0.153499                 0.491723   206.960893   \n6           0.163074      0.100828                 0.592551   101.684972   \n7           0.139008      0.074868                 0.667419    49.718671   \n8           0.107663      0.108728                 0.776147     8.729817   \n9           0.087216      0.071482                 0.847630   -28.516729   \n10          0.073107      0.057938                 0.905568   -42.060928   \n11          0.061865      0.033484                 0.939052   -66.515731   \n12          0.053343      0.022197                 0.961249   -77.811442   \n13          0.046794      0.018435                 0.979684   -81.557461   \n14          0.041619      0.012415                 0.992099   -87.607626   \n15          0.037467      0.007901                 1.000000   -92.084436   \n\n    cumulative_gain  \n0       1137.294156  \n1        872.159694  \n2        738.652270  \n3        652.405304  \n4        576.367262  \n5        391.664078  \n6        295.021566  \n7        233.691752  \n8        158.707775  \n9        111.903210  \n10        81.111204  \n11        56.507261  \n12        37.312660  \n13        22.460088  \n14        10.210227  \n15         0.000000  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>group</th>\n      <th>cumulative_data_fraction</th>\n      <th>lower_threshold</th>\n      <th>lift</th>\n      <th>cumulative_lift</th>\n      <th>response_rate</th>\n      <th>score</th>\n      <th>cumulative_response_rate</th>\n      <th>cumulative_score</th>\n      <th>capture_rate</th>\n      <th>cumulative_capture_rate</th>\n      <th>gain</th>\n      <th>cumulative_gain</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td></td>\n      <td>1</td>\n      <td>0.010004</td>\n      <td>0.325072</td>\n      <td>12.372942</td>\n      <td>12.372942</td>\n      <td>0.438667</td>\n      <td>0.439038</td>\n      <td>0.438667</td>\n      <td>0.439038</td>\n      <td>0.123777</td>\n      <td>0.123777</td>\n      <td>1137.294156</td>\n      <td>1137.294156</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td></td>\n      <td>2</td>\n      <td>0.020008</td>\n      <td>0.248567</td>\n      <td>7.070252</td>\n      <td>9.721597</td>\n      <td>0.250667</td>\n      <td>0.282077</td>\n      <td>0.344667</td>\n      <td>0.360557</td>\n      <td>0.070730</td>\n      <td>0.194507</td>\n      <td>607.025232</td>\n      <td>872.159694</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td></td>\n      <td>3</td>\n      <td>0.030012</td>\n      <td>0.210902</td>\n      <td>5.716374</td>\n      <td>8.386523</td>\n      <td>0.202667</td>\n      <td>0.228056</td>\n      <td>0.297333</td>\n      <td>0.316390</td>\n      <td>0.057186</td>\n      <td>0.251693</td>\n      <td>471.637422</td>\n      <td>738.652270</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td></td>\n      <td>4</td>\n      <td>0.040002</td>\n      <td>0.185958</td>\n      <td>4.933190</td>\n      <td>7.524053</td>\n      <td>0.174900</td>\n      <td>0.197849</td>\n      <td>0.266756</td>\n      <td>0.286785</td>\n      <td>0.049285</td>\n      <td>0.300978</td>\n      <td>393.318958</td>\n      <td>652.405304</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td></td>\n      <td>5</td>\n      <td>0.050006</td>\n      <td>0.166226</td>\n      <td>3.723165</td>\n      <td>6.763673</td>\n      <td>0.132000</td>\n      <td>0.175703</td>\n      <td>0.239797</td>\n      <td>0.264562</td>\n      <td>0.037246</td>\n      <td>0.338224</td>\n      <td>272.316479</td>\n      <td>576.367262</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td></td>\n      <td>6</td>\n      <td>0.100012</td>\n      <td>0.107784</td>\n      <td>3.069609</td>\n      <td>4.916641</td>\n      <td>0.108829</td>\n      <td>0.133063</td>\n      <td>0.174313</td>\n      <td>0.198813</td>\n      <td>0.153499</td>\n      <td>0.491723</td>\n      <td>206.960893</td>\n      <td>391.664078</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td></td>\n      <td>7</td>\n      <td>0.150005</td>\n      <td>0.077850</td>\n      <td>2.016850</td>\n      <td>3.950216</td>\n      <td>0.071505</td>\n      <td>0.091579</td>\n      <td>0.140050</td>\n      <td>0.163074</td>\n      <td>0.100828</td>\n      <td>0.592551</td>\n      <td>101.684972</td>\n      <td>295.021566</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td></td>\n      <td>8</td>\n      <td>0.200011</td>\n      <td>0.059189</td>\n      <td>1.497187</td>\n      <td>3.336918</td>\n      <td>0.053081</td>\n      <td>0.066814</td>\n      <td>0.118306</td>\n      <td>0.139008</td>\n      <td>0.074868</td>\n      <td>0.667419</td>\n      <td>49.718671</td>\n      <td>233.691752</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td></td>\n      <td>9</td>\n      <td>0.300009</td>\n      <td>0.033730</td>\n      <td>1.087298</td>\n      <td>2.587078</td>\n      <td>0.038549</td>\n      <td>0.044971</td>\n      <td>0.091722</td>\n      <td>0.107663</td>\n      <td>0.108728</td>\n      <td>0.776147</td>\n      <td>8.729817</td>\n      <td>158.707775</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td></td>\n      <td>10</td>\n      <td>0.400008</td>\n      <td>0.021259</td>\n      <td>0.714833</td>\n      <td>2.119032</td>\n      <td>0.025343</td>\n      <td>0.025871</td>\n      <td>0.075128</td>\n      <td>0.087216</td>\n      <td>0.071482</td>\n      <td>0.847630</td>\n      <td>-28.516729</td>\n      <td>111.903210</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td></td>\n      <td>11</td>\n      <td>0.500007</td>\n      <td>0.009280</td>\n      <td>0.579391</td>\n      <td>1.811112</td>\n      <td>0.020542</td>\n      <td>0.016667</td>\n      <td>0.064211</td>\n      <td>0.073107</td>\n      <td>0.057938</td>\n      <td>0.905568</td>\n      <td>-42.060928</td>\n      <td>81.111204</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td></td>\n      <td>12</td>\n      <td>0.600005</td>\n      <td>0.003341</td>\n      <td>0.334843</td>\n      <td>1.565073</td>\n      <td>0.011871</td>\n      <td>0.005657</td>\n      <td>0.055488</td>\n      <td>0.061865</td>\n      <td>0.033484</td>\n      <td>0.939052</td>\n      <td>-66.515731</td>\n      <td>56.507261</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td></td>\n      <td>13</td>\n      <td>0.700044</td>\n      <td>0.001418</td>\n      <td>0.221886</td>\n      <td>1.373127</td>\n      <td>0.007867</td>\n      <td>0.002230</td>\n      <td>0.048682</td>\n      <td>0.053343</td>\n      <td>0.022197</td>\n      <td>0.961249</td>\n      <td>-77.811442</td>\n      <td>37.312660</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td></td>\n      <td>14</td>\n      <td>0.800003</td>\n      <td>0.000542</td>\n      <td>0.184425</td>\n      <td>1.224601</td>\n      <td>0.006539</td>\n      <td>0.000926</td>\n      <td>0.043417</td>\n      <td>0.046794</td>\n      <td>0.018435</td>\n      <td>0.979684</td>\n      <td>-81.557461</td>\n      <td>22.460088</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td></td>\n      <td>15</td>\n      <td>0.900188</td>\n      <td>0.000097</td>\n      <td>0.123924</td>\n      <td>1.102102</td>\n      <td>0.004394</td>\n      <td>0.000294</td>\n      <td>0.039074</td>\n      <td>0.041619</td>\n      <td>0.012415</td>\n      <td>0.992099</td>\n      <td>-87.607626</td>\n      <td>10.210227</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td></td>\n      <td>16</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.079156</td>\n      <td>1.000000</td>\n      <td>0.002806</td>\n      <td>0.000020</td>\n      <td>0.035454</td>\n      <td>0.037467</td>\n      <td>0.007901</td>\n      <td>1.000000</td>\n      <td>-92.084436</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"stream","text":"\n\nScoring History: \n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"               timestamp           duration  number_of_trees  training_rmse  \\\n0    2020-06-27 21:13:38          0.099 sec              0.0            NaN   \n1    2020-06-27 21:13:41          3.134 sec              1.0       0.238486   \n2    2020-06-27 21:13:50         12.298 sec              7.0       0.207189   \n3    2020-06-27 21:14:06         28.117 sec             20.0       0.186162   \n4    2020-06-27 21:14:27         49.576 sec             39.0       0.180613   \n5    2020-06-27 21:14:41   1 min  3.557 sec             50.0       0.179361   \n\n   training_logloss  training_auc  training_pr_auc  training_lift  \\\n0               NaN           NaN              NaN            NaN   \n1          1.772648      0.579630         0.068566       4.199508   \n2          0.867876      0.645735         0.097043       6.483888   \n3          0.367441      0.742657         0.153089       9.113771   \n4          0.221133      0.790126         0.188393      10.519535   \n5          0.188080      0.803437         0.198803      10.811744   \n\n   training_classification_error  validation_rmse  validation_logloss  \\\n0                            NaN              NaN                 NaN   \n1                       0.074234         0.235348            1.725575   \n2                       0.095799         0.184272            0.355434   \n3                       0.068297         0.177654            0.177910   \n4                       0.067226         0.175795            0.140814   \n5                       0.067551         0.175247            0.132676   \n\n   validation_auc  validation_pr_auc  validation_lift  \\\n0             NaN                NaN              NaN   \n1        0.585285           0.071755         4.582604   \n2        0.741514           0.158701         9.234414   \n3        0.802288           0.200073        11.399995   \n4        0.819720           0.217811        12.034472   \n5        0.826379           0.223669        12.372942   \n\n   validation_classification_error  \n0                              NaN  \n1                         0.070080  \n2                         0.074255  \n3                         0.059570  \n4                         0.063064  \n5                         0.054474  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>timestamp</th>\n      <th>duration</th>\n      <th>number_of_trees</th>\n      <th>training_rmse</th>\n      <th>training_logloss</th>\n      <th>training_auc</th>\n      <th>training_pr_auc</th>\n      <th>training_lift</th>\n      <th>training_classification_error</th>\n      <th>validation_rmse</th>\n      <th>validation_logloss</th>\n      <th>validation_auc</th>\n      <th>validation_pr_auc</th>\n      <th>validation_lift</th>\n      <th>validation_classification_error</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td></td>\n      <td>2020-06-27 21:13:38</td>\n      <td>0.099 sec</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td></td>\n      <td>2020-06-27 21:13:41</td>\n      <td>3.134 sec</td>\n      <td>1.0</td>\n      <td>0.238486</td>\n      <td>1.772648</td>\n      <td>0.579630</td>\n      <td>0.068566</td>\n      <td>4.199508</td>\n      <td>0.074234</td>\n      <td>0.235348</td>\n      <td>1.725575</td>\n      <td>0.585285</td>\n      <td>0.071755</td>\n      <td>4.582604</td>\n      <td>0.070080</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td></td>\n      <td>2020-06-27 21:13:50</td>\n      <td>12.298 sec</td>\n      <td>7.0</td>\n      <td>0.207189</td>\n      <td>0.867876</td>\n      <td>0.645735</td>\n      <td>0.097043</td>\n      <td>6.483888</td>\n      <td>0.095799</td>\n      <td>0.184272</td>\n      <td>0.355434</td>\n      <td>0.741514</td>\n      <td>0.158701</td>\n      <td>9.234414</td>\n      <td>0.074255</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td></td>\n      <td>2020-06-27 21:14:06</td>\n      <td>28.117 sec</td>\n      <td>20.0</td>\n      <td>0.186162</td>\n      <td>0.367441</td>\n      <td>0.742657</td>\n      <td>0.153089</td>\n      <td>9.113771</td>\n      <td>0.068297</td>\n      <td>0.177654</td>\n      <td>0.177910</td>\n      <td>0.802288</td>\n      <td>0.200073</td>\n      <td>11.399995</td>\n      <td>0.059570</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td></td>\n      <td>2020-06-27 21:14:27</td>\n      <td>49.576 sec</td>\n      <td>39.0</td>\n      <td>0.180613</td>\n      <td>0.221133</td>\n      <td>0.790126</td>\n      <td>0.188393</td>\n      <td>10.519535</td>\n      <td>0.067226</td>\n      <td>0.175795</td>\n      <td>0.140814</td>\n      <td>0.819720</td>\n      <td>0.217811</td>\n      <td>12.034472</td>\n      <td>0.063064</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td></td>\n      <td>2020-06-27 21:14:41</td>\n      <td>1 min  3.557 sec</td>\n      <td>50.0</td>\n      <td>0.179361</td>\n      <td>0.188080</td>\n      <td>0.803437</td>\n      <td>0.198803</td>\n      <td>10.811744</td>\n      <td>0.067551</td>\n      <td>0.175247</td>\n      <td>0.132676</td>\n      <td>0.826379</td>\n      <td>0.223669</td>\n      <td>12.372942</td>\n      <td>0.054474</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"stream","text":"\nVariable Importances: \n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"                           variable  relative_importance  scaled_importance  \\\n0                    PROPERTY_STATE         42236.546875           1.000000   \n1                      CREDIT_SCORE         38299.613281           0.906788   \n2                       SELLER_NAME         31417.185547           0.743839   \n3                     SERVICER_NAME         25920.623047           0.613701   \n4     ORIGINAL_DEBT_TO_INCOME_RATIO         23534.988281           0.557219   \n5                      ORIGINAL_UPB         23414.837891           0.554374   \n6     METROPOLITAN_STATISTICAL_AREA         20642.494141           0.488735   \n7            ORIGINAL_INTEREST_RATE         20437.968750           0.483893   \n8            ORIGINAL_LOAN_TO_VALUE         13487.042969           0.319322   \n9                       POSTAL_CODE         12512.929688           0.296258   \n10  ORIGINAL_COMBINED_LOAN_TO_VALUE         11854.041016           0.280658   \n11    MORTGAGE_INSURANCE_PERCENTAGE          7334.125000           0.173644   \n12                     LOAN_PURPOSE          7286.483887           0.172516   \n13                    MATURITY_DATE          6375.242676           0.150941   \n14               FIRST_PAYMENT_DATE          6201.092773           0.146818   \n15        FIRST_TIME_HOMEBUYER_FLAG          5562.740234           0.131704   \n16                    PROPERTY_TYPE          5073.029297           0.120110   \n17                          CHANNEL          4179.753418           0.098961   \n18              NUMBER_OF_BORROWERS          4068.819824           0.096334   \n19                 OCCUPANCY_STATUS          2614.186768           0.061894   \n\n    percentage  \n0     0.134475  \n1     0.121940  \n2     0.100028  \n3     0.082527  \n4     0.074932  \n5     0.074549  \n6     0.065723  \n7     0.065071  \n8     0.042941  \n9     0.039839  \n10    0.037742  \n11    0.023351  \n12    0.023199  \n13    0.020298  \n14    0.019743  \n15    0.017711  \n16    0.016152  \n17    0.013308  \n18    0.012955  \n19    0.008323  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>variable</th>\n      <th>relative_importance</th>\n      <th>scaled_importance</th>\n      <th>percentage</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>PROPERTY_STATE</td>\n      <td>42236.546875</td>\n      <td>1.000000</td>\n      <td>0.134475</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>CREDIT_SCORE</td>\n      <td>38299.613281</td>\n      <td>0.906788</td>\n      <td>0.121940</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>SELLER_NAME</td>\n      <td>31417.185547</td>\n      <td>0.743839</td>\n      <td>0.100028</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>SERVICER_NAME</td>\n      <td>25920.623047</td>\n      <td>0.613701</td>\n      <td>0.082527</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ORIGINAL_DEBT_TO_INCOME_RATIO</td>\n      <td>23534.988281</td>\n      <td>0.557219</td>\n      <td>0.074932</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>ORIGINAL_UPB</td>\n      <td>23414.837891</td>\n      <td>0.554374</td>\n      <td>0.074549</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>METROPOLITAN_STATISTICAL_AREA</td>\n      <td>20642.494141</td>\n      <td>0.488735</td>\n      <td>0.065723</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>ORIGINAL_INTEREST_RATE</td>\n      <td>20437.968750</td>\n      <td>0.483893</td>\n      <td>0.065071</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>ORIGINAL_LOAN_TO_VALUE</td>\n      <td>13487.042969</td>\n      <td>0.319322</td>\n      <td>0.042941</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>POSTAL_CODE</td>\n      <td>12512.929688</td>\n      <td>0.296258</td>\n      <td>0.039839</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>ORIGINAL_COMBINED_LOAN_TO_VALUE</td>\n      <td>11854.041016</td>\n      <td>0.280658</td>\n      <td>0.037742</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>MORTGAGE_INSURANCE_PERCENTAGE</td>\n      <td>7334.125000</td>\n      <td>0.173644</td>\n      <td>0.023351</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>LOAN_PURPOSE</td>\n      <td>7286.483887</td>\n      <td>0.172516</td>\n      <td>0.023199</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>MATURITY_DATE</td>\n      <td>6375.242676</td>\n      <td>0.150941</td>\n      <td>0.020298</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>FIRST_PAYMENT_DATE</td>\n      <td>6201.092773</td>\n      <td>0.146818</td>\n      <td>0.019743</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>FIRST_TIME_HOMEBUYER_FLAG</td>\n      <td>5562.740234</td>\n      <td>0.131704</td>\n      <td>0.017711</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>PROPERTY_TYPE</td>\n      <td>5073.029297</td>\n      <td>0.120110</td>\n      <td>0.016152</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>CHANNEL</td>\n      <td>4179.753418</td>\n      <td>0.098961</td>\n      <td>0.013308</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>NUMBER_OF_BORROWERS</td>\n      <td>4068.819824</td>\n      <td>0.096334</td>\n      <td>0.012955</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>OCCUPANCY_STATUS</td>\n      <td>2614.186768</td>\n      <td>0.061894</td>\n      <td>0.008323</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"stream","text":"\nSee the whole table with table.as_data_frame()\n","name":"stdout"},{"output_type":"execute_result","execution_count":21,"data":{"text/plain":""},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"In this case, we see that the RF model is far from overfitting because the training error is still lower than the validation error, and that means that we can probably do some tuning to improve our model.\n\nWe can also generate the variable importance plot:\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"rf.plot(metric='auc')","execution_count":22,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf.varimp_plot(20)","execution_count":23,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 1008x720 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"metadata":{},"cell_type":"markdown","source":"It is interesting to see that for our RF model, PROPERTY_STATE Is the most important variable, implying that the prediction of whether a loan could be delinquent or not depends on the state where someone is trying to buy that property. The second most important is a more intuitive one, which is the CREDIT_SCORE, as one could expect someone with really good credit to pay their loans fully.\n\nIf you want to check the options of what you can print from your model, just type the name of your model along with a dot (.) and press tab. You should see a drop-down menu like the one shown in the image below."},{"metadata":{"trusted":true},"cell_type":"code","source":"rf.accuracy()","execution_count":24,"outputs":[{"output_type":"execute_result","execution_count":24,"data":{"text/plain":"[[0.5709275782581964, 0.9642730709057065]]"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"- The first parameter shown in the list above is the threshold, and the second value is the accuracy."},{"metadata":{"trusted":true},"cell_type":"code","source":"rf.F1()","execution_count":25,"outputs":[{"output_type":"execute_result","execution_count":25,"data":{"text/plain":"[[0.1714152473716729, 0.2621386472074095]]"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"- You will see the output in a list format. First, you will see the threshold, and then the actual value, the same as in the accuracy. You could also specify the threshold inside the parenthesis, that way you use the threshold that you want.\n\nLet's take a look at the first ten predictions in our validation set, and compare it to our first model."},{"metadata":{"trusted":true},"cell_type":"code","source":"rf.predict(valid)","execution_count":26,"outputs":[{"output_type":"stream","text":"drf prediction progress: |████████████████████████████████████████████████| 100%\n","name":"stdout"},{"output_type":"display_data","data":{"text/html":"<table>\n<thead>\n<tr><th>predict  </th><th style=\"text-align: right;\">   FALSE</th><th style=\"text-align: right;\">       TRUE</th></tr>\n</thead>\n<tbody>\n<tr><td>FALSE    </td><td style=\"text-align: right;\">0.89606 </td><td style=\"text-align: right;\">0.10394    </td></tr>\n<tr><td>FALSE    </td><td style=\"text-align: right;\">0.989924</td><td style=\"text-align: right;\">0.0100759  </td></tr>\n<tr><td>FALSE    </td><td style=\"text-align: right;\">0.99179 </td><td style=\"text-align: right;\">0.00820961 </td></tr>\n<tr><td>FALSE    </td><td style=\"text-align: right;\">0.994186</td><td style=\"text-align: right;\">0.005814   </td></tr>\n<tr><td>FALSE    </td><td style=\"text-align: right;\">0.999108</td><td style=\"text-align: right;\">0.00089201 </td></tr>\n<tr><td>TRUE     </td><td style=\"text-align: right;\">0.726028</td><td style=\"text-align: right;\">0.273972   </td></tr>\n<tr><td>FALSE    </td><td style=\"text-align: right;\">0.999971</td><td style=\"text-align: right;\">2.88916e-05</td></tr>\n<tr><td>FALSE    </td><td style=\"text-align: right;\">0.999835</td><td style=\"text-align: right;\">0.000164608</td></tr>\n<tr><td>FALSE    </td><td style=\"text-align: right;\">0.847452</td><td style=\"text-align: right;\">0.152548   </td></tr>\n<tr><td>FALSE    </td><td style=\"text-align: right;\">1       </td><td style=\"text-align: right;\">0          </td></tr>\n</tbody>\n</table>"},"metadata":{}},{"output_type":"execute_result","execution_count":26,"data":{"text/plain":""},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"Both models, GLM and RF, made the same predictions in the first ten predictions. For e.g., the TRUE prediction for the sixth row is the same; there is a different probability, but the prediction is the same.\n\nAgain, save the model performance on the validation data"},{"metadata":{},"cell_type":"markdown","source":"### save the model:"},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_default_per = rf.model_performance(valid)","execution_count":27,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Build Gradient Boosting Machine"},{"metadata":{},"cell_type":"markdown","source":"Gradient Boosting Machine (for Regression and Classification) is a forward learning ensemble method. H2O's GBM sequentially builds classification trees on all the features of the dataset in a fully distributed way - each tree is built in parallel. H2O's GBM fits consecutive trees where each solves for the net loss of the prior trees.\nSometimes GBMs tend to be the best possible models because they are robust and directly optimize the cost function. On the other hand, they tend to overfit, so you need to find the proper stopping point; they are sensitive to noise, and they have several hyper-parameters.\n\nDefining a GBM model is as simple as the other models we have been working with."},{"metadata":{"trusted":true},"cell_type":"code","source":"gbm = H2OGradientBoostingEstimator(seed = 42, model_id='default_gbm')\n%time gbm.train(x = x, y = y, training_frame=train, validation_frame=valid)","execution_count":28,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.7/site-packages/h2o/estimators/estimator_base.py:200: RuntimeWarning: Dropping bad and constant columns: [LOAN_SEQUENCE_NUMBER]\n  warnings.warn(mesg[\"message\"], RuntimeWarning)\n","name":"stderr"},{"output_type":"stream","text":"gbm Model Build progress: |███████████████████████████████████████████████| 100%\nCPU times: user 496 ms, sys: 45.5 ms, total: 541 ms\nWall time: 40.8 s\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"gbm","execution_count":29,"outputs":[{"output_type":"stream","text":"Model Details\n=============\nH2OGradientBoostingEstimator :  Gradient Boosting Machine\nModel Key:  default_gbm\n\n\nModel Summary: \n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"     number_of_trees  number_of_internal_trees  model_size_in_bytes  \\\n0               50.0                      50.0              28336.0   \n\n   min_depth  max_depth  mean_depth  min_leaves  max_leaves  mean_leaves  \n0        5.0        5.0         5.0        25.0        32.0        30.96  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>number_of_trees</th>\n      <th>number_of_internal_trees</th>\n      <th>model_size_in_bytes</th>\n      <th>min_depth</th>\n      <th>max_depth</th>\n      <th>mean_depth</th>\n      <th>min_leaves</th>\n      <th>max_leaves</th>\n      <th>mean_leaves</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td></td>\n      <td>50.0</td>\n      <td>50.0</td>\n      <td>28336.0</td>\n      <td>5.0</td>\n      <td>5.0</td>\n      <td>5.0</td>\n      <td>25.0</td>\n      <td>32.0</td>\n      <td>30.96</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"stream","text":"\n\nModelMetricsBinomial: gbm\n** Reported on train data. **\n\nMSE: 0.029506421363469686\nRMSE: 0.17177433266780484\nLogLoss: 0.11505127038888421\nMean Per-Class Error: 0.20226265196401738\nAUC: 0.8781516490712882\nAUCPR: 0.29501524692178666\nGini: 0.7563032981425764\n\nConfusion Matrix (Act/Pred) for max f1 @ threshold = 0.15429695309862027: \n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"             FALSE     TRUE   Error                 Rate\n0  FALSE  326552.0  11055.0  0.0327   (11055.0/337607.0)\n1   TRUE    7745.0   4916.0  0.6117     (7745.0/12661.0)\n2  Total  334297.0  15971.0  0.0537   (18800.0/350268.0)","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>FALSE</th>\n      <th>TRUE</th>\n      <th>Error</th>\n      <th>Rate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>FALSE</td>\n      <td>326552.0</td>\n      <td>11055.0</td>\n      <td>0.0327</td>\n      <td>(11055.0/337607.0)</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>TRUE</td>\n      <td>7745.0</td>\n      <td>4916.0</td>\n      <td>0.6117</td>\n      <td>(7745.0/12661.0)</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Total</td>\n      <td>334297.0</td>\n      <td>15971.0</td>\n      <td>0.0537</td>\n      <td>(18800.0/350268.0)</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"stream","text":"\nMaximum Metrics: Maximum metrics at their respective thresholds\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"                         metric  threshold          value    idx\n0                        max f1   0.154297       0.343392  194.0\n1                        max f2   0.071922       0.428489  265.0\n2                  max f0point5   0.269743       0.364851  133.0\n3                  max accuracy   0.451590       0.965027   71.0\n4                 max precision   0.896728       1.000000    0.0\n5                    max recall   0.003220       1.000000  398.0\n6               max specificity   0.896728       1.000000    0.0\n7              max absolute_mcc   0.141960       0.318392  203.0\n8    max min_per_class_accuracy   0.039489       0.796986  309.0\n9   max mean_per_class_accuracy   0.037540       0.797737  312.0\n10                      max tns   0.896728  337607.000000    0.0\n11                      max fns   0.896728   12659.000000    0.0\n12                      max fps   0.002897  337607.000000  399.0\n13                      max tps   0.003220   12661.000000  398.0\n14                      max tnr   0.896728       1.000000    0.0\n15                      max fnr   0.896728       0.999842    0.0\n16                      max fpr   0.002897       1.000000  399.0\n17                      max tpr   0.003220       1.000000  398.0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>metric</th>\n      <th>threshold</th>\n      <th>value</th>\n      <th>idx</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>max f1</td>\n      <td>0.154297</td>\n      <td>0.343392</td>\n      <td>194.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>max f2</td>\n      <td>0.071922</td>\n      <td>0.428489</td>\n      <td>265.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>max f0point5</td>\n      <td>0.269743</td>\n      <td>0.364851</td>\n      <td>133.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>max accuracy</td>\n      <td>0.451590</td>\n      <td>0.965027</td>\n      <td>71.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>max precision</td>\n      <td>0.896728</td>\n      <td>1.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>max recall</td>\n      <td>0.003220</td>\n      <td>1.000000</td>\n      <td>398.0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>max specificity</td>\n      <td>0.896728</td>\n      <td>1.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>max absolute_mcc</td>\n      <td>0.141960</td>\n      <td>0.318392</td>\n      <td>203.0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>max min_per_class_accuracy</td>\n      <td>0.039489</td>\n      <td>0.796986</td>\n      <td>309.0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>max mean_per_class_accuracy</td>\n      <td>0.037540</td>\n      <td>0.797737</td>\n      <td>312.0</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>max tns</td>\n      <td>0.896728</td>\n      <td>337607.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>max fns</td>\n      <td>0.896728</td>\n      <td>12659.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>max fps</td>\n      <td>0.002897</td>\n      <td>337607.000000</td>\n      <td>399.0</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>max tps</td>\n      <td>0.003220</td>\n      <td>12661.000000</td>\n      <td>398.0</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>max tnr</td>\n      <td>0.896728</td>\n      <td>1.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>max fnr</td>\n      <td>0.896728</td>\n      <td>0.999842</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>max fpr</td>\n      <td>0.002897</td>\n      <td>1.000000</td>\n      <td>399.0</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>max tpr</td>\n      <td>0.003220</td>\n      <td>1.000000</td>\n      <td>398.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"stream","text":"\nGains/Lift Table: Avg response rate:  3.61 %, avg score:  3.62 %\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"      group  cumulative_data_fraction  lower_threshold       lift  \\\n0         1                  0.010001         0.345972  14.286666   \n1         2                  0.020002         0.247640   9.011103   \n2         3                  0.030003         0.197997   7.139384   \n3         4                  0.040001         0.166786   5.482464   \n4         5                  0.050002         0.144748   4.880685   \n5         6                  0.100001         0.085874   3.405812   \n6         7                  0.150002         0.059880   2.250930   \n7         8                  0.200001         0.044609   1.525981   \n8         9                  0.300002         0.027793   0.992017   \n9        10                  0.399999         0.019080   0.537884   \n10       11                  0.500000         0.013850   0.326987   \n11       12                  0.600001         0.010488   0.203774   \n12       13                  0.699998         0.008156   0.134274   \n13       14                  0.799999         0.006371   0.073453   \n14       15                  0.899999         0.004872   0.044230   \n15       16                  1.000000         0.002477   0.015796   \n\n    cumulative_lift  response_rate     score  cumulative_response_rate  \\\n0         14.286666       0.516415  0.479898                  0.516415   \n1         11.648884       0.325721  0.290490                  0.421068   \n2         10.145718       0.258065  0.220582                  0.366733   \n3          8.980154       0.198172  0.181255                  0.324602   \n4          8.160213       0.176420  0.155075                  0.294964   \n5          5.783080       0.123109  0.110567                  0.209039   \n6          4.605675       0.081363  0.071572                  0.166480   \n7          3.835773       0.055159  0.051662                  0.138650   \n8          2.887854       0.035858  0.035153                  0.104386   \n9          2.300375       0.019443  0.023012                  0.083151   \n10         1.905695       0.011819  0.016267                  0.068884   \n11         1.622040       0.007366  0.012055                  0.058631   \n12         1.409506       0.004854  0.009260                  0.050949   \n13         1.242498       0.002655  0.007231                  0.044912   \n14         1.109357       0.001599  0.005606                  0.040099   \n15         1.000000       0.000571  0.004052                  0.036147   \n\n    cumulative_score  capture_rate  cumulative_capture_rate         gain  \\\n0           0.479898      0.142880                 0.142880  1328.666572   \n1           0.385194      0.090119                 0.232999   801.110315   \n2           0.330323      0.071400                 0.304399   613.938409   \n3           0.293064      0.054814                 0.359213   448.246392   \n4           0.265465      0.048811                 0.408025   388.068514   \n5           0.188018      0.170287                 0.578311   240.581193   \n6           0.149202      0.112550                 0.690862   125.092991   \n7           0.124817      0.076297                 0.767159    52.598067   \n8           0.094929      0.099202                 0.866361    -0.798292   \n9           0.076950      0.053787                 0.920148   -46.211551   \n10          0.064814      0.032699                 0.952847   -67.301348   \n11          0.056021      0.020378                 0.973225   -79.622579   \n12          0.049341      0.013427                 0.986652   -86.572634   \n13          0.044077      0.007345                 0.993997   -92.654651   \n14          0.039802      0.004423                 0.998420   -95.576994   \n15          0.036227      0.001580                 1.000000   -98.420355   \n\n    cumulative_gain  \n0       1328.666572  \n1       1064.888444  \n2        914.571765  \n3        798.015384  \n4        716.021329  \n5        478.308048  \n6        360.567455  \n7        283.577306  \n8        188.785440  \n9        130.037450  \n10        90.569465  \n11        62.203990  \n12        40.950620  \n13        24.249842  \n14        10.935664  \n15         0.000000  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>group</th>\n      <th>cumulative_data_fraction</th>\n      <th>lower_threshold</th>\n      <th>lift</th>\n      <th>cumulative_lift</th>\n      <th>response_rate</th>\n      <th>score</th>\n      <th>cumulative_response_rate</th>\n      <th>cumulative_score</th>\n      <th>capture_rate</th>\n      <th>cumulative_capture_rate</th>\n      <th>gain</th>\n      <th>cumulative_gain</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td></td>\n      <td>1</td>\n      <td>0.010001</td>\n      <td>0.345972</td>\n      <td>14.286666</td>\n      <td>14.286666</td>\n      <td>0.516415</td>\n      <td>0.479898</td>\n      <td>0.516415</td>\n      <td>0.479898</td>\n      <td>0.142880</td>\n      <td>0.142880</td>\n      <td>1328.666572</td>\n      <td>1328.666572</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td></td>\n      <td>2</td>\n      <td>0.020002</td>\n      <td>0.247640</td>\n      <td>9.011103</td>\n      <td>11.648884</td>\n      <td>0.325721</td>\n      <td>0.290490</td>\n      <td>0.421068</td>\n      <td>0.385194</td>\n      <td>0.090119</td>\n      <td>0.232999</td>\n      <td>801.110315</td>\n      <td>1064.888444</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td></td>\n      <td>3</td>\n      <td>0.030003</td>\n      <td>0.197997</td>\n      <td>7.139384</td>\n      <td>10.145718</td>\n      <td>0.258065</td>\n      <td>0.220582</td>\n      <td>0.366733</td>\n      <td>0.330323</td>\n      <td>0.071400</td>\n      <td>0.304399</td>\n      <td>613.938409</td>\n      <td>914.571765</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td></td>\n      <td>4</td>\n      <td>0.040001</td>\n      <td>0.166786</td>\n      <td>5.482464</td>\n      <td>8.980154</td>\n      <td>0.198172</td>\n      <td>0.181255</td>\n      <td>0.324602</td>\n      <td>0.293064</td>\n      <td>0.054814</td>\n      <td>0.359213</td>\n      <td>448.246392</td>\n      <td>798.015384</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td></td>\n      <td>5</td>\n      <td>0.050002</td>\n      <td>0.144748</td>\n      <td>4.880685</td>\n      <td>8.160213</td>\n      <td>0.176420</td>\n      <td>0.155075</td>\n      <td>0.294964</td>\n      <td>0.265465</td>\n      <td>0.048811</td>\n      <td>0.408025</td>\n      <td>388.068514</td>\n      <td>716.021329</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td></td>\n      <td>6</td>\n      <td>0.100001</td>\n      <td>0.085874</td>\n      <td>3.405812</td>\n      <td>5.783080</td>\n      <td>0.123109</td>\n      <td>0.110567</td>\n      <td>0.209039</td>\n      <td>0.188018</td>\n      <td>0.170287</td>\n      <td>0.578311</td>\n      <td>240.581193</td>\n      <td>478.308048</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td></td>\n      <td>7</td>\n      <td>0.150002</td>\n      <td>0.059880</td>\n      <td>2.250930</td>\n      <td>4.605675</td>\n      <td>0.081363</td>\n      <td>0.071572</td>\n      <td>0.166480</td>\n      <td>0.149202</td>\n      <td>0.112550</td>\n      <td>0.690862</td>\n      <td>125.092991</td>\n      <td>360.567455</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td></td>\n      <td>8</td>\n      <td>0.200001</td>\n      <td>0.044609</td>\n      <td>1.525981</td>\n      <td>3.835773</td>\n      <td>0.055159</td>\n      <td>0.051662</td>\n      <td>0.138650</td>\n      <td>0.124817</td>\n      <td>0.076297</td>\n      <td>0.767159</td>\n      <td>52.598067</td>\n      <td>283.577306</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td></td>\n      <td>9</td>\n      <td>0.300002</td>\n      <td>0.027793</td>\n      <td>0.992017</td>\n      <td>2.887854</td>\n      <td>0.035858</td>\n      <td>0.035153</td>\n      <td>0.104386</td>\n      <td>0.094929</td>\n      <td>0.099202</td>\n      <td>0.866361</td>\n      <td>-0.798292</td>\n      <td>188.785440</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td></td>\n      <td>10</td>\n      <td>0.399999</td>\n      <td>0.019080</td>\n      <td>0.537884</td>\n      <td>2.300375</td>\n      <td>0.019443</td>\n      <td>0.023012</td>\n      <td>0.083151</td>\n      <td>0.076950</td>\n      <td>0.053787</td>\n      <td>0.920148</td>\n      <td>-46.211551</td>\n      <td>130.037450</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td></td>\n      <td>11</td>\n      <td>0.500000</td>\n      <td>0.013850</td>\n      <td>0.326987</td>\n      <td>1.905695</td>\n      <td>0.011819</td>\n      <td>0.016267</td>\n      <td>0.068884</td>\n      <td>0.064814</td>\n      <td>0.032699</td>\n      <td>0.952847</td>\n      <td>-67.301348</td>\n      <td>90.569465</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td></td>\n      <td>12</td>\n      <td>0.600001</td>\n      <td>0.010488</td>\n      <td>0.203774</td>\n      <td>1.622040</td>\n      <td>0.007366</td>\n      <td>0.012055</td>\n      <td>0.058631</td>\n      <td>0.056021</td>\n      <td>0.020378</td>\n      <td>0.973225</td>\n      <td>-79.622579</td>\n      <td>62.203990</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td></td>\n      <td>13</td>\n      <td>0.699998</td>\n      <td>0.008156</td>\n      <td>0.134274</td>\n      <td>1.409506</td>\n      <td>0.004854</td>\n      <td>0.009260</td>\n      <td>0.050949</td>\n      <td>0.049341</td>\n      <td>0.013427</td>\n      <td>0.986652</td>\n      <td>-86.572634</td>\n      <td>40.950620</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td></td>\n      <td>14</td>\n      <td>0.799999</td>\n      <td>0.006371</td>\n      <td>0.073453</td>\n      <td>1.242498</td>\n      <td>0.002655</td>\n      <td>0.007231</td>\n      <td>0.044912</td>\n      <td>0.044077</td>\n      <td>0.007345</td>\n      <td>0.993997</td>\n      <td>-92.654651</td>\n      <td>24.249842</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td></td>\n      <td>15</td>\n      <td>0.899999</td>\n      <td>0.004872</td>\n      <td>0.044230</td>\n      <td>1.109357</td>\n      <td>0.001599</td>\n      <td>0.005606</td>\n      <td>0.040099</td>\n      <td>0.039802</td>\n      <td>0.004423</td>\n      <td>0.998420</td>\n      <td>-95.576994</td>\n      <td>10.935664</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td></td>\n      <td>16</td>\n      <td>1.000000</td>\n      <td>0.002477</td>\n      <td>0.015796</td>\n      <td>1.000000</td>\n      <td>0.000571</td>\n      <td>0.004052</td>\n      <td>0.036147</td>\n      <td>0.036227</td>\n      <td>0.001580</td>\n      <td>1.000000</td>\n      <td>-98.420355</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"stream","text":"\n\nModelMetricsBinomial: gbm\n** Reported on validation data. **\n\nMSE: 0.03014535673578486\nRMSE: 0.1736241824625385\nLogLoss: 0.11952062413571657\nMean Per-Class Error: 0.22386818861825042\nAUC: 0.8541002080486222\nAUCPR: 0.23773886113273363\nGini: 0.7082004160972444\n\nConfusion Matrix (Act/Pred) for max f1 @ threshold = 0.16566772863569384: \n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"            FALSE    TRUE   Error               Rate\n0  FALSE  70192.0  2121.0  0.0293   (2121.0/72313.0)\n1   TRUE   1817.0   841.0  0.6836    (1817.0/2658.0)\n2  Total  72009.0  2962.0  0.0525   (3938.0/74971.0)","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>FALSE</th>\n      <th>TRUE</th>\n      <th>Error</th>\n      <th>Rate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>FALSE</td>\n      <td>70192.0</td>\n      <td>2121.0</td>\n      <td>0.0293</td>\n      <td>(2121.0/72313.0)</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>TRUE</td>\n      <td>1817.0</td>\n      <td>841.0</td>\n      <td>0.6836</td>\n      <td>(1817.0/2658.0)</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Total</td>\n      <td>72009.0</td>\n      <td>2962.0</td>\n      <td>0.0525</td>\n      <td>(3938.0/74971.0)</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"stream","text":"\nMaximum Metrics: Maximum metrics at their respective thresholds\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"                         metric  threshold         value    idx\n0                        max f1   0.165668      0.299288  177.0\n1                        max f2   0.070046      0.392894  261.0\n2                  max f0point5   0.257240      0.321033  127.0\n3                  max accuracy   0.592026      0.964946   30.0\n4                 max precision   0.895425      1.000000    0.0\n5                    max recall   0.003543      1.000000  397.0\n6               max specificity   0.895425      1.000000    0.0\n7              max absolute_mcc   0.100112      0.280014  230.0\n8    max min_per_class_accuracy   0.035786      0.773514  311.0\n9   max mean_per_class_accuracy   0.031330      0.776132  319.0\n10                      max tns   0.895425  72313.000000    0.0\n11                      max fns   0.895425   2657.000000    0.0\n12                      max fps   0.002962  72313.000000  399.0\n13                      max tps   0.003543   2658.000000  397.0\n14                      max tnr   0.895425      1.000000    0.0\n15                      max fnr   0.895425      0.999624    0.0\n16                      max fpr   0.002962      1.000000  399.0\n17                      max tpr   0.003543      1.000000  397.0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>metric</th>\n      <th>threshold</th>\n      <th>value</th>\n      <th>idx</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>max f1</td>\n      <td>0.165668</td>\n      <td>0.299288</td>\n      <td>177.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>max f2</td>\n      <td>0.070046</td>\n      <td>0.392894</td>\n      <td>261.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>max f0point5</td>\n      <td>0.257240</td>\n      <td>0.321033</td>\n      <td>127.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>max accuracy</td>\n      <td>0.592026</td>\n      <td>0.964946</td>\n      <td>30.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>max precision</td>\n      <td>0.895425</td>\n      <td>1.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>max recall</td>\n      <td>0.003543</td>\n      <td>1.000000</td>\n      <td>397.0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>max specificity</td>\n      <td>0.895425</td>\n      <td>1.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>max absolute_mcc</td>\n      <td>0.100112</td>\n      <td>0.280014</td>\n      <td>230.0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>max min_per_class_accuracy</td>\n      <td>0.035786</td>\n      <td>0.773514</td>\n      <td>311.0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>max mean_per_class_accuracy</td>\n      <td>0.031330</td>\n      <td>0.776132</td>\n      <td>319.0</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>max tns</td>\n      <td>0.895425</td>\n      <td>72313.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>max fns</td>\n      <td>0.895425</td>\n      <td>2657.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>max fps</td>\n      <td>0.002962</td>\n      <td>72313.000000</td>\n      <td>399.0</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>max tps</td>\n      <td>0.003543</td>\n      <td>2658.000000</td>\n      <td>397.0</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>max tnr</td>\n      <td>0.895425</td>\n      <td>1.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>max fnr</td>\n      <td>0.895425</td>\n      <td>0.999624</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>max fpr</td>\n      <td>0.002962</td>\n      <td>1.000000</td>\n      <td>399.0</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>max tpr</td>\n      <td>0.003543</td>\n      <td>1.000000</td>\n      <td>397.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"stream","text":"\nGains/Lift Table: Avg response rate:  3.55 %, avg score:  3.60 %\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"      group  cumulative_data_fraction  lower_threshold       lift  \\\n0         1                  0.010004         0.344236  13.012273   \n1         2                  0.020008         0.243068   7.784799   \n2         3                  0.030012         0.195026   6.054844   \n3         4                  0.040002         0.163482   4.933190   \n4         5                  0.050006         0.141967   3.723165   \n5         6                  0.100012         0.085865   3.468357   \n6         7                  0.150005         0.060279   2.197463   \n7         8                  0.200011         0.044445   1.617564   \n8         9                  0.300009         0.027777   1.068487   \n9        10                  0.400008         0.019122   0.639587   \n10       11                  0.500007         0.013803   0.406326   \n11       12                  0.600005         0.010450   0.300982   \n12       13                  0.700004         0.008107   0.184352   \n13       14                  0.800003         0.006342   0.105344   \n14       15                  0.900001         0.004857   0.060196   \n15       16                  1.000000         0.002448   0.041385   \n\n    cumulative_lift  response_rate     score  cumulative_response_rate  \\\n0         13.012273       0.461333  0.473428                  0.461333   \n1         10.398536       0.276000  0.287629                  0.368667   \n2          8.950639       0.214667  0.217315                  0.317333   \n3          7.947281       0.174900  0.178416                  0.281761   \n4          7.102232       0.132000  0.152511                  0.251800   \n5          5.285295       0.122966  0.109552                  0.187383   \n6          4.256201       0.077908  0.071692                  0.150898   \n7          3.596497       0.057349  0.051758                  0.127509   \n8          2.753865       0.037882  0.035185                  0.097635   \n9          2.225313       0.022676  0.023018                  0.078896   \n10         1.861525       0.014406  0.016273                  0.065998   \n11         1.601440       0.010671  0.012010                  0.056777   \n12         1.399003       0.006536  0.009223                  0.049600   \n13         1.237298       0.003735  0.007193                  0.043867   \n14         1.106511       0.002134  0.005594                  0.039230   \n15         1.000000       0.001467  0.004046                  0.035454   \n\n    cumulative_score  capture_rate  cumulative_capture_rate         gain  \\\n0           0.473428      0.130173                 0.130173  1201.227289   \n1           0.380528      0.077878                 0.208051   678.479910   \n2           0.326124      0.060572                 0.268623   505.484374   \n3           0.289234      0.049285                 0.317908   393.318958   \n4           0.261882      0.037246                 0.355154   272.316479   \n5           0.185717      0.173439                 0.528593   246.835715   \n6           0.147716      0.109857                 0.638450   119.746313   \n7           0.123725      0.080888                 0.719338    61.756353   \n8           0.094213      0.106847                 0.826185     6.848679   \n9           0.076415      0.063958                 0.890143   -36.041284   \n10          0.064387      0.040632                 0.930775   -59.367404   \n11          0.055657      0.030098                 0.960873   -69.901781   \n12          0.049024      0.018435                 0.979308   -81.564841   \n13          0.043795      0.010534                 0.989842   -89.465623   \n14          0.039551      0.006020                 0.995862   -93.980356   \n15          0.036000      0.004138                 1.000000   -95.861495   \n\n    cumulative_gain  \n0       1201.227289  \n1        939.853599  \n2        795.063858  \n3        694.728102  \n4        610.223243  \n5        428.529479  \n6        325.620062  \n7        259.649735  \n8        175.386463  \n9        122.531289  \n10        86.152521  \n11        60.144049  \n12        39.900307  \n13        23.729836  \n14        10.651119  \n15         0.000000  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>group</th>\n      <th>cumulative_data_fraction</th>\n      <th>lower_threshold</th>\n      <th>lift</th>\n      <th>cumulative_lift</th>\n      <th>response_rate</th>\n      <th>score</th>\n      <th>cumulative_response_rate</th>\n      <th>cumulative_score</th>\n      <th>capture_rate</th>\n      <th>cumulative_capture_rate</th>\n      <th>gain</th>\n      <th>cumulative_gain</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td></td>\n      <td>1</td>\n      <td>0.010004</td>\n      <td>0.344236</td>\n      <td>13.012273</td>\n      <td>13.012273</td>\n      <td>0.461333</td>\n      <td>0.473428</td>\n      <td>0.461333</td>\n      <td>0.473428</td>\n      <td>0.130173</td>\n      <td>0.130173</td>\n      <td>1201.227289</td>\n      <td>1201.227289</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td></td>\n      <td>2</td>\n      <td>0.020008</td>\n      <td>0.243068</td>\n      <td>7.784799</td>\n      <td>10.398536</td>\n      <td>0.276000</td>\n      <td>0.287629</td>\n      <td>0.368667</td>\n      <td>0.380528</td>\n      <td>0.077878</td>\n      <td>0.208051</td>\n      <td>678.479910</td>\n      <td>939.853599</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td></td>\n      <td>3</td>\n      <td>0.030012</td>\n      <td>0.195026</td>\n      <td>6.054844</td>\n      <td>8.950639</td>\n      <td>0.214667</td>\n      <td>0.217315</td>\n      <td>0.317333</td>\n      <td>0.326124</td>\n      <td>0.060572</td>\n      <td>0.268623</td>\n      <td>505.484374</td>\n      <td>795.063858</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td></td>\n      <td>4</td>\n      <td>0.040002</td>\n      <td>0.163482</td>\n      <td>4.933190</td>\n      <td>7.947281</td>\n      <td>0.174900</td>\n      <td>0.178416</td>\n      <td>0.281761</td>\n      <td>0.289234</td>\n      <td>0.049285</td>\n      <td>0.317908</td>\n      <td>393.318958</td>\n      <td>694.728102</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td></td>\n      <td>5</td>\n      <td>0.050006</td>\n      <td>0.141967</td>\n      <td>3.723165</td>\n      <td>7.102232</td>\n      <td>0.132000</td>\n      <td>0.152511</td>\n      <td>0.251800</td>\n      <td>0.261882</td>\n      <td>0.037246</td>\n      <td>0.355154</td>\n      <td>272.316479</td>\n      <td>610.223243</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td></td>\n      <td>6</td>\n      <td>0.100012</td>\n      <td>0.085865</td>\n      <td>3.468357</td>\n      <td>5.285295</td>\n      <td>0.122966</td>\n      <td>0.109552</td>\n      <td>0.187383</td>\n      <td>0.185717</td>\n      <td>0.173439</td>\n      <td>0.528593</td>\n      <td>246.835715</td>\n      <td>428.529479</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td></td>\n      <td>7</td>\n      <td>0.150005</td>\n      <td>0.060279</td>\n      <td>2.197463</td>\n      <td>4.256201</td>\n      <td>0.077908</td>\n      <td>0.071692</td>\n      <td>0.150898</td>\n      <td>0.147716</td>\n      <td>0.109857</td>\n      <td>0.638450</td>\n      <td>119.746313</td>\n      <td>325.620062</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td></td>\n      <td>8</td>\n      <td>0.200011</td>\n      <td>0.044445</td>\n      <td>1.617564</td>\n      <td>3.596497</td>\n      <td>0.057349</td>\n      <td>0.051758</td>\n      <td>0.127509</td>\n      <td>0.123725</td>\n      <td>0.080888</td>\n      <td>0.719338</td>\n      <td>61.756353</td>\n      <td>259.649735</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td></td>\n      <td>9</td>\n      <td>0.300009</td>\n      <td>0.027777</td>\n      <td>1.068487</td>\n      <td>2.753865</td>\n      <td>0.037882</td>\n      <td>0.035185</td>\n      <td>0.097635</td>\n      <td>0.094213</td>\n      <td>0.106847</td>\n      <td>0.826185</td>\n      <td>6.848679</td>\n      <td>175.386463</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td></td>\n      <td>10</td>\n      <td>0.400008</td>\n      <td>0.019122</td>\n      <td>0.639587</td>\n      <td>2.225313</td>\n      <td>0.022676</td>\n      <td>0.023018</td>\n      <td>0.078896</td>\n      <td>0.076415</td>\n      <td>0.063958</td>\n      <td>0.890143</td>\n      <td>-36.041284</td>\n      <td>122.531289</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td></td>\n      <td>11</td>\n      <td>0.500007</td>\n      <td>0.013803</td>\n      <td>0.406326</td>\n      <td>1.861525</td>\n      <td>0.014406</td>\n      <td>0.016273</td>\n      <td>0.065998</td>\n      <td>0.064387</td>\n      <td>0.040632</td>\n      <td>0.930775</td>\n      <td>-59.367404</td>\n      <td>86.152521</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td></td>\n      <td>12</td>\n      <td>0.600005</td>\n      <td>0.010450</td>\n      <td>0.300982</td>\n      <td>1.601440</td>\n      <td>0.010671</td>\n      <td>0.012010</td>\n      <td>0.056777</td>\n      <td>0.055657</td>\n      <td>0.030098</td>\n      <td>0.960873</td>\n      <td>-69.901781</td>\n      <td>60.144049</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td></td>\n      <td>13</td>\n      <td>0.700004</td>\n      <td>0.008107</td>\n      <td>0.184352</td>\n      <td>1.399003</td>\n      <td>0.006536</td>\n      <td>0.009223</td>\n      <td>0.049600</td>\n      <td>0.049024</td>\n      <td>0.018435</td>\n      <td>0.979308</td>\n      <td>-81.564841</td>\n      <td>39.900307</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td></td>\n      <td>14</td>\n      <td>0.800003</td>\n      <td>0.006342</td>\n      <td>0.105344</td>\n      <td>1.237298</td>\n      <td>0.003735</td>\n      <td>0.007193</td>\n      <td>0.043867</td>\n      <td>0.043795</td>\n      <td>0.010534</td>\n      <td>0.989842</td>\n      <td>-89.465623</td>\n      <td>23.729836</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td></td>\n      <td>15</td>\n      <td>0.900001</td>\n      <td>0.004857</td>\n      <td>0.060196</td>\n      <td>1.106511</td>\n      <td>0.002134</td>\n      <td>0.005594</td>\n      <td>0.039230</td>\n      <td>0.039551</td>\n      <td>0.006020</td>\n      <td>0.995862</td>\n      <td>-93.980356</td>\n      <td>10.651119</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td></td>\n      <td>16</td>\n      <td>1.000000</td>\n      <td>0.002448</td>\n      <td>0.041385</td>\n      <td>1.000000</td>\n      <td>0.001467</td>\n      <td>0.004046</td>\n      <td>0.035454</td>\n      <td>0.036000</td>\n      <td>0.004138</td>\n      <td>1.000000</td>\n      <td>-95.861495</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"stream","text":"\n\nScoring History: \n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"               timestamp    duration  number_of_trees  training_rmse  \\\n0    2020-06-27 21:14:52   0.046 sec              0.0       0.186655   \n1    2020-06-27 21:14:54   2.402 sec              1.0       0.184765   \n2    2020-06-27 21:14:56   3.600 sec              2.0       0.183459   \n3    2020-06-27 21:15:00   7.888 sec              8.0       0.178666   \n4    2020-06-27 21:15:08  15.984 sec             16.0       0.175893   \n5    2020-06-27 21:15:15  22.977 sec             27.0       0.174047   \n6    2020-06-27 21:15:24  31.708 sec             41.0       0.172508   \n7    2020-06-27 21:15:31  39.396 sec             50.0       0.171774   \n\n   training_logloss  training_auc  training_pr_auc  training_lift  \\\n0          0.155498      0.500000         0.036147       1.000000   \n1          0.147793      0.813317         0.179129       8.555719   \n2          0.143542      0.826473         0.187720       8.791581   \n3          0.130545      0.848040         0.223464      11.535026   \n4          0.123865      0.857773         0.243940      12.501820   \n5          0.119457      0.867153         0.263628      13.133624   \n6          0.116393      0.875027         0.284508      13.718042   \n7          0.115051      0.878152         0.295015      14.286666   \n\n   training_classification_error  validation_rmse  validation_logloss  \\\n0                       0.963853         0.184925            0.153223   \n1                       0.075742         0.183099            0.145890   \n2                       0.075742         0.181892            0.142011   \n3                       0.062738         0.177618            0.130322   \n4                       0.059851         0.175489            0.124846   \n5                       0.062355         0.174506            0.121813   \n6                       0.052280         0.173864            0.120108   \n7                       0.053673         0.173624            0.119521   \n\n   validation_auc  validation_pr_auc  validation_lift  \\\n0        0.500000           0.035454         1.000000   \n1        0.802085           0.169243         8.720747   \n2        0.812856           0.173714         8.818929   \n3        0.833531           0.203900        10.943848   \n4        0.840628           0.216801        11.846433   \n5        0.847427           0.226077        12.072080   \n6        0.852743           0.234470        12.636196   \n7        0.854100           0.237739        13.012273   \n\n   validation_classification_error  \n0                         0.964546  \n1                         0.056662  \n2                         0.071134  \n3                         0.074242  \n4                         0.060650  \n5                         0.060330  \n6                         0.055688  \n7                         0.052527  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>timestamp</th>\n      <th>duration</th>\n      <th>number_of_trees</th>\n      <th>training_rmse</th>\n      <th>training_logloss</th>\n      <th>training_auc</th>\n      <th>training_pr_auc</th>\n      <th>training_lift</th>\n      <th>training_classification_error</th>\n      <th>validation_rmse</th>\n      <th>validation_logloss</th>\n      <th>validation_auc</th>\n      <th>validation_pr_auc</th>\n      <th>validation_lift</th>\n      <th>validation_classification_error</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td></td>\n      <td>2020-06-27 21:14:52</td>\n      <td>0.046 sec</td>\n      <td>0.0</td>\n      <td>0.186655</td>\n      <td>0.155498</td>\n      <td>0.500000</td>\n      <td>0.036147</td>\n      <td>1.000000</td>\n      <td>0.963853</td>\n      <td>0.184925</td>\n      <td>0.153223</td>\n      <td>0.500000</td>\n      <td>0.035454</td>\n      <td>1.000000</td>\n      <td>0.964546</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td></td>\n      <td>2020-06-27 21:14:54</td>\n      <td>2.402 sec</td>\n      <td>1.0</td>\n      <td>0.184765</td>\n      <td>0.147793</td>\n      <td>0.813317</td>\n      <td>0.179129</td>\n      <td>8.555719</td>\n      <td>0.075742</td>\n      <td>0.183099</td>\n      <td>0.145890</td>\n      <td>0.802085</td>\n      <td>0.169243</td>\n      <td>8.720747</td>\n      <td>0.056662</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td></td>\n      <td>2020-06-27 21:14:56</td>\n      <td>3.600 sec</td>\n      <td>2.0</td>\n      <td>0.183459</td>\n      <td>0.143542</td>\n      <td>0.826473</td>\n      <td>0.187720</td>\n      <td>8.791581</td>\n      <td>0.075742</td>\n      <td>0.181892</td>\n      <td>0.142011</td>\n      <td>0.812856</td>\n      <td>0.173714</td>\n      <td>8.818929</td>\n      <td>0.071134</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td></td>\n      <td>2020-06-27 21:15:00</td>\n      <td>7.888 sec</td>\n      <td>8.0</td>\n      <td>0.178666</td>\n      <td>0.130545</td>\n      <td>0.848040</td>\n      <td>0.223464</td>\n      <td>11.535026</td>\n      <td>0.062738</td>\n      <td>0.177618</td>\n      <td>0.130322</td>\n      <td>0.833531</td>\n      <td>0.203900</td>\n      <td>10.943848</td>\n      <td>0.074242</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td></td>\n      <td>2020-06-27 21:15:08</td>\n      <td>15.984 sec</td>\n      <td>16.0</td>\n      <td>0.175893</td>\n      <td>0.123865</td>\n      <td>0.857773</td>\n      <td>0.243940</td>\n      <td>12.501820</td>\n      <td>0.059851</td>\n      <td>0.175489</td>\n      <td>0.124846</td>\n      <td>0.840628</td>\n      <td>0.216801</td>\n      <td>11.846433</td>\n      <td>0.060650</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td></td>\n      <td>2020-06-27 21:15:15</td>\n      <td>22.977 sec</td>\n      <td>27.0</td>\n      <td>0.174047</td>\n      <td>0.119457</td>\n      <td>0.867153</td>\n      <td>0.263628</td>\n      <td>13.133624</td>\n      <td>0.062355</td>\n      <td>0.174506</td>\n      <td>0.121813</td>\n      <td>0.847427</td>\n      <td>0.226077</td>\n      <td>12.072080</td>\n      <td>0.060330</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td></td>\n      <td>2020-06-27 21:15:24</td>\n      <td>31.708 sec</td>\n      <td>41.0</td>\n      <td>0.172508</td>\n      <td>0.116393</td>\n      <td>0.875027</td>\n      <td>0.284508</td>\n      <td>13.718042</td>\n      <td>0.052280</td>\n      <td>0.173864</td>\n      <td>0.120108</td>\n      <td>0.852743</td>\n      <td>0.234470</td>\n      <td>12.636196</td>\n      <td>0.055688</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td></td>\n      <td>2020-06-27 21:15:31</td>\n      <td>39.396 sec</td>\n      <td>50.0</td>\n      <td>0.171774</td>\n      <td>0.115051</td>\n      <td>0.878152</td>\n      <td>0.295015</td>\n      <td>14.286666</td>\n      <td>0.053673</td>\n      <td>0.173624</td>\n      <td>0.119521</td>\n      <td>0.854100</td>\n      <td>0.237739</td>\n      <td>13.012273</td>\n      <td>0.052527</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"stream","text":"\nVariable Importances: \n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"                           variable  relative_importance  scaled_importance  \\\n0                      CREDIT_SCORE          2309.658691           1.000000   \n1                     SERVICER_NAME          1683.956299           0.729093   \n2                    PROPERTY_STATE          1255.222290           0.543467   \n3                       SELLER_NAME           997.285217           0.431789   \n4               NUMBER_OF_BORROWERS           316.293396           0.136944   \n5            ORIGINAL_INTEREST_RATE           300.391693           0.130059   \n6                      ORIGINAL_UPB           292.308807           0.126559   \n7     MORTGAGE_INSURANCE_PERCENTAGE           186.016342           0.080538   \n8            ORIGINAL_LOAN_TO_VALUE           158.307068           0.068541   \n9                     PROPERTY_TYPE            64.317169           0.027847   \n10  ORIGINAL_COMBINED_LOAN_TO_VALUE            54.901577           0.023770   \n11                     LOAN_PURPOSE            53.130379           0.023004   \n12                    MATURITY_DATE            46.874786           0.020295   \n13    ORIGINAL_DEBT_TO_INCOME_RATIO            36.971573           0.016007   \n14               FIRST_PAYMENT_DATE            25.007473           0.010827   \n15                 OCCUPANCY_STATUS            21.170610           0.009166   \n16                          CHANNEL            16.820601           0.007283   \n17    METROPOLITAN_STATISTICAL_AREA            11.293387           0.004890   \n18        FIRST_TIME_HOMEBUYER_FLAG             1.468417           0.000636   \n19                  NUMBER_OF_UNITS             0.000000           0.000000   \n\n    percentage  \n0     0.294923  \n1     0.215026  \n2     0.160281  \n3     0.127345  \n4     0.040388  \n5     0.038357  \n6     0.037325  \n7     0.023753  \n8     0.020214  \n9     0.008213  \n10    0.007010  \n11    0.006784  \n12    0.005985  \n13    0.004721  \n14    0.003193  \n15    0.002703  \n16    0.002148  \n17    0.001442  \n18    0.000188  \n19    0.000000  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>variable</th>\n      <th>relative_importance</th>\n      <th>scaled_importance</th>\n      <th>percentage</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>CREDIT_SCORE</td>\n      <td>2309.658691</td>\n      <td>1.000000</td>\n      <td>0.294923</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>SERVICER_NAME</td>\n      <td>1683.956299</td>\n      <td>0.729093</td>\n      <td>0.215026</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>PROPERTY_STATE</td>\n      <td>1255.222290</td>\n      <td>0.543467</td>\n      <td>0.160281</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>SELLER_NAME</td>\n      <td>997.285217</td>\n      <td>0.431789</td>\n      <td>0.127345</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>NUMBER_OF_BORROWERS</td>\n      <td>316.293396</td>\n      <td>0.136944</td>\n      <td>0.040388</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>ORIGINAL_INTEREST_RATE</td>\n      <td>300.391693</td>\n      <td>0.130059</td>\n      <td>0.038357</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>ORIGINAL_UPB</td>\n      <td>292.308807</td>\n      <td>0.126559</td>\n      <td>0.037325</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>MORTGAGE_INSURANCE_PERCENTAGE</td>\n      <td>186.016342</td>\n      <td>0.080538</td>\n      <td>0.023753</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>ORIGINAL_LOAN_TO_VALUE</td>\n      <td>158.307068</td>\n      <td>0.068541</td>\n      <td>0.020214</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>PROPERTY_TYPE</td>\n      <td>64.317169</td>\n      <td>0.027847</td>\n      <td>0.008213</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>ORIGINAL_COMBINED_LOAN_TO_VALUE</td>\n      <td>54.901577</td>\n      <td>0.023770</td>\n      <td>0.007010</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>LOAN_PURPOSE</td>\n      <td>53.130379</td>\n      <td>0.023004</td>\n      <td>0.006784</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>MATURITY_DATE</td>\n      <td>46.874786</td>\n      <td>0.020295</td>\n      <td>0.005985</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>ORIGINAL_DEBT_TO_INCOME_RATIO</td>\n      <td>36.971573</td>\n      <td>0.016007</td>\n      <td>0.004721</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>FIRST_PAYMENT_DATE</td>\n      <td>25.007473</td>\n      <td>0.010827</td>\n      <td>0.003193</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>OCCUPANCY_STATUS</td>\n      <td>21.170610</td>\n      <td>0.009166</td>\n      <td>0.002703</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>CHANNEL</td>\n      <td>16.820601</td>\n      <td>0.007283</td>\n      <td>0.002148</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>METROPOLITAN_STATISTICAL_AREA</td>\n      <td>11.293387</td>\n      <td>0.004890</td>\n      <td>0.001442</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>FIRST_TIME_HOMEBUYER_FLAG</td>\n      <td>1.468417</td>\n      <td>0.000636</td>\n      <td>0.000188</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>NUMBER_OF_UNITS</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"stream","text":"\nSee the whole table with table.as_data_frame()\n","name":"stdout"},{"output_type":"execute_result","execution_count":29,"data":{"text/plain":""},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"gbm.varimp_plot(20)","execution_count":30,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 1008x720 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"gbm.plot(metric='auc')","execution_count":31,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"metadata":{},"cell_type":"markdown","source":"The default GBM model had a slightly better performance than the default RF.\nWe will make the predictions with the GBM model as well."},{"metadata":{"trusted":true},"cell_type":"code","source":"gbm.predict(valid)","execution_count":32,"outputs":[{"output_type":"stream","text":"gbm prediction progress: |████████████████████████████████████████████████| 100%\n","name":"stdout"},{"output_type":"display_data","data":{"text/html":"<table>\n<thead>\n<tr><th>predict  </th><th style=\"text-align: right;\">   FALSE</th><th style=\"text-align: right;\">      TRUE</th></tr>\n</thead>\n<tbody>\n<tr><td>FALSE    </td><td style=\"text-align: right;\">0.978372</td><td style=\"text-align: right;\">0.0216281 </td></tr>\n<tr><td>FALSE    </td><td style=\"text-align: right;\">0.995024</td><td style=\"text-align: right;\">0.00497636</td></tr>\n<tr><td>FALSE    </td><td style=\"text-align: right;\">0.964645</td><td style=\"text-align: right;\">0.0353549 </td></tr>\n<tr><td>FALSE    </td><td style=\"text-align: right;\">0.99305 </td><td style=\"text-align: right;\">0.00694996</td></tr>\n<tr><td>FALSE    </td><td style=\"text-align: right;\">0.99217 </td><td style=\"text-align: right;\">0.0078297 </td></tr>\n<tr><td>TRUE     </td><td style=\"text-align: right;\">0.591272</td><td style=\"text-align: right;\">0.408728  </td></tr>\n<tr><td>FALSE    </td><td style=\"text-align: right;\">0.993899</td><td style=\"text-align: right;\">0.00610064</td></tr>\n<tr><td>FALSE    </td><td style=\"text-align: right;\">0.995599</td><td style=\"text-align: right;\">0.00440117</td></tr>\n<tr><td>FALSE    </td><td style=\"text-align: right;\">0.950489</td><td style=\"text-align: right;\">0.0495107 </td></tr>\n<tr><td>FALSE    </td><td style=\"text-align: right;\">0.992925</td><td style=\"text-align: right;\">0.00707464</td></tr>\n</tbody>\n</table>"},"metadata":{}},{"output_type":"execute_result","execution_count":32,"data":{"text/plain":""},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"All three models made the same ten predictions, and this gives us an indication of why all three scores are close to each other. Although the sixth prediction is TRUE for all three models, the probability is not exactly the same, but since the thresholds for all three models were low, the predictions were still TRUE.\nAs we did with the other two models, save the model performance."},{"metadata":{"trusted":true},"cell_type":"code","source":"default_gbm_per = gbm.model_performance(valid)","execution_count":33,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model tuning\n### Tune GLM with H2O GridSearch"},{"metadata":{},"cell_type":"markdown","source":"H2O supports two types of grid search – traditional (or \"cartesian\") grid search and random grid search. In a cartesian grid search, you specify a set of values for each hyperparameter that you want to search over, and H2O will train a model for every combination of the hyperparameter values. This means that if you have three hyperparameters and you specify 5, 10, and 2 values for each, your grid will contain a total of 5*10*2 = 100 models.\n\nIn a random grid search, you specify the hyperparameter space in the exact same way, except H2O will sample uniformly from the set of all possible hyperparameter value combinations. In the random grid search, you also specify a stopping criterion, which controls when the random grid search is completed. You can tell the random grid search to stop by specifying a maximum number of models or the maximum number of seconds allowed for the search. You can also specify a performance-metric-based stopping criterion, which will stop the random grid search when the performance stops improving by a specified amount.\nOnce the grid search is complete, you can query the grid object and sort the models by a particular performance metric (for example, \"AUC\"). All models are stored in the H2O cluster and are accessible by model id.\n\nTo save some time, we will do a random grid search for our GLM model instead of the cartesian search. The H2OGridSearch has 4 parameters, and in order to use it, you need at least three of them. The first parameter for the grid search is the model that you want to tune. Next are your hyperparameters, which needs to be a string of parameters, and a list of values to be explored by grid search. The third one is optional, which is the grid id, and if you do not specify one, an id will automatically be generated. Lastly, the fourth parameter is the search criteria, where you can specify if you want to do a cartesian or random search.\n\nWe will explore two ways of defining your grid search, and you can use the way you prefer. One way is to define all at once in the grid search (as we will do it for the GLM). The second way is to define every parameter separately. For example, define your model, your hyper-parameters, and your search criteria, and just add that to your grid search once you are ready.\n\nFor our GLM, we will tune alpha,lambda, and missing_values_handling. The other parameters that you could change, such as solver,max_active_predictors, and nlambdas, to mention a few, are not supported by H2OGridSearch.\n\n1. alpha is the distribution of regularization between the L1 (Lasso) and L2 (Ridge) penalties. A value of 1 for alpha represents Lasso regression, a value of 0 produces Ridge regression, and anything in between specifies the amount of mixing between the two.\n\n2. lambda, on the other hand, is the regularization strength. For alpha, we can explore the range from 0 to 1 in steps of 0.01. For lambda, you could start just doing your own random searches, but that might take a lot of time. Instead, we can base our value for lambda on the original value of lambda, which was 6.626e-5. We can choose our starting point to be 1e-6 and go from there.\n\n3. missing_values_handling This parameter allows us to specify how we want to specify any missing data (Options are skip and MeanImputation)"},{"metadata":{"trusted":true},"cell_type":"code","source":"glm_grid = h2o.grid.H2OGridSearch (\n    H2OGeneralizedLinearEstimator(family= 'binomial', lambda_search = True),\n\n    hyper_params = {\n        'alpha': [x*0.01 for x in range(0, 100)],\n        'lambda': [x*1e-8 for x in range(0, 1000)],\n        'missing_values_handling': ['Skip', 'MeanImputation']\n    },\n\n    grid_id = 'glm_random_grid',\n\n    search_criteria = {\n        'strategy': 'RandomDiscrete',\n        'max_models': 200,\n        'max_runtime_secs': 300,\n        'seed': 42}\n)\n\n%time glm_grid.train(x = x, y = y, training_frame=train, validation_frame=valid)","execution_count":34,"outputs":[{"output_type":"stream","text":"glm Grid Build progress: |████████████████████████████████████████████████| 100%\nCPU times: user 5.69 s, sys: 256 ms, total: 5.95 s\nWall time: 5min 9s\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"You can easily see all four parameters of our grid search in the code sample above. We defined our GLM model the same way we did before. Then, we take care of the hyper-parameters and notice that we have used a for loop for the ranges of both alpha and lambda in order to cover more possible values. Because the number of possible models in our search criteria is very, we specify that we want a maximum number of 200 models, or that the grid search runs for only 300 seconds.\n\nPrint the models in descending order, sorted by the AUC. By default, the grid search will return the best models based on the logloss. Therefore, in order to get the best model based on the AUC, we will specify that we want to sort the models by AUC. You can change this to other metrics, depending on what you are looking for."},{"metadata":{"trusted":true},"cell_type":"code","source":"sorted_glm_grid = glm_grid.get_grid(sort_by='auc', decreasing=True)\nsorted_glm_grid.sorted_metric_table()","execution_count":35,"outputs":[{"output_type":"execute_result","execution_count":35,"data":{"text/plain":"                      alpha                  lambda missing_values_handling  \\\n0                    [0.03]               [6.29E-6]                    Skip   \n1                    [0.56]               [6.68E-6]                    Skip   \n2      [0.6900000000000001]               [2.18E-6]                    Skip   \n3                    [0.09]               [3.45E-6]                    Skip   \n4                    [0.32]               [5.67E-6]                    Skip   \n.. ..                   ...                     ...                     ...   \n73                   [0.88]               [7.32E-6]          MeanImputation   \n74                   [0.17]                [7.0E-8]          MeanImputation   \n75                    [0.9]  [4.800000000000001E-7]          MeanImputation   \n76                    [0.6]               [4.67E-6]          MeanImputation   \n77                   [0.91]                [9.7E-6]          MeanImputation   \n\n                   model_ids                 auc  \n0    glm_random_grid_model_5  0.8534243904294566  \n1   glm_random_grid_model_33  0.8533819787402868  \n2   glm_random_grid_model_64  0.8533804711127351  \n3   glm_random_grid_model_42  0.8533803793020828  \n4   glm_random_grid_model_35  0.8533737157815902  \n..                       ...                 ...  \n73  glm_random_grid_model_46  0.8459654874636457  \n74   glm_random_grid_model_9  0.8459653886123777  \n75  glm_random_grid_model_15   0.845953019197114  \n76  glm_random_grid_model_60  0.8459445960285286  \n77  glm_random_grid_model_69  0.8458931439434603  \n\n[78 rows x 6 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>alpha</th>\n      <th>lambda</th>\n      <th>missing_values_handling</th>\n      <th>model_ids</th>\n      <th>auc</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td></td>\n      <td>[0.03]</td>\n      <td>[6.29E-6]</td>\n      <td>Skip</td>\n      <td>glm_random_grid_model_5</td>\n      <td>0.8534243904294566</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td></td>\n      <td>[0.56]</td>\n      <td>[6.68E-6]</td>\n      <td>Skip</td>\n      <td>glm_random_grid_model_33</td>\n      <td>0.8533819787402868</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td></td>\n      <td>[0.6900000000000001]</td>\n      <td>[2.18E-6]</td>\n      <td>Skip</td>\n      <td>glm_random_grid_model_64</td>\n      <td>0.8533804711127351</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td></td>\n      <td>[0.09]</td>\n      <td>[3.45E-6]</td>\n      <td>Skip</td>\n      <td>glm_random_grid_model_42</td>\n      <td>0.8533803793020828</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td></td>\n      <td>[0.32]</td>\n      <td>[5.67E-6]</td>\n      <td>Skip</td>\n      <td>glm_random_grid_model_35</td>\n      <td>0.8533737157815902</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>73</th>\n      <td></td>\n      <td>[0.88]</td>\n      <td>[7.32E-6]</td>\n      <td>MeanImputation</td>\n      <td>glm_random_grid_model_46</td>\n      <td>0.8459654874636457</td>\n    </tr>\n    <tr>\n      <th>74</th>\n      <td></td>\n      <td>[0.17]</td>\n      <td>[7.0E-8]</td>\n      <td>MeanImputation</td>\n      <td>glm_random_grid_model_9</td>\n      <td>0.8459653886123777</td>\n    </tr>\n    <tr>\n      <th>75</th>\n      <td></td>\n      <td>[0.9]</td>\n      <td>[4.800000000000001E-7]</td>\n      <td>MeanImputation</td>\n      <td>glm_random_grid_model_15</td>\n      <td>0.845953019197114</td>\n    </tr>\n    <tr>\n      <th>76</th>\n      <td></td>\n      <td>[0.6]</td>\n      <td>[4.67E-6]</td>\n      <td>MeanImputation</td>\n      <td>glm_random_grid_model_60</td>\n      <td>0.8459445960285286</td>\n    </tr>\n    <tr>\n      <th>77</th>\n      <td></td>\n      <td>[0.91]</td>\n      <td>[9.7E-6]</td>\n      <td>MeanImputation</td>\n      <td>glm_random_grid_model_69</td>\n      <td>0.8458931439434603</td>\n    </tr>\n  </tbody>\n</table>\n<p>78 rows × 6 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"With the code sample above, you will get the models that were created with their respective parameters, model id, and AUC. As you can see, the grid search did not take that long to complete, and it trained a total of 200 models, which was our second constraint. The AUC did improve, and we will compare it to the AUC from our default model."},{"metadata":{},"cell_type":"markdown","source":"### Save the best model and print the model summary"},{"metadata":{"trusted":true},"cell_type":"code","source":"tuned_glm = glm_grid.models[0]\ntuned_glm.summary()","execution_count":36,"outputs":[{"output_type":"stream","text":"\nGLM Model: summary\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"       family   link                                 regularization  \\\n0    binomial  logit  Elastic Net (alpha = 0.09, lambda = 3.45E-6 )   \n\n                                                           lambda_search  \\\n0  nlambda = 100, lambda.max = 0.3691, lambda.min = 3.45E-6, lambda.1...   \n\n   number_of_predictors_total number_of_active_predictors  \\\n0                         161                         160   \n\n   number_of_iterations training_frame  \n0                     5  py_4_sid_b930  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>family</th>\n      <th>link</th>\n      <th>regularization</th>\n      <th>lambda_search</th>\n      <th>number_of_predictors_total</th>\n      <th>number_of_active_predictors</th>\n      <th>number_of_iterations</th>\n      <th>training_frame</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td></td>\n      <td>binomial</td>\n      <td>logit</td>\n      <td>Elastic Net (alpha = 0.09, lambda = 3.45E-6 )</td>\n      <td>nlambda = 100, lambda.max = 0.3691, lambda.min = 3.45E-6, lambda.1...</td>\n      <td>161</td>\n      <td>160</td>\n      <td>5</td>\n      <td>py_4_sid_b930</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"execute_result","execution_count":36,"data":{"text/plain":""},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"## Make a comparison between the performance of default glm model and the best model from grid search.\n- First, evaluate the model performane on the validation set:"},{"metadata":{"trusted":true},"cell_type":"code","source":"tuned_glm_perf = tuned_glm.model_performance(valid)","execution_count":37,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### print the AUC for default and the tuned model:"},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Default GLM AUC: %.4f \\nTuned GLM AUC: %.4f' % (default_glm_perf.auc(), tuned_glm_perf.auc()))","execution_count":38,"outputs":[{"output_type":"stream","text":"Default GLM AUC: 0.8450 \nTuned GLM AUC: 0.8534\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"### Print F1 score to see if it improved or not:"},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Default GLM F1 Score', default_glm_perf.F1())\nprint('Tuned FLm F1 Score', tuned_glm_perf.F1())","execution_count":39,"outputs":[{"output_type":"stream","text":"Default GLM F1 Score [[0.12627867037192236, 0.28374578177727783]]\nTuned FLm F1 Score [[0.12549339190401904, 0.28352059925093637]]\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"- The max F1 Score did not have a significant improvement. Although the threshold slightly increased, it did not improve the overall F1 Score by much. Let's take a look at the confusion matrix to see if the values changed."},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Default GLM: ', default_glm_perf.confusion_matrix())\nprint('Tuned GLM: ', tuned_glm_perf.confusion_matrix())","execution_count":40,"outputs":[{"output_type":"stream","text":"Default GLM:  \nConfusion Matrix (Act/Pred) for max f1 @ threshold = 0.12627867037192236: \n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"            FALSE    TRUE   Error               Rate\n0  FALSE  68868.0  3445.0  0.0476   (3445.0/72313.0)\n1   TRUE   1649.0  1009.0  0.6204    (1649.0/2658.0)\n2  Total  70517.0  4454.0  0.0679   (5094.0/74971.0)","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>FALSE</th>\n      <th>TRUE</th>\n      <th>Error</th>\n      <th>Rate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>FALSE</td>\n      <td>68868.0</td>\n      <td>3445.0</td>\n      <td>0.0476</td>\n      <td>(3445.0/72313.0)</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>TRUE</td>\n      <td>1649.0</td>\n      <td>1009.0</td>\n      <td>0.6204</td>\n      <td>(1649.0/2658.0)</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Total</td>\n      <td>70517.0</td>\n      <td>4454.0</td>\n      <td>0.0679</td>\n      <td>(5094.0/74971.0)</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"stream","text":"\nTuned GLM:  \nConfusion Matrix (Act/Pred) for max f1 @ threshold = 0.12549339190401904: \n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"            FALSE    TRUE   Error               Rate\n0  FALSE  51014.0  2655.0  0.0495   (2655.0/53669.0)\n1   TRUE   1171.0   757.0  0.6074    (1171.0/1928.0)\n2  Total  52185.0  3412.0  0.0688   (3826.0/55597.0)","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>FALSE</th>\n      <th>TRUE</th>\n      <th>Error</th>\n      <th>Rate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>FALSE</td>\n      <td>51014.0</td>\n      <td>2655.0</td>\n      <td>0.0495</td>\n      <td>(2655.0/53669.0)</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>TRUE</td>\n      <td>1171.0</td>\n      <td>757.0</td>\n      <td>0.6074</td>\n      <td>(1171.0/1928.0)</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Total</td>\n      <td>52185.0</td>\n      <td>3412.0</td>\n      <td>0.0688</td>\n      <td>(3826.0/55597.0)</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"stream","text":"\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"Notice how the overall error slightly decreased, as well as the error for the FALSE class. While the error for the TRUE class had minimal improvement, meaning the model is classifying a few more samples that are actually TRUE correctly. We see that our model has a hard time classifying the TRUE labels, and this is due to the highly imbalanced dataset that we are working on.\n\nWe will do the test evaluation after we tune our other two models."},{"metadata":{},"cell_type":"markdown","source":"### Tune the RF model with H2O GridSearch"},{"metadata":{},"cell_type":"markdown","source":"- We will do the grid search a bit differently this time. We are going to define each parameter of the grid search separately, and then pass the variables to the grid search function.\n\n- We will first find one of the most important parameters for an RF, which is the maximum depth.\n\n- max_depth defines the number of nodes along the longest path from the start of the tree to the farthest leaf node. Higher values will make the model more complex and can lead to overfitting. Setting this value to 0 specifies no limit. This value defaults to 20. We will first look for the best value for the max_depth; this would save us some computational time when we tune the other parameters. As we mentioned before, we will use a slightly different approach for the grid search. We are going to instantiate each parameter for the grid search, and then pass each one into it."},{"metadata":{"trusted":true},"cell_type":"code","source":"hyper_parameters = {'max_depth': [1,3,5,6,7,8,9,10,12,13,15,20,25,35]}\n\nrf = H2ORandomForestEstimator(\n        seed= 42,\n        stopping_rounds = 5,\n        stopping_tolerance = 1e-4,\n        stopping_metric = 'auc',\n        model_id= 'rf')\n\ngrid_id = 'depth_grid'\n\nsearch_criteria = {'strategy': \"Cartesian\"}\n\n#Grid Search\n\nrf_grid = H2OGridSearch(model = rf,\n                       hyper_params = hyper_parameters,\n                       grid_id = grid_id,\n                       search_criteria = search_criteria)\n\n%time rf_grid.train(x=x, y=y, training_frame=train, validation_frame=valid)","execution_count":41,"outputs":[{"output_type":"stream","text":"drf Grid Build progress: |████████████████████████████████████████████████| 100%\nCPU times: user 7min 58s, sys: 1min 6s, total: 9min 4s\nWall time: 13min 35s\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"We are doing a random search of values for max_depth to see if the default value is good, or if we need to adjust the value. After it is done training, print the models sorted by AUC"},{"metadata":{"trusted":true},"cell_type":"code","source":"sorted_rf_depth = rf_grid.get_grid(sort_by='auc',decreasing=True)\nsorted_rf_depth.sorted_metric_table()","execution_count":42,"outputs":[{"output_type":"execute_result","execution_count":42,"data":{"text/plain":"     max_depth            model_ids                 auc\n0           10   depth_grid_model_8  0.8483202339274679\n1           12   depth_grid_model_9  0.8475205427762891\n2            9   depth_grid_model_7  0.8472289965689974\n3           13  depth_grid_model_10  0.8469513389648796\n4            8   depth_grid_model_6  0.8452958845813425\n5           15  depth_grid_model_11  0.8430497704585108\n6            7   depth_grid_model_5   0.842491713428259\n7            6   depth_grid_model_4  0.8368467831461335\n8            5   depth_grid_model_3  0.8311638705648987\n9           20  depth_grid_model_12   0.826378639356413\n10          25  depth_grid_model_13   0.818381904736367\n11           3   depth_grid_model_2  0.8154863611939805\n12          35  depth_grid_model_14  0.8135941320097503\n13           1   depth_grid_model_1  0.7686296114467771","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>max_depth</th>\n      <th>model_ids</th>\n      <th>auc</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td></td>\n      <td>10</td>\n      <td>depth_grid_model_8</td>\n      <td>0.8483202339274679</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td></td>\n      <td>12</td>\n      <td>depth_grid_model_9</td>\n      <td>0.8475205427762891</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td></td>\n      <td>9</td>\n      <td>depth_grid_model_7</td>\n      <td>0.8472289965689974</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td></td>\n      <td>13</td>\n      <td>depth_grid_model_10</td>\n      <td>0.8469513389648796</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td></td>\n      <td>8</td>\n      <td>depth_grid_model_6</td>\n      <td>0.8452958845813425</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td></td>\n      <td>15</td>\n      <td>depth_grid_model_11</td>\n      <td>0.8430497704585108</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td></td>\n      <td>7</td>\n      <td>depth_grid_model_5</td>\n      <td>0.842491713428259</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td></td>\n      <td>6</td>\n      <td>depth_grid_model_4</td>\n      <td>0.8368467831461335</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td></td>\n      <td>5</td>\n      <td>depth_grid_model_3</td>\n      <td>0.8311638705648987</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td></td>\n      <td>20</td>\n      <td>depth_grid_model_12</td>\n      <td>0.826378639356413</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td></td>\n      <td>25</td>\n      <td>depth_grid_model_13</td>\n      <td>0.818381904736367</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td></td>\n      <td>3</td>\n      <td>depth_grid_model_2</td>\n      <td>0.8154863611939805</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td></td>\n      <td>35</td>\n      <td>depth_grid_model_14</td>\n      <td>0.8135941320097503</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td></td>\n      <td>1</td>\n      <td>depth_grid_model_1</td>\n      <td>0.7686296114467771</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"#### Now that we have the proper depth for our RF, we will do a random grid search to try to find the next four parameters, categorical_encoding,histogram_type,mtries, and nbins."},{"metadata":{"trusted":true},"cell_type":"code","source":"hyper_parameters = {'categorical_encoding': ['auto','enum',\n                                             'one_hot_explicit', 'binary',\n                                             'label_encoder', 'sort_by_response',\n                                             'enum_limited'],\n                   'histogram_type': ['uniform_adaptive', 'random',\n                                      'quantiles_global', 'round_robin'],\n                   'nbins': [10,12,15,18,20,25,30,40,50] #Default = 20\n                   }\n\nrf = H2ORandomForestEstimator(max_depth = 10,\n                             ntrees = 50,\n                             seed = 42,\n                             stopping_rounds = 5,\n                             stopping_tolerance = 1e-5,\n                             stopping_metric = 'auc',\n                              model_id = 'rf'\n                             )\n\ngrid_id =  'rf_random_grid_'\n\nsearch_criteria = {'strategy': 'RandomDiscrete',\n                  'max_models': 100,\n                  'max_runtime_secs': 900,\n                  'seed': 42\n                  }\n\nrf_grid = H2OGridSearch(model = rf,\n                       hyper_params = hyper_parameters,\n                       grid_id = grid_id,\n                       search_criteria = search_criteria)\n\n%time rf_grid.train(x=x, y=y, training_frame = train, validation_frame = valid)\n    \n","execution_count":43,"outputs":[{"output_type":"stream","text":"drf Grid Build progress: |████████████████████████████████████████████████| 100%\nCPU times: user 4.55 s, sys: 223 ms, total: 4.77 s\nWall time: 15min 3s\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"sorted_rf = rf_grid.get_grid(sort_by='auc', decreasing=True)\nsorted_rf.sorted_metric_table()","execution_count":44,"outputs":[{"output_type":"execute_result","execution_count":44,"data":{"text/plain":"     categorical_encoding   histogram_type nbins                 model_ids  \\\n0          SortByResponse       RoundRobin    20  rf_random_grid__model_13   \n1          SortByResponse  QuantilesGlobal    40  rf_random_grid__model_12   \n2                    AUTO       RoundRobin    12   rf_random_grid__model_5   \n3                    Enum       RoundRobin    10   rf_random_grid__model_1   \n4          SortByResponse       RoundRobin    40  rf_random_grid__model_20   \n5             EnumLimited  UniformAdaptive    15   rf_random_grid__model_8   \n6          OneHotExplicit           Random    15  rf_random_grid__model_17   \n7             EnumLimited       RoundRobin    15   rf_random_grid__model_2   \n8          OneHotExplicit  UniformAdaptive    18   rf_random_grid__model_7   \n9             EnumLimited  QuantilesGlobal    25   rf_random_grid__model_3   \n10            EnumLimited  QuantilesGlobal    15   rf_random_grid__model_6   \n11            EnumLimited       RoundRobin    10  rf_random_grid__model_19   \n12                 Binary  UniformAdaptive    15  rf_random_grid__model_16   \n13                 Binary  QuantilesGlobal    10  rf_random_grid__model_14   \n14           LabelEncoder  UniformAdaptive    30  rf_random_grid__model_15   \n15                 Binary  QuantilesGlobal    30  rf_random_grid__model_10   \n16           LabelEncoder           Random    40  rf_random_grid__model_18   \n17            EnumLimited           Random    40  rf_random_grid__model_11   \n18           LabelEncoder       RoundRobin    15   rf_random_grid__model_9   \n19           LabelEncoder  QuantilesGlobal    18   rf_random_grid__model_4   \n\n                   auc  \n0   0.8488894949685589  \n1   0.8488213734380629  \n2    0.848509162113031  \n3   0.8476035518280373  \n4   0.8475552109565664  \n5     0.84196855609836  \n6    0.841501580106305  \n7   0.8410884416364995  \n8   0.8402644434787543  \n9   0.8402269658413825  \n10  0.8401774621668363  \n11  0.8380411223772769  \n12  0.8358527165842471  \n13    0.83568710429122  \n14  0.8353360132016181  \n15  0.8346134156341938  \n16  0.8343893094039178  \n17  0.8336008456757206  \n18  0.8298735259415956  \n19  0.8239937146409664  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>categorical_encoding</th>\n      <th>histogram_type</th>\n      <th>nbins</th>\n      <th>model_ids</th>\n      <th>auc</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td></td>\n      <td>SortByResponse</td>\n      <td>RoundRobin</td>\n      <td>20</td>\n      <td>rf_random_grid__model_13</td>\n      <td>0.8488894949685589</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td></td>\n      <td>SortByResponse</td>\n      <td>QuantilesGlobal</td>\n      <td>40</td>\n      <td>rf_random_grid__model_12</td>\n      <td>0.8488213734380629</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td></td>\n      <td>AUTO</td>\n      <td>RoundRobin</td>\n      <td>12</td>\n      <td>rf_random_grid__model_5</td>\n      <td>0.848509162113031</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td></td>\n      <td>Enum</td>\n      <td>RoundRobin</td>\n      <td>10</td>\n      <td>rf_random_grid__model_1</td>\n      <td>0.8476035518280373</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td></td>\n      <td>SortByResponse</td>\n      <td>RoundRobin</td>\n      <td>40</td>\n      <td>rf_random_grid__model_20</td>\n      <td>0.8475552109565664</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td></td>\n      <td>EnumLimited</td>\n      <td>UniformAdaptive</td>\n      <td>15</td>\n      <td>rf_random_grid__model_8</td>\n      <td>0.84196855609836</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td></td>\n      <td>OneHotExplicit</td>\n      <td>Random</td>\n      <td>15</td>\n      <td>rf_random_grid__model_17</td>\n      <td>0.841501580106305</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td></td>\n      <td>EnumLimited</td>\n      <td>RoundRobin</td>\n      <td>15</td>\n      <td>rf_random_grid__model_2</td>\n      <td>0.8410884416364995</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td></td>\n      <td>OneHotExplicit</td>\n      <td>UniformAdaptive</td>\n      <td>18</td>\n      <td>rf_random_grid__model_7</td>\n      <td>0.8402644434787543</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td></td>\n      <td>EnumLimited</td>\n      <td>QuantilesGlobal</td>\n      <td>25</td>\n      <td>rf_random_grid__model_3</td>\n      <td>0.8402269658413825</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td></td>\n      <td>EnumLimited</td>\n      <td>QuantilesGlobal</td>\n      <td>15</td>\n      <td>rf_random_grid__model_6</td>\n      <td>0.8401774621668363</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td></td>\n      <td>EnumLimited</td>\n      <td>RoundRobin</td>\n      <td>10</td>\n      <td>rf_random_grid__model_19</td>\n      <td>0.8380411223772769</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td></td>\n      <td>Binary</td>\n      <td>UniformAdaptive</td>\n      <td>15</td>\n      <td>rf_random_grid__model_16</td>\n      <td>0.8358527165842471</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td></td>\n      <td>Binary</td>\n      <td>QuantilesGlobal</td>\n      <td>10</td>\n      <td>rf_random_grid__model_14</td>\n      <td>0.83568710429122</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td></td>\n      <td>LabelEncoder</td>\n      <td>UniformAdaptive</td>\n      <td>30</td>\n      <td>rf_random_grid__model_15</td>\n      <td>0.8353360132016181</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td></td>\n      <td>Binary</td>\n      <td>QuantilesGlobal</td>\n      <td>30</td>\n      <td>rf_random_grid__model_10</td>\n      <td>0.8346134156341938</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td></td>\n      <td>LabelEncoder</td>\n      <td>Random</td>\n      <td>40</td>\n      <td>rf_random_grid__model_18</td>\n      <td>0.8343893094039178</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td></td>\n      <td>EnumLimited</td>\n      <td>Random</td>\n      <td>40</td>\n      <td>rf_random_grid__model_11</td>\n      <td>0.8336008456757206</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td></td>\n      <td>LabelEncoder</td>\n      <td>RoundRobin</td>\n      <td>15</td>\n      <td>rf_random_grid__model_9</td>\n      <td>0.8298735259415956</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td></td>\n      <td>LabelEncoder</td>\n      <td>QuantilesGlobal</td>\n      <td>18</td>\n      <td>rf_random_grid__model_4</td>\n      <td>0.8239937146409664</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"- The AUC improved using max_depth=10 and doing a random grid search for the parameters mentioned above.\n\n- Another important parameter that we can tune is the number of trees (ntrees).\n\n- ntrees specifies the number of trees that you want your RF to have. When tuning the number of trees, you need to be careful because when you have too many trees, your model will tend to overfit. That's why it's always advised to use cross-validation, and never tune models based on training scores. Again, you can also use early stopping; that way, your model stops training once the validation score is no longer improving.\n\n- We won't do a grid search for a maximum number of trees. We are going to update the parameters of our model with the values we found in the previous two grid searches that we did. We will use 500 trees while using early stopping; that way, if the model doesn't improve, it will automatically stop."},{"metadata":{"trusted":true},"cell_type":"code","source":"tuned_rf = H2ORandomForestEstimator (max_depth = 10,\n                                    seed = 42,\n                                    model_id = 'tuned_rf',\n                                    categorical_encoding = 'auto',\n                                    histogram_type ='quantiles_global',\n                                    mtries = 4,\n                                    nbins = 10,\n                                    ntrees = 500,\n                                     \n                                    stopping_rounds = 3,\n                                    stopping_tolerance = 1e-5,\n                                    stopping_metric = 'auc'\n                                    )\n%time tuned_rf.train(x=x, y=y, training_frame=train, validation_frame=valid)","execution_count":45,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.7/site-packages/h2o/estimators/estimator_base.py:200: RuntimeWarning: Dropping bad and constant columns: [LOAN_SEQUENCE_NUMBER]\n  warnings.warn(mesg[\"message\"], RuntimeWarning)\n","name":"stderr"},{"output_type":"stream","text":"drf Model Build progress: |███████████████████████████████████████████████| 100%\nCPU times: user 1.8 s, sys: 134 ms, total: 1.93 s\nWall time: 6min 21s\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"- lets take a look if the model is not overfitting:"},{"metadata":{"trusted":true},"cell_type":"code","source":"tuned_rf.plot(metric='auc')","execution_count":46,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"metadata":{},"cell_type":"markdown","source":"#### By looking at the plot above, we can see that if we were to use less than 500 trees, we would get a similar score. Even if you use more than 500 trees, the training AUC might keep increasing, but the validation AUC will remain the same. For that reason, one way to find a good number of trees is just to build a model with a large number of trees, and from the scoring plot, identify a good cut-off or just use more aggressive early stopping settings. Please keep in mind that you need to be doing cross-validation.\n\n#### From the scoring history plot, we can see that the Validation AUC starts plateauing around 200 trees, but keeps slightly increasing. H2O models are, by default, optimized to give a good performance; therefore, sometimes, there is not much tuning to be done. We will see that with the GBM model as well."},{"metadata":{},"cell_type":"markdown","source":"- Print validation AUC"},{"metadata":{"trusted":true},"cell_type":"code","source":"tuned_rf_per = tuned_rf.model_performance(valid)\ntuned_rf_per.auc()","execution_count":47,"outputs":[{"output_type":"execute_result","execution_count":47,"data":{"text/plain":"0.8516867179180316"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"- F1 Score:"},{"metadata":{"trusted":true},"cell_type":"code","source":"tuned_rf_per.F1()","execution_count":48,"outputs":[{"output_type":"execute_result","execution_count":48,"data":{"text/plain":"[[0.1301545067565406, 0.2994997579473939]]"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"- The AUC from the validation data was 0.8516, and the F1 Score 0.2993.\n\n- Compare the tuned model with the dafault one:"},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Default RF AUC: %.4f \\nTuned RF AUC: %.4f' % (rf_default_per.auc(), tuned_rf_per.auc()))","execution_count":49,"outputs":[{"output_type":"stream","text":"Default RF AUC: 0.8264 \nTuned RF AUC: 0.8517\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"- The AUC value for our RF model had a decent improvement by changing the max_depth, doing a quick random search for the parameters categorical_encoding,histogram_type,mtries, and nbins. Also by increasing the number of trees. Let's see if the F1 Score improved :"},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Default RF F1 Score:', rf_default_per.F1())\nprint('Tuned RF F1 Score:', tuned_rf_per.F1())","execution_count":50,"outputs":[{"output_type":"stream","text":"Default RF F1 Score: [[0.1855035085498162, 0.2832572832572833]]\nTuned RF F1 Score: [[0.1301545067565406, 0.2994997579473939]]\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"- The F1 score also improved. Although the F1 score is still low, we will look at the confusion matrix, and let's see how this improvement reflects on the confusion matrix"},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Default RF: ', rf_default_per.confusion_matrix())\nprint('Tuned RF: ', tuned_rf_per.confusion_matrix())","execution_count":51,"outputs":[{"output_type":"stream","text":"Default RF:  \nConfusion Matrix (Act/Pred) for max f1 @ threshold = 0.1855035085498162: \n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"            FALSE    TRUE   Error               Rate\n0  FALSE  70080.0  2233.0  0.0309   (2233.0/72313.0)\n1   TRUE   1851.0   807.0  0.6964    (1851.0/2658.0)\n2  Total  71931.0  3040.0  0.0545   (4084.0/74971.0)","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>FALSE</th>\n      <th>TRUE</th>\n      <th>Error</th>\n      <th>Rate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>FALSE</td>\n      <td>70080.0</td>\n      <td>2233.0</td>\n      <td>0.0309</td>\n      <td>(2233.0/72313.0)</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>TRUE</td>\n      <td>1851.0</td>\n      <td>807.0</td>\n      <td>0.6964</td>\n      <td>(1851.0/2658.0)</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Total</td>\n      <td>71931.0</td>\n      <td>3040.0</td>\n      <td>0.0545</td>\n      <td>(4084.0/74971.0)</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"stream","text":"\nTuned RF:  \nConfusion Matrix (Act/Pred) for max f1 @ threshold = 0.1301545067565406: \n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"            FALSE    TRUE   Error               Rate\n0  FALSE  69702.0  2611.0  0.0361   (2611.0/72313.0)\n1   TRUE   1730.0   928.0  0.6509    (1730.0/2658.0)\n2  Total  71432.0  3539.0  0.0579   (4341.0/74971.0)","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>FALSE</th>\n      <th>TRUE</th>\n      <th>Error</th>\n      <th>Rate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>FALSE</td>\n      <td>69702.0</td>\n      <td>2611.0</td>\n      <td>0.0361</td>\n      <td>(2611.0/72313.0)</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>TRUE</td>\n      <td>1730.0</td>\n      <td>928.0</td>\n      <td>0.6509</td>\n      <td>(1730.0/2658.0)</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Total</td>\n      <td>71432.0</td>\n      <td>3539.0</td>\n      <td>0.0579</td>\n      <td>(4341.0/74971.0)</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"stream","text":"\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"#### The AUC for our tuned model actually improved, as well as the F1 Score. However, the misclassification error slightly increased. The new model is predicting fewer FALSE labels that are actually FALSE; this means the model is classifying more FALSE labels incorrectly. On the bright side, the model is predicting more TRUE labels correctly, and thus, we have a smaller misclassification error for the TRUE label. It is good to see that the model now predicts more TRUE labels as TRUE because we saw that the default model, as well as the GLM, were also having a hard time making those predictions.\n\nNow, we will see if we can improve our GBM model."},{"metadata":{},"cell_type":"markdown","source":"## Tune the GBM model with H2O GridSearch"},{"metadata":{},"cell_type":"markdown","source":"- We will take a similar approach to the tuning of the RF model. We could do the grid search for a list of a number of trees, but since the scoring history will show us the validation score based on the number of trees, we will obtain that number from the plot. We will be using 50 trees, which is the default. For a GBM model, conceptually speaking, the max_depth and ntrees is the same as the RF model. However, we will see that the values are smaller than the ones used for the RF."},{"metadata":{"trusted":true},"cell_type":"code","source":"hyper_params = {'max_depth': [3,4,5,6,7,8,9,10,11,12,13,15],\n               }\n\ngbm = H2OGradientBoostingEstimator(model_id = 'grid_gbm', ntrees = 50,\n                                  seed = 42\n                                  )\ngbm_grid = H2OGridSearch(gbm, hyper_params,\n                        grid_id = 'depth_gbm_grid',\n                        search_criteria = {'strategy': \"Cartesian\"})\n\n%time gbm_grid.train(x=x, y=y, training_frame=train, validation_frame=valid)","execution_count":52,"outputs":[{"output_type":"stream","text":"gbm Grid Build progress: |████████████████████████████████████████████████| 100%\nCPU times: user 2.67 s, sys: 114 ms, total: 2.79 s\nWall time: 11min 37s\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"sorted_gbm_depth = gbm_grid.get_grid(sort_by='auc', decreasing=True)\nsorted_gbm_depth.sorted_metric_table()","execution_count":53,"outputs":[{"output_type":"execute_result","execution_count":53,"data":{"text/plain":"     max_depth                model_ids                 auc\n0            6   depth_gbm_grid_model_4  0.8545357753508993\n1            5   depth_gbm_grid_model_3  0.8541002080486222\n2            7   depth_gbm_grid_model_5  0.8529009496662141\n3            8   depth_gbm_grid_model_6  0.8512531640600055\n4            4   depth_gbm_grid_model_2  0.8512081321046683\n5            9   depth_gbm_grid_model_7  0.8497842446208027\n6            3   depth_gbm_grid_model_1  0.8476725422091533\n7           10   depth_gbm_grid_model_8  0.8449705260376477\n8           11   depth_gbm_grid_model_9  0.8376480533162535\n9           12  depth_gbm_grid_model_10  0.8346376914245702\n10          13  depth_gbm_grid_model_11  0.8323679024230184\n11          15  depth_gbm_grid_model_12  0.8258963049989075","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>max_depth</th>\n      <th>model_ids</th>\n      <th>auc</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td></td>\n      <td>6</td>\n      <td>depth_gbm_grid_model_4</td>\n      <td>0.8545357753508993</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td></td>\n      <td>5</td>\n      <td>depth_gbm_grid_model_3</td>\n      <td>0.8541002080486222</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td></td>\n      <td>7</td>\n      <td>depth_gbm_grid_model_5</td>\n      <td>0.8529009496662141</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td></td>\n      <td>8</td>\n      <td>depth_gbm_grid_model_6</td>\n      <td>0.8512531640600055</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td></td>\n      <td>4</td>\n      <td>depth_gbm_grid_model_2</td>\n      <td>0.8512081321046683</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td></td>\n      <td>9</td>\n      <td>depth_gbm_grid_model_7</td>\n      <td>0.8497842446208027</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td></td>\n      <td>3</td>\n      <td>depth_gbm_grid_model_1</td>\n      <td>0.8476725422091533</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td></td>\n      <td>10</td>\n      <td>depth_gbm_grid_model_8</td>\n      <td>0.8449705260376477</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td></td>\n      <td>11</td>\n      <td>depth_gbm_grid_model_9</td>\n      <td>0.8376480533162535</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td></td>\n      <td>12</td>\n      <td>depth_gbm_grid_model_10</td>\n      <td>0.8346376914245702</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td></td>\n      <td>13</td>\n      <td>depth_gbm_grid_model_11</td>\n      <td>0.8323679024230184</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td></td>\n      <td>15</td>\n      <td>depth_gbm_grid_model_12</td>\n      <td>0.8258963049989075</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"Based on the grid search that we just did, the best max_depth is 6.\nWe will do a random grid search with a few parameters to see if we can get a better model. We will use 50 trees, and after we find some values from the random grid search, we will increase the number of trees.\n\nNote: You don't have to run the following line of code unless you want to see it for yourself. The search criteria will only allow the grid search to run for 15 minutes, if you would like to see the results of running it for longer, just increase the max_runtime_secs to a higher value and wait for the results.\n\nHere is the list of parameters that we are going to try to tune\n\n1. sample_rate: Specify the row sampling rate (x-axis). (Note that this method is sample without replacement.) The range is 0.0 to 1.0, and this value defaults to 1. Higher values may improve training accuracy. Test accuracy improves when either columns or rows are sampled.\n\n2. col_sample_rate: Specify the column sampling rate (y-axis). (Note that this method is sampling without replacement.) The range is 0.0 to 1.0.\n\n3. col_sample_rate_per_tree: Specify the column sample rate per tree. This can be a value from 0.0 to 1.0 and defaults to 1. Note that it is multiplicative with col_sample_rate, so setting both parameters to 0.8, for example, results in 64% of columns being considered at any given node to split.\n\n4. col_sample_rate_change_per_level: This option specifies to change the column sampling rate as a function of the depth in the tree.\n\n5. learn_rate: Specify the learning rate. The range is 0.0 to 1.0.\n\nnbins: Specify the number of bins for the histogram to build, then split at the best point.\n\n6. nbins_cats: Specify the maximum number of bins for the histogram to build, then split at the best point. Higher values can lead to more overfitting.\n\n7. min_split_improvement: The value of this option specifies the minimum relative improvement in squared error reduction in order for a split to happen.\n\n8. histogram_type: Random split points or quantile-based split points can be selected as well. RoundRobin can be specified to cycle through all histogram types (one per tree). Use this option to specify the type of histogram to use for finding optimal split points.\n\nFind more parameters and more information about them at the Documentation - GBM Section and also the Python Module\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"gbm = H2OGradientBoostingEstimator(\n    max_depth = 6,\n    ntrees = 50,\n    seed = 42,\n    model_id = 'grid_gbm'\n)\n\nhyper_params_tune = {\n    'sample_rate': [x/100. for x in range(20,101)],\n    'col_sample_rate': [x/100. for x in range(20,101)],\n    'col_sample_rate_per_tree': [x/100. for x in range(20,101)],\n    'col_sample_rate_change_per_level': [x/100. for x in range(90,111)],\n    'learn_rate': [.5, .25, 0.1, 0.07, 0.05, 0.01, 0.001],\n    'nbins': [2**x for x in range(4,11)],\n    'nbins_cats': [2**x for x in range(4,13)],\n    'min_split_improvement': [0,1e-8,1e-6,1e-4],\n    'histogram_type': ['UniformAdaptive', 'QuantilesGlobal', 'RoundRobin']}\n\nsearch_criteria_tune = {'strategy': 'RandomDiscrete',\n                       'max_runtime_secs': 1200,\n                       'max_models': 100, ##build no more than 100 models\n                       'seed': 42 }\n\nrandom_grid = H2OGridSearch(model=gbm, \n                            hyper_params=hyper_params_tune,\n                           grid_id= 'random_grid',\n                           search_criteria = search_criteria_tune)\n\n%time random_grid.train(x=x, y=y, training_frame=train, validation_frame=valid)","execution_count":54,"outputs":[{"output_type":"stream","text":"gbm Grid Build progress: |████████████████████████████████████████████████| 100%\nCPU times: user 6.89 s, sys: 370 ms, total: 7.26 s\nWall time: 20min 4s\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"sorted_random_search = random_grid.get_grid(sort_by='auc',decreasing=True)\nsorted_random_search.sorted_metric_table()","execution_count":55,"outputs":[{"output_type":"execute_result","execution_count":55,"data":{"text/plain":"     col_sample_rate col_sample_rate_change_per_level  \\\n0               0.68                             0.92   \n1               0.91                             1.05   \n2               0.91                              0.9   \n3               0.99                             0.96   \n4               0.46                             0.93   \n5               0.67                             1.07   \n6               0.28                             1.04   \n7               0.93                             0.93   \n8               0.85                             0.91   \n9               0.78                             0.96   \n10              0.41                             0.98   \n11              0.78                             0.92   \n12              0.85                              1.0   \n13              0.26                             0.98   \n14              0.77                             0.94   \n15              0.37                              0.9   \n16              0.99                             0.96   \n17              0.55                             0.96   \n18              0.77                             0.98   \n19              0.43                             1.08   \n20              0.82                             0.95   \n21               0.7                             1.02   \n22              0.82                             0.91   \n23               0.5                             1.02   \n24              0.26                             1.01   \n25              0.64                             0.91   \n26              0.55                             0.99   \n27              0.99                             0.99   \n28               0.2                             0.91   \n29               0.4                             0.98   \n30              0.49                             1.02   \n31              0.77                             0.95   \n32              0.41                             1.07   \n33              0.25                             0.99   \n34              0.43                              0.9   \n35              0.93                              1.0   \n36              0.23                             0.96   \n37              0.23                              1.0   \n38              0.92                             1.02   \n39              0.92                             0.92   \n40              0.37                             0.97   \n41              0.55                             1.07   \n42               0.5                             0.91   \n43              0.44                             1.01   \n44              0.83                             1.08   \n45              0.31                             1.04   \n46              0.93                              1.0   \n47               0.2                             0.95   \n48              0.63                             0.93   \n49               0.2                              1.1   \n50              0.22                             0.94   \n\n   col_sample_rate_per_tree   histogram_type learn_rate min_split_improvement  \\\n0                      0.59  UniformAdaptive        0.1                1.0E-6   \n1                      0.46  QuantilesGlobal       0.07                1.0E-4   \n2                      0.68  QuantilesGlobal        0.1                1.0E-4   \n3                      0.49       RoundRobin       0.05                1.0E-8   \n4                      0.75       RoundRobin        0.1                1.0E-4   \n5                      0.74       RoundRobin       0.05                1.0E-4   \n6                      0.38  QuantilesGlobal        0.1                   0.0   \n7                      0.41  QuantilesGlobal       0.07                1.0E-4   \n8                      0.74       RoundRobin       0.25                1.0E-4   \n9                      0.98  QuantilesGlobal        0.1                1.0E-4   \n10                      0.5  UniformAdaptive       0.25                1.0E-6   \n11                     0.27       RoundRobin        0.5                1.0E-6   \n12                     0.44       RoundRobin        0.5                   0.0   \n13                     0.91  QuantilesGlobal        0.1                1.0E-8   \n14                     0.34  UniformAdaptive       0.05                1.0E-6   \n15                     0.75  QuantilesGlobal       0.25                1.0E-4   \n16                     0.34  UniformAdaptive        0.5                   0.0   \n17                     0.34  UniformAdaptive       0.05                   0.0   \n18                      0.9  UniformAdaptive       0.05                   0.0   \n19                     0.92  UniformAdaptive       0.25                1.0E-8   \n20                     0.42  QuantilesGlobal       0.01                   0.0   \n21                     0.49       RoundRobin       0.07                1.0E-8   \n22                     0.99  UniformAdaptive       0.05                1.0E-4   \n23                     0.38  QuantilesGlobal        0.5                1.0E-8   \n24                     0.52  UniformAdaptive        0.1                1.0E-4   \n25                     0.49       RoundRobin       0.01                1.0E-8   \n26                     0.49  UniformAdaptive       0.01                1.0E-4   \n27                     0.67  UniformAdaptive      0.001                1.0E-6   \n28                     0.54  UniformAdaptive       0.07                1.0E-4   \n29                     0.73       RoundRobin        0.5                1.0E-6   \n30                     0.54  UniformAdaptive      0.001                   0.0   \n31                     0.67  QuantilesGlobal      0.001                1.0E-4   \n32                     0.43       RoundRobin       0.01                1.0E-4   \n33                     0.97  QuantilesGlobal      0.001                1.0E-4   \n34                     0.87       RoundRobin      0.001                1.0E-8   \n35                     0.48  UniformAdaptive      0.001                1.0E-6   \n36                     0.97       RoundRobin        0.5                1.0E-8   \n37                     0.75       RoundRobin      0.001                1.0E-4   \n38                     0.99       RoundRobin      0.001                1.0E-6   \n39                     0.59       RoundRobin      0.001                1.0E-4   \n40                     0.35  QuantilesGlobal        0.5                1.0E-8   \n41                     0.28  QuantilesGlobal       0.01                1.0E-8   \n42                     0.54  UniformAdaptive        0.5                1.0E-8   \n43                     0.63       RoundRobin        0.5                1.0E-6   \n44                     0.26  QuantilesGlobal        0.5                   0.0   \n45                     0.32  QuantilesGlobal       0.01                1.0E-6   \n46                     0.25  UniformAdaptive        0.5                1.0E-6   \n47                     0.27       RoundRobin       0.05                   0.0   \n48                     0.33  QuantilesGlobal      0.001                1.0E-6   \n49                     0.31  QuantilesGlobal      0.001                1.0E-6   \n50                     0.35  QuantilesGlobal      0.001                1.0E-8   \n\n   nbins nbins_cats sample_rate             model_ids                 auc  \n0     16        128         0.7  random_grid_model_41  0.8576773258821536  \n1   1024       1024        0.63  random_grid_model_17  0.8566483440118197  \n2     16        256        0.55   random_grid_model_7   0.855462997644728  \n3     64        512        0.82  random_grid_model_20  0.8551429094344347  \n4     32        256        0.92  random_grid_model_27   0.854659794672181  \n5     32        256        0.57  random_grid_model_18   0.853612114304073  \n6   1024       4096        0.58  random_grid_model_22  0.8534286983773836  \n7   1024         32        0.58  random_grid_model_45  0.8531069791211657  \n8    512       4096        0.95  random_grid_model_13  0.8512727079962571  \n9    512       4096        0.54  random_grid_model_10  0.8510067954836041  \n10    32       1024        0.58  random_grid_model_37  0.8499386529029906  \n11   256        128        0.66  random_grid_model_12  0.8489202793345378  \n12   128        512        0.93   random_grid_model_8   0.848829744579665  \n13  1024        512        0.53  random_grid_model_51  0.8481275519950647  \n14    16       1024        0.24  random_grid_model_21  0.8481006202271941  \n15    16         64        0.53  random_grid_model_43  0.8479129094730388  \n16    32        512        0.78  random_grid_model_40  0.8476372835226164  \n17    64        512        0.47  random_grid_model_11  0.8473929882214968  \n18   512         32        0.33  random_grid_model_34  0.8468289715003158  \n19    32       2048        0.47   random_grid_model_6  0.8466654532933637  \n20    32       1024        0.27  random_grid_model_28  0.8463576798700017  \n21  1024         16        0.53   random_grid_model_2  0.8462450934782855  \n22   128         32        0.95  random_grid_model_24  0.8461099247744971  \n23  1024         16        0.74  random_grid_model_25  0.8457884578491481  \n24    64         32         0.3   random_grid_model_5  0.8453561578414179  \n25   256       4096        0.58  random_grid_model_39  0.8441269449234136  \n26    32        128        0.81  random_grid_model_30  0.8432352336469905  \n27   128       4096        0.78  random_grid_model_16  0.8421069114548715  \n28    32         64        0.57  random_grid_model_32  0.8420492031250695  \n29    64        256        0.82  random_grid_model_48  0.8408996799372829  \n30   128       4096        0.29  random_grid_model_42  0.8407320073757197  \n31    64         64        0.83  random_grid_model_31  0.8405237641726315  \n32    16       1024        0.27  random_grid_model_36  0.8387886018494323  \n33   512       1024        0.93   random_grid_model_3  0.8382085478106697  \n34    16        256        0.79  random_grid_model_26  0.8376103415574571  \n35   512         32        0.61   random_grid_model_1  0.8366632579627792  \n36    16         64         0.8  random_grid_model_44  0.8362339469052358  \n37   512         64        0.72  random_grid_model_23  0.8353153142663389  \n38    16       1024        0.34   random_grid_model_4  0.8352053032102927  \n39  1024         32        0.72  random_grid_model_14  0.8348036575010834  \n40  1024       4096        0.29  random_grid_model_29  0.8330279245363592  \n41   128         64        0.89  random_grid_model_47  0.8326879724238675  \n42  1024        256        0.38  random_grid_model_46  0.8302291850003252  \n43    32        128        0.44  random_grid_model_15  0.8292532004164614  \n44    64         32        0.25  random_grid_model_35  0.8284299410418781  \n45   512        256        0.53  random_grid_model_33  0.8281194960329269  \n46    16         64        0.24  random_grid_model_19   0.827822989052784  \n47   128         64        0.45  random_grid_model_38  0.8256407198424265  \n48    16       2048        0.31  random_grid_model_49  0.8250635220850434  \n49   256        128        0.58   random_grid_model_9  0.8241806631998174  \n50  1024        256        0.75  random_grid_model_50  0.8138247416129303  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>col_sample_rate</th>\n      <th>col_sample_rate_change_per_level</th>\n      <th>col_sample_rate_per_tree</th>\n      <th>histogram_type</th>\n      <th>learn_rate</th>\n      <th>min_split_improvement</th>\n      <th>nbins</th>\n      <th>nbins_cats</th>\n      <th>sample_rate</th>\n      <th>model_ids</th>\n      <th>auc</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td></td>\n      <td>0.68</td>\n      <td>0.92</td>\n      <td>0.59</td>\n      <td>UniformAdaptive</td>\n      <td>0.1</td>\n      <td>1.0E-6</td>\n      <td>16</td>\n      <td>128</td>\n      <td>0.7</td>\n      <td>random_grid_model_41</td>\n      <td>0.8576773258821536</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td></td>\n      <td>0.91</td>\n      <td>1.05</td>\n      <td>0.46</td>\n      <td>QuantilesGlobal</td>\n      <td>0.07</td>\n      <td>1.0E-4</td>\n      <td>1024</td>\n      <td>1024</td>\n      <td>0.63</td>\n      <td>random_grid_model_17</td>\n      <td>0.8566483440118197</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td></td>\n      <td>0.91</td>\n      <td>0.9</td>\n      <td>0.68</td>\n      <td>QuantilesGlobal</td>\n      <td>0.1</td>\n      <td>1.0E-4</td>\n      <td>16</td>\n      <td>256</td>\n      <td>0.55</td>\n      <td>random_grid_model_7</td>\n      <td>0.855462997644728</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td></td>\n      <td>0.99</td>\n      <td>0.96</td>\n      <td>0.49</td>\n      <td>RoundRobin</td>\n      <td>0.05</td>\n      <td>1.0E-8</td>\n      <td>64</td>\n      <td>512</td>\n      <td>0.82</td>\n      <td>random_grid_model_20</td>\n      <td>0.8551429094344347</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td></td>\n      <td>0.46</td>\n      <td>0.93</td>\n      <td>0.75</td>\n      <td>RoundRobin</td>\n      <td>0.1</td>\n      <td>1.0E-4</td>\n      <td>32</td>\n      <td>256</td>\n      <td>0.92</td>\n      <td>random_grid_model_27</td>\n      <td>0.854659794672181</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td></td>\n      <td>0.67</td>\n      <td>1.07</td>\n      <td>0.74</td>\n      <td>RoundRobin</td>\n      <td>0.05</td>\n      <td>1.0E-4</td>\n      <td>32</td>\n      <td>256</td>\n      <td>0.57</td>\n      <td>random_grid_model_18</td>\n      <td>0.853612114304073</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td></td>\n      <td>0.28</td>\n      <td>1.04</td>\n      <td>0.38</td>\n      <td>QuantilesGlobal</td>\n      <td>0.1</td>\n      <td>0.0</td>\n      <td>1024</td>\n      <td>4096</td>\n      <td>0.58</td>\n      <td>random_grid_model_22</td>\n      <td>0.8534286983773836</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td></td>\n      <td>0.93</td>\n      <td>0.93</td>\n      <td>0.41</td>\n      <td>QuantilesGlobal</td>\n      <td>0.07</td>\n      <td>1.0E-4</td>\n      <td>1024</td>\n      <td>32</td>\n      <td>0.58</td>\n      <td>random_grid_model_45</td>\n      <td>0.8531069791211657</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td></td>\n      <td>0.85</td>\n      <td>0.91</td>\n      <td>0.74</td>\n      <td>RoundRobin</td>\n      <td>0.25</td>\n      <td>1.0E-4</td>\n      <td>512</td>\n      <td>4096</td>\n      <td>0.95</td>\n      <td>random_grid_model_13</td>\n      <td>0.8512727079962571</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td></td>\n      <td>0.78</td>\n      <td>0.96</td>\n      <td>0.98</td>\n      <td>QuantilesGlobal</td>\n      <td>0.1</td>\n      <td>1.0E-4</td>\n      <td>512</td>\n      <td>4096</td>\n      <td>0.54</td>\n      <td>random_grid_model_10</td>\n      <td>0.8510067954836041</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td></td>\n      <td>0.41</td>\n      <td>0.98</td>\n      <td>0.5</td>\n      <td>UniformAdaptive</td>\n      <td>0.25</td>\n      <td>1.0E-6</td>\n      <td>32</td>\n      <td>1024</td>\n      <td>0.58</td>\n      <td>random_grid_model_37</td>\n      <td>0.8499386529029906</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td></td>\n      <td>0.78</td>\n      <td>0.92</td>\n      <td>0.27</td>\n      <td>RoundRobin</td>\n      <td>0.5</td>\n      <td>1.0E-6</td>\n      <td>256</td>\n      <td>128</td>\n      <td>0.66</td>\n      <td>random_grid_model_12</td>\n      <td>0.8489202793345378</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td></td>\n      <td>0.85</td>\n      <td>1.0</td>\n      <td>0.44</td>\n      <td>RoundRobin</td>\n      <td>0.5</td>\n      <td>0.0</td>\n      <td>128</td>\n      <td>512</td>\n      <td>0.93</td>\n      <td>random_grid_model_8</td>\n      <td>0.848829744579665</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td></td>\n      <td>0.26</td>\n      <td>0.98</td>\n      <td>0.91</td>\n      <td>QuantilesGlobal</td>\n      <td>0.1</td>\n      <td>1.0E-8</td>\n      <td>1024</td>\n      <td>512</td>\n      <td>0.53</td>\n      <td>random_grid_model_51</td>\n      <td>0.8481275519950647</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td></td>\n      <td>0.77</td>\n      <td>0.94</td>\n      <td>0.34</td>\n      <td>UniformAdaptive</td>\n      <td>0.05</td>\n      <td>1.0E-6</td>\n      <td>16</td>\n      <td>1024</td>\n      <td>0.24</td>\n      <td>random_grid_model_21</td>\n      <td>0.8481006202271941</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td></td>\n      <td>0.37</td>\n      <td>0.9</td>\n      <td>0.75</td>\n      <td>QuantilesGlobal</td>\n      <td>0.25</td>\n      <td>1.0E-4</td>\n      <td>16</td>\n      <td>64</td>\n      <td>0.53</td>\n      <td>random_grid_model_43</td>\n      <td>0.8479129094730388</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td></td>\n      <td>0.99</td>\n      <td>0.96</td>\n      <td>0.34</td>\n      <td>UniformAdaptive</td>\n      <td>0.5</td>\n      <td>0.0</td>\n      <td>32</td>\n      <td>512</td>\n      <td>0.78</td>\n      <td>random_grid_model_40</td>\n      <td>0.8476372835226164</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td></td>\n      <td>0.55</td>\n      <td>0.96</td>\n      <td>0.34</td>\n      <td>UniformAdaptive</td>\n      <td>0.05</td>\n      <td>0.0</td>\n      <td>64</td>\n      <td>512</td>\n      <td>0.47</td>\n      <td>random_grid_model_11</td>\n      <td>0.8473929882214968</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td></td>\n      <td>0.77</td>\n      <td>0.98</td>\n      <td>0.9</td>\n      <td>UniformAdaptive</td>\n      <td>0.05</td>\n      <td>0.0</td>\n      <td>512</td>\n      <td>32</td>\n      <td>0.33</td>\n      <td>random_grid_model_34</td>\n      <td>0.8468289715003158</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td></td>\n      <td>0.43</td>\n      <td>1.08</td>\n      <td>0.92</td>\n      <td>UniformAdaptive</td>\n      <td>0.25</td>\n      <td>1.0E-8</td>\n      <td>32</td>\n      <td>2048</td>\n      <td>0.47</td>\n      <td>random_grid_model_6</td>\n      <td>0.8466654532933637</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td></td>\n      <td>0.82</td>\n      <td>0.95</td>\n      <td>0.42</td>\n      <td>QuantilesGlobal</td>\n      <td>0.01</td>\n      <td>0.0</td>\n      <td>32</td>\n      <td>1024</td>\n      <td>0.27</td>\n      <td>random_grid_model_28</td>\n      <td>0.8463576798700017</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td></td>\n      <td>0.7</td>\n      <td>1.02</td>\n      <td>0.49</td>\n      <td>RoundRobin</td>\n      <td>0.07</td>\n      <td>1.0E-8</td>\n      <td>1024</td>\n      <td>16</td>\n      <td>0.53</td>\n      <td>random_grid_model_2</td>\n      <td>0.8462450934782855</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td></td>\n      <td>0.82</td>\n      <td>0.91</td>\n      <td>0.99</td>\n      <td>UniformAdaptive</td>\n      <td>0.05</td>\n      <td>1.0E-4</td>\n      <td>128</td>\n      <td>32</td>\n      <td>0.95</td>\n      <td>random_grid_model_24</td>\n      <td>0.8461099247744971</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td></td>\n      <td>0.5</td>\n      <td>1.02</td>\n      <td>0.38</td>\n      <td>QuantilesGlobal</td>\n      <td>0.5</td>\n      <td>1.0E-8</td>\n      <td>1024</td>\n      <td>16</td>\n      <td>0.74</td>\n      <td>random_grid_model_25</td>\n      <td>0.8457884578491481</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td></td>\n      <td>0.26</td>\n      <td>1.01</td>\n      <td>0.52</td>\n      <td>UniformAdaptive</td>\n      <td>0.1</td>\n      <td>1.0E-4</td>\n      <td>64</td>\n      <td>32</td>\n      <td>0.3</td>\n      <td>random_grid_model_5</td>\n      <td>0.8453561578414179</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td></td>\n      <td>0.64</td>\n      <td>0.91</td>\n      <td>0.49</td>\n      <td>RoundRobin</td>\n      <td>0.01</td>\n      <td>1.0E-8</td>\n      <td>256</td>\n      <td>4096</td>\n      <td>0.58</td>\n      <td>random_grid_model_39</td>\n      <td>0.8441269449234136</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td></td>\n      <td>0.55</td>\n      <td>0.99</td>\n      <td>0.49</td>\n      <td>UniformAdaptive</td>\n      <td>0.01</td>\n      <td>1.0E-4</td>\n      <td>32</td>\n      <td>128</td>\n      <td>0.81</td>\n      <td>random_grid_model_30</td>\n      <td>0.8432352336469905</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td></td>\n      <td>0.99</td>\n      <td>0.99</td>\n      <td>0.67</td>\n      <td>UniformAdaptive</td>\n      <td>0.001</td>\n      <td>1.0E-6</td>\n      <td>128</td>\n      <td>4096</td>\n      <td>0.78</td>\n      <td>random_grid_model_16</td>\n      <td>0.8421069114548715</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td></td>\n      <td>0.2</td>\n      <td>0.91</td>\n      <td>0.54</td>\n      <td>UniformAdaptive</td>\n      <td>0.07</td>\n      <td>1.0E-4</td>\n      <td>32</td>\n      <td>64</td>\n      <td>0.57</td>\n      <td>random_grid_model_32</td>\n      <td>0.8420492031250695</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td></td>\n      <td>0.4</td>\n      <td>0.98</td>\n      <td>0.73</td>\n      <td>RoundRobin</td>\n      <td>0.5</td>\n      <td>1.0E-6</td>\n      <td>64</td>\n      <td>256</td>\n      <td>0.82</td>\n      <td>random_grid_model_48</td>\n      <td>0.8408996799372829</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td></td>\n      <td>0.49</td>\n      <td>1.02</td>\n      <td>0.54</td>\n      <td>UniformAdaptive</td>\n      <td>0.001</td>\n      <td>0.0</td>\n      <td>128</td>\n      <td>4096</td>\n      <td>0.29</td>\n      <td>random_grid_model_42</td>\n      <td>0.8407320073757197</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td></td>\n      <td>0.77</td>\n      <td>0.95</td>\n      <td>0.67</td>\n      <td>QuantilesGlobal</td>\n      <td>0.001</td>\n      <td>1.0E-4</td>\n      <td>64</td>\n      <td>64</td>\n      <td>0.83</td>\n      <td>random_grid_model_31</td>\n      <td>0.8405237641726315</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td></td>\n      <td>0.41</td>\n      <td>1.07</td>\n      <td>0.43</td>\n      <td>RoundRobin</td>\n      <td>0.01</td>\n      <td>1.0E-4</td>\n      <td>16</td>\n      <td>1024</td>\n      <td>0.27</td>\n      <td>random_grid_model_36</td>\n      <td>0.8387886018494323</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td></td>\n      <td>0.25</td>\n      <td>0.99</td>\n      <td>0.97</td>\n      <td>QuantilesGlobal</td>\n      <td>0.001</td>\n      <td>1.0E-4</td>\n      <td>512</td>\n      <td>1024</td>\n      <td>0.93</td>\n      <td>random_grid_model_3</td>\n      <td>0.8382085478106697</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td></td>\n      <td>0.43</td>\n      <td>0.9</td>\n      <td>0.87</td>\n      <td>RoundRobin</td>\n      <td>0.001</td>\n      <td>1.0E-8</td>\n      <td>16</td>\n      <td>256</td>\n      <td>0.79</td>\n      <td>random_grid_model_26</td>\n      <td>0.8376103415574571</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td></td>\n      <td>0.93</td>\n      <td>1.0</td>\n      <td>0.48</td>\n      <td>UniformAdaptive</td>\n      <td>0.001</td>\n      <td>1.0E-6</td>\n      <td>512</td>\n      <td>32</td>\n      <td>0.61</td>\n      <td>random_grid_model_1</td>\n      <td>0.8366632579627792</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td></td>\n      <td>0.23</td>\n      <td>0.96</td>\n      <td>0.97</td>\n      <td>RoundRobin</td>\n      <td>0.5</td>\n      <td>1.0E-8</td>\n      <td>16</td>\n      <td>64</td>\n      <td>0.8</td>\n      <td>random_grid_model_44</td>\n      <td>0.8362339469052358</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td></td>\n      <td>0.23</td>\n      <td>1.0</td>\n      <td>0.75</td>\n      <td>RoundRobin</td>\n      <td>0.001</td>\n      <td>1.0E-4</td>\n      <td>512</td>\n      <td>64</td>\n      <td>0.72</td>\n      <td>random_grid_model_23</td>\n      <td>0.8353153142663389</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td></td>\n      <td>0.92</td>\n      <td>1.02</td>\n      <td>0.99</td>\n      <td>RoundRobin</td>\n      <td>0.001</td>\n      <td>1.0E-6</td>\n      <td>16</td>\n      <td>1024</td>\n      <td>0.34</td>\n      <td>random_grid_model_4</td>\n      <td>0.8352053032102927</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td></td>\n      <td>0.92</td>\n      <td>0.92</td>\n      <td>0.59</td>\n      <td>RoundRobin</td>\n      <td>0.001</td>\n      <td>1.0E-4</td>\n      <td>1024</td>\n      <td>32</td>\n      <td>0.72</td>\n      <td>random_grid_model_14</td>\n      <td>0.8348036575010834</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td></td>\n      <td>0.37</td>\n      <td>0.97</td>\n      <td>0.35</td>\n      <td>QuantilesGlobal</td>\n      <td>0.5</td>\n      <td>1.0E-8</td>\n      <td>1024</td>\n      <td>4096</td>\n      <td>0.29</td>\n      <td>random_grid_model_29</td>\n      <td>0.8330279245363592</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td></td>\n      <td>0.55</td>\n      <td>1.07</td>\n      <td>0.28</td>\n      <td>QuantilesGlobal</td>\n      <td>0.01</td>\n      <td>1.0E-8</td>\n      <td>128</td>\n      <td>64</td>\n      <td>0.89</td>\n      <td>random_grid_model_47</td>\n      <td>0.8326879724238675</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td></td>\n      <td>0.5</td>\n      <td>0.91</td>\n      <td>0.54</td>\n      <td>UniformAdaptive</td>\n      <td>0.5</td>\n      <td>1.0E-8</td>\n      <td>1024</td>\n      <td>256</td>\n      <td>0.38</td>\n      <td>random_grid_model_46</td>\n      <td>0.8302291850003252</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td></td>\n      <td>0.44</td>\n      <td>1.01</td>\n      <td>0.63</td>\n      <td>RoundRobin</td>\n      <td>0.5</td>\n      <td>1.0E-6</td>\n      <td>32</td>\n      <td>128</td>\n      <td>0.44</td>\n      <td>random_grid_model_15</td>\n      <td>0.8292532004164614</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td></td>\n      <td>0.83</td>\n      <td>1.08</td>\n      <td>0.26</td>\n      <td>QuantilesGlobal</td>\n      <td>0.5</td>\n      <td>0.0</td>\n      <td>64</td>\n      <td>32</td>\n      <td>0.25</td>\n      <td>random_grid_model_35</td>\n      <td>0.8284299410418781</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td></td>\n      <td>0.31</td>\n      <td>1.04</td>\n      <td>0.32</td>\n      <td>QuantilesGlobal</td>\n      <td>0.01</td>\n      <td>1.0E-6</td>\n      <td>512</td>\n      <td>256</td>\n      <td>0.53</td>\n      <td>random_grid_model_33</td>\n      <td>0.8281194960329269</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td></td>\n      <td>0.93</td>\n      <td>1.0</td>\n      <td>0.25</td>\n      <td>UniformAdaptive</td>\n      <td>0.5</td>\n      <td>1.0E-6</td>\n      <td>16</td>\n      <td>64</td>\n      <td>0.24</td>\n      <td>random_grid_model_19</td>\n      <td>0.827822989052784</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td></td>\n      <td>0.2</td>\n      <td>0.95</td>\n      <td>0.27</td>\n      <td>RoundRobin</td>\n      <td>0.05</td>\n      <td>0.0</td>\n      <td>128</td>\n      <td>64</td>\n      <td>0.45</td>\n      <td>random_grid_model_38</td>\n      <td>0.8256407198424265</td>\n    </tr>\n    <tr>\n      <th>48</th>\n      <td></td>\n      <td>0.63</td>\n      <td>0.93</td>\n      <td>0.33</td>\n      <td>QuantilesGlobal</td>\n      <td>0.001</td>\n      <td>1.0E-6</td>\n      <td>16</td>\n      <td>2048</td>\n      <td>0.31</td>\n      <td>random_grid_model_49</td>\n      <td>0.8250635220850434</td>\n    </tr>\n    <tr>\n      <th>49</th>\n      <td></td>\n      <td>0.2</td>\n      <td>1.1</td>\n      <td>0.31</td>\n      <td>QuantilesGlobal</td>\n      <td>0.001</td>\n      <td>1.0E-6</td>\n      <td>256</td>\n      <td>128</td>\n      <td>0.58</td>\n      <td>random_grid_model_9</td>\n      <td>0.8241806631998174</td>\n    </tr>\n    <tr>\n      <th>50</th>\n      <td></td>\n      <td>0.22</td>\n      <td>0.94</td>\n      <td>0.35</td>\n      <td>QuantilesGlobal</td>\n      <td>0.001</td>\n      <td>1.0E-8</td>\n      <td>1024</td>\n      <td>256</td>\n      <td>0.75</td>\n      <td>random_grid_model_50</td>\n      <td>0.8138247416129303</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"The random grid search slightly improved the results. Note that since the combination of possible models is so large, we will need to run the grid search for much longer to see if there are models that further improve the AUC. For now, we can leave it at that, or you can try it on your own to see if you get better results! The random search yielded an AUC of 0.8576.\n\nWe are going to build another GBM model, but we will update the parameters we found, and we are going to increase ntrees to 200 and see if we can further improve our model."},{"metadata":{"trusted":true},"cell_type":"code","source":"tuned_gbm = H2OGradientBoostingEstimator(max_depth = 6,\n                                        ntrees = 200,\n                                        sample_rate = 0.7,\n                                        col_sample_rate = 0.68,\n                                        col_sample_rate_per_tree = 0.59,\n                                        col_sample_rate_change_per_level = 0.92,\n                                        learn_rate = 0.1,\n                                        nbins = 16,\n                                        nbins_cats = 128,\n                                        min_split_improvement = 1e-6,\n                                        histogram_type = 'UniformAdaptive',\n                                         \n                                        seed = 42,\n                                        model_id = 'tuned_gbm',\n                                        stopping_rounds = 3,\n                                        stopping_tolerance = 1e-5,\n                                        stopping_metric = 'auc'\n                                         \n                                    )\n%time tuned_gbm.train(x=x, y=y, training_frame=train, validation_frame=valid)","execution_count":56,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.7/site-packages/h2o/estimators/estimator_base.py:200: RuntimeWarning: Dropping bad and constant columns: [LOAN_SEQUENCE_NUMBER]\n  warnings.warn(mesg[\"message\"], RuntimeWarning)\n","name":"stderr"},{"output_type":"stream","text":"gbm Model Build progress: |███████████████████████████████████████████████| 100%\nCPU times: user 568 ms, sys: 51.3 ms, total: 619 ms\nWall time: 1min 10s\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"Print the AUC and F1 scores to see how the model performed:"},{"metadata":{"trusted":true},"cell_type":"code","source":"tuned_gbm_per = tuned_gbm.model_performance(valid)\nprint(tuned_gbm_per.auc())\nprint(tuned_gbm_per.F1())","execution_count":57,"outputs":[{"output_type":"stream","text":"0.8605749531052185\n[[0.18148647270330784, 0.31592084150472455]]\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"We were able to get the highest validation AUC among the three models with our GBM. The model reached a 0.8606 AUC, while also improving the F1 to 0.3163.\n\nLet's take a look at the confusion matrix and see how are the misclassification errors from this model:"},{"metadata":{"trusted":true},"cell_type":"code","source":"tuned_gbm_per.confusion_matrix()","execution_count":58,"outputs":[{"output_type":"stream","text":"\nConfusion Matrix (Act/Pred) for max f1 @ threshold = 0.18148647270330784: \n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"            FALSE    TRUE   Error               Rate\n0  FALSE  70248.0  2065.0  0.0286   (2065.0/72313.0)\n1   TRUE   1772.0   886.0  0.6667    (1772.0/2658.0)\n2  Total  72020.0  2951.0  0.0512   (3837.0/74971.0)","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>FALSE</th>\n      <th>TRUE</th>\n      <th>Error</th>\n      <th>Rate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>FALSE</td>\n      <td>70248.0</td>\n      <td>2065.0</td>\n      <td>0.0286</td>\n      <td>(2065.0/72313.0)</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>TRUE</td>\n      <td>1772.0</td>\n      <td>886.0</td>\n      <td>0.6667</td>\n      <td>(1772.0/2658.0)</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Total</td>\n      <td>72020.0</td>\n      <td>2951.0</td>\n      <td>0.0512</td>\n      <td>(3837.0/74971.0)</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"execute_result","execution_count":58,"data":{"text/plain":""},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"Even though the misclassification error for the TRUE class improved, the error for the FALSE class and the overall error did not improve by much. However, with the tuning that we did, our GBM model was able to make more correct predictions for the TRUE class, which is good since we are dealing with a highly imbalanced dataset.\n\nHere is how you can compare the AUC from the default model with the tuned model:"},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Default GBM AUC: %.4f \\nTuned GBM AUC: %.4f' % (default_gbm_per.auc(), tuned_gbm_per.auc()))","execution_count":59,"outputs":[{"output_type":"stream","text":"Default GBM AUC: 0.8541 \nTuned GBM AUC: 0.8606\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# Test Set Performance"},{"metadata":{},"cell_type":"markdown","source":"We are going to obtain the test performance of each of the best models. Notice that we are just taking the best models and checking the model performance with the test set."},{"metadata":{"trusted":true},"cell_type":"code","source":"glm_test_per = tuned_glm.model_performance(test)\nrf_test_per = tuned_rf.model_performance(test)\ngbm_test_per = tuned_gbm.model_performance(test)","execution_count":60,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"You can now print any performance metric that you would like. Right now, we will just focus on the AUC, F1 Score, and the misclassification error from the confusion matrix."},{"metadata":{"trusted":true},"cell_type":"code","source":"print('GLM Test AUC: %.4f \\nRF Test AUC: %.4f \\nGBM Test AUC: %.4f'\n     % (glm_test_per.auc(), rf_test_per.auc(), gbm_test_per.auc()))","execution_count":61,"outputs":[{"output_type":"stream","text":"GLM Test AUC: 0.8548 \nRF Test AUC: 0.8557 \nGBM Test AUC: 0.8642\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"We were able to improve the AUC of all three models with the quick grid search that we did for all three models. We saw the greatest improvement with the RF model, as the default parameters were a little off from what we found to be good. All three AUC test scores are slightly higher than the validation scores but close enough to trust the validation score to tune all our models. And as it could be expected, the GBM had the best AUC, followed by the RF and, lastly, the GLM.\n\nNow print the F1 Score for each model :"},{"metadata":{"trusted":true},"cell_type":"code","source":"print('GLM Test F1 Score: ', glm_test_per.F1())\nprint('RF Test F1 Score: ', rf_test_per.F1())\nprint('GBM Test F1 Score: ', gbm_test_per.F1())","execution_count":63,"outputs":[{"output_type":"stream","text":"GLM Test F1 Score:  [[0.11310159001589919, 0.2863376972138301]]\nRF Test F1 Score:  [[0.12934723523259162, 0.29143314651721375]]\nGBM Test F1 Score:  [[0.1546546139670458, 0.30836866070026697]]\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"The F1 Score for the RF and GBM slightly increased compared to the default value; however, the GLM F1 Score slightly decreased compared to both the default and the validation results. Even though the AUC for the GLM improved, the F1 did not, and we will see shortly how that is reflected in the misclassification error. On the other hand, by tuning some parameters, we were able to get better AUC and better F1 scores for both the RF and the GBM models.\n\nLastly, we will take a look at the confusion matrix for each model:"},{"metadata":{"trusted":true},"cell_type":"code","source":"print('GLM Confusion Matrix: ', glm_test_per.confusion_matrix())\nprint('RF Confusion Matrix: ', rf_test_per.confusion_matrix())\nprint('GBM Confusion Matrix: ', gbm_test_per.confusion_matrix())","execution_count":64,"outputs":[{"output_type":"stream","text":"GLM Confusion Matrix:  \nConfusion Matrix (Act/Pred) for max f1 @ threshold = 0.11310159001589919: \n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"            FALSE    TRUE   Error               Rate\n0  FALSE  50471.0  3119.0  0.0582   (3119.0/53590.0)\n1   TRUE   1133.0   853.0  0.5705    (1133.0/1986.0)\n2  Total  51604.0  3972.0  0.0765   (4252.0/55576.0)","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>FALSE</th>\n      <th>TRUE</th>\n      <th>Error</th>\n      <th>Rate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>FALSE</td>\n      <td>50471.0</td>\n      <td>3119.0</td>\n      <td>0.0582</td>\n      <td>(3119.0/53590.0)</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>TRUE</td>\n      <td>1133.0</td>\n      <td>853.0</td>\n      <td>0.5705</td>\n      <td>(1133.0/1986.0)</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Total</td>\n      <td>51604.0</td>\n      <td>3972.0</td>\n      <td>0.0765</td>\n      <td>(4252.0/55576.0)</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"stream","text":"\nRF Confusion Matrix:  \nConfusion Matrix (Act/Pred) for max f1 @ threshold = 0.12934723523259162: \n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"            FALSE    TRUE   Error               Rate\n0  FALSE  69563.0  2663.0  0.0369   (2663.0/72226.0)\n1   TRUE   1762.0   910.0  0.6594    (1762.0/2672.0)\n2  Total  71325.0  3573.0  0.0591   (4425.0/74898.0)","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>FALSE</th>\n      <th>TRUE</th>\n      <th>Error</th>\n      <th>Rate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>FALSE</td>\n      <td>69563.0</td>\n      <td>2663.0</td>\n      <td>0.0369</td>\n      <td>(2663.0/72226.0)</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>TRUE</td>\n      <td>1762.0</td>\n      <td>910.0</td>\n      <td>0.6594</td>\n      <td>(1762.0/2672.0)</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Total</td>\n      <td>71325.0</td>\n      <td>3573.0</td>\n      <td>0.0591</td>\n      <td>(4425.0/74898.0)</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"stream","text":"\nGBM Confusion Matrix:  \nConfusion Matrix (Act/Pred) for max f1 @ threshold = 0.1546546139670458: \n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"            FALSE    TRUE   Error               Rate\n0  FALSE  69511.0  2715.0  0.0376   (2715.0/72226.0)\n1   TRUE   1690.0   982.0  0.6325    (1690.0/2672.0)\n2  Total  71201.0  3697.0  0.0588   (4405.0/74898.0)","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>FALSE</th>\n      <th>TRUE</th>\n      <th>Error</th>\n      <th>Rate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>FALSE</td>\n      <td>69511.0</td>\n      <td>2715.0</td>\n      <td>0.0376</td>\n      <td>(2715.0/72226.0)</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>TRUE</td>\n      <td>1690.0</td>\n      <td>982.0</td>\n      <td>0.6325</td>\n      <td>(1690.0/2672.0)</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Total</td>\n      <td>71201.0</td>\n      <td>3697.0</td>\n      <td>0.0588</td>\n      <td>(4405.0/74898.0)</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"stream","text":"\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"Again, all three scores are very close to each other, but the best one is the GBM, second the RF, and lastly, our GLM. For the misclassification error, we see the opposite pattern to the F1 Score, the test misclassification error for both RF and GBM increased, and it slightly decreased for the GLM. However, it is important to note that for both RF and GBM, the error for the TRUE predicted label decreased, and for the GLM increased. The high misclassification error for the TRUE class, along with a relatively low F1 Score, is due to the highly imbalanced dataset.\n\nFor this dataset, we obtained a good AUC for all three models. We obtained an okay F1 Score, given that our dataset is highly imbalanced, and we also obtained a good overall misclassification error, although due to the given imbalanced data, the error for the TRUE label was not so low. Overall, The best model trained on our dataset was the GBM, followed by the RF, and lastly, the GLM."},{"metadata":{},"cell_type":"markdown","source":"- shutdown cluster once done with:\n\nh2o.cluster().shutdown()"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}